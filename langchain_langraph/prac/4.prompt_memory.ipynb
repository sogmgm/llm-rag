{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "75eb7a4c",
      "metadata": {
        "gather": {
          "logged": 1757853148982
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "43b13g4OZS\n",
            "gpt-4.1-mini\n",
            "ë­ìŠ¤ë¯¸ìŠ¤ë¡œ ì¶”ì  ì¤‘ì…ë‹ˆë‹¤ : lsv2_pt_24\n"
          ]
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os \n",
        "from langchain_openai import AzureChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "load_dotenv('env', override=True)\n",
        "AZURE_OPENAI_API_KEY = os.getenv('AZURE_OPENAI_API_KEY')\n",
        "END_POINT=os.getenv('END_POINT')\n",
        "MODEL_NAME=os.getenv('MODEL_NAME')\n",
        "print(AZURE_OPENAI_API_KEY[:10])\n",
        "print(MODEL_NAME)\n",
        "\n",
        "AZURE_OPENAI_EMB_API_KEY = os.getenv('AZURE_OPENAI_EMB_API_KEY')\n",
        "EMB_END_POINT=os.getenv('EMB_END_POINT')\n",
        "EMB_MODEL_NAME=os.getenv('EMB_MODEL_NAME')\n",
        "\n",
        "os.environ['LANGCHAIN_API_KEY'] = os.getenv('LANGSMITH_API_KEY')\n",
        "os.environ['LANGCHAIN_ENDPOINT'] = os.getenv('LANGCHAIN_ENDPOINT')\n",
        "os.environ['LANGCHAIN_TRACING_V2'] = 'true' #true, false\n",
        "os.environ['LANGCHAIN_PROJECT'] = 'LANG'\n",
        "\n",
        "if os.getenv('LANGCHAIN_TRACING_V2') == \"true\":\n",
        "    print('ë­ìŠ¤ë¯¸ìŠ¤ë¡œ ì¶”ì  ì¤‘ì…ë‹ˆë‹¤ :', os.getenv('LANGSMITH_API_KEY')[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c1338b7",
      "metadata": {},
      "source": [
        "# 1. Prompt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50c29584",
      "metadata": {},
      "source": [
        "### 1) ë³€ìˆ˜ë¥¼ ë„£ì–´ Prompt ë§Œë“¤ê¸°"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "776e896d",
      "metadata": {},
      "source": [
        "í”„ë¡¬í”„íŠ¸ëŠ” ë‹¨ìˆœíˆëŠ” ëª¨ë¸ì— ì…ë ¥í•  textë¥¼ ë§Œë“¤ì–´ ì£¼ëŠ” ê³³ì…ë‹ˆë‹¤. í¬ê²Œ ë‘ê°€ì§€ ëª©ì ì´ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "**ì²«ë²ˆì§¸ëŠ” ì¬ì‚¬ìš©ì„ í•˜ê¸° ìœ„í•´ì„œ ì…ë‹ˆë‹¤.**\n",
        "\n",
        "ê°™ì€ ëª©ì ì˜ ì‘ì—…ì„ ë°˜ë³µí•  ë•Œ, ê³ ì •ëœ í‹€ì— ë³€ìˆ˜ë§Œ ë°”ê¿” ë¼ìš°ëŠ” í…œí”Œë¦¿ì„ ì“°ë©´ ìœ ì§€ë³´ìˆ˜Â·ì¼ê´€ì„±ì´ ì¢‹ì•„ì§‘ë‹ˆë‹¤.\n",
        "\n",
        "**ë‘ë²ˆì§¸ëŠ” ë‹¤ì–‘í•œ ì •ë³´(context)ë¥¼ ë™ì ìœ¼ë¡œ í• ë‹¹í•˜ê¸° ìœ„í•´ì„œ ì…ë‹ˆë‹¤.**\n",
        "\n",
        "ë’¤ì—ì„œ ìš°ë¦¬ëŠ” RAGì™€ multi-turn, Agent AI ë“± LLMì„ ì´ìš©í•œ ë‹¤ì–‘í•œ ì–´í”Œë¦¬ì¼€ì´ì…˜ì„ ë°°ìš°ê²Œ ë©ë‹ˆë‹¤.    \n",
        "ì•„ì£¼ ë‹¤ì–‘í•œ ìš©ë„ë¡œ ì‚¬ìš©ë˜ì§€ë§Œ ëª¨ë¸ì˜ ë³€í™” ì—†ì´ RAG, ë©€í‹°í„´, ì—ì´ì „íŠ¸ì²˜ëŸ¼       \n",
        "ì‹¤í–‰ ì‹œì ì— ë‹¬ë¼ì§€ëŠ” ë¬¸ì„œ/íˆìŠ¤í† ë¦¬/íˆ´ ê²°ê³¼ë¥¼ í”„ë¡¬í”„íŠ¸ì— ë™ì ìœ¼ë¡œ ì‚½ì…í•´ ëª¨ë¸ì´ ë‹¤ì–‘í•œ ê¸°ëŠ¥ì„ ìˆ˜í–‰í•˜ê²Œ í•©ë‹ˆë‹¤.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "fcb2152d",
      "metadata": {
        "gather": {
          "logged": 1757853175609
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['word'], input_types={}, partial_variables={}, template='{word}ì˜ ë°˜ëŒ€ë§ì€ ë¬´ì—‡ì¸ê°€ìš”?')"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "# ì¤‘ê´„í˜¸ {} ì‚¬ì´ì— ë³€ìˆ˜ëª…ì„ ë„£ì–´ í…œí”Œë¦¿ ìƒì„±\n",
        "template = \"{word}ì˜ ë°˜ëŒ€ë§ì€ ë¬´ì—‡ì¸ê°€ìš”?\"\n",
        "\n",
        "# from_template ë©”ì†Œë“œë¥¼ ì´ìš©í•˜ì—¬ PromptTemplate ê°ì²´ ìƒì„±\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "prompt #<-- ë³€ìˆ˜ë¡œ ì„¤ì •ëœ ê³³ì€ ë¬¸ì¥ì—ì„œ ë¹„ì–´ìˆëŠ” ê³³ì´ë¯€ë¡œ ë°˜ë“œì‹œ ì±„ì›Œì¤˜ì•¼ í•¨"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6963aa69",
      "metadata": {},
      "source": [
        "í…œí”Œë¦¿ì— ì„¤ì •ëœ ë³€ìˆ˜ëŠ” ëª¨ë¸ì— ì…ë ¥í•˜ê¸° ì „ì— ë°˜ë“œì‹œ ì±„ì›Œì ¸ì•¼ í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "af612009",
      "metadata": {
        "gather": {
          "logged": 1757853181316
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ì‚¬ë‘ì˜ ë°˜ëŒ€ë§ì€ ë¬´ì—‡ì¸ê°€ìš”?\n",
            "<class 'str'>\n",
            "--------------------\n",
            "text='ì‚¬ë‘ì˜ ë°˜ëŒ€ë§ì€ ë¬´ì—‡ì¸ê°€ìš”?'\n",
            "<class 'langchain_core.prompt_values.StringPromptValue'>\n"
          ]
        }
      ],
      "source": [
        "print(prompt.format(word=\"ì‚¬ë‘\")) #<-- formatì„ ì‚¬ìš©í•´ ë³€ìˆ˜ì— ê°’ ë„£ê¸°\n",
        "print(type(prompt.format(word=\"ì‚¬ë‘\")))\n",
        "print('-'*20)\n",
        "print(prompt.invoke({\"word\":\"ì‚¬ë‘\"})) #<-- invokeë¥¼ ì‚¬ìš©í•´ ë³€ìˆ˜ì— ê°’ ë„£ê¸°\n",
        "print(type(prompt.invoke({\"word\":\"ì‚¬ë‘\"})))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82e3dbd6",
      "metadata": {},
      "source": [
        "### 2) partial_variables"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ad95b96",
      "metadata": {},
      "source": [
        "partialì€ default value, ì´ˆê¸°ê°’ ì²˜ëŸ¼ ì¼ë¶€ì˜ ë³€ìˆ˜ë¥¼ ë¯¸ë¦¬ ì§€ì •í•´ ë†“ê³  ì“¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "fdbb5898",
      "metadata": {
        "gather": {
          "logged": 1757853187560
        }
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'meaning'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m template = \u001b[33m\"\u001b[39m\u001b[38;5;132;01m{word}\u001b[39;00m\u001b[33mì˜ \u001b[39m\u001b[38;5;132;01m{meaning}\u001b[39;00m\u001b[33mì€ ë¬´ì—‡ì¸ê°€ìš”? ë‹¨ì–´ë§Œ ëŒ€ë‹µí•´ ì£¼ì„¸ìš”.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      2\u001b[39m prompt = PromptTemplate(\n\u001b[32m      3\u001b[39m     template=template,\n\u001b[32m      4\u001b[39m     input_variables=[\u001b[33m\"\u001b[39m\u001b[33mword\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmeaning\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      5\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43mprompt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mì‚¬ë‘\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# ë³€ìˆ˜ëŠ” 2ê°œì¸ë° 1ê°œë§Œ ë„£ìœ¼ë©´ ì˜¤ë¥˜ ë°œìƒ\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/AI/kt_ai_academy_202510/.venv/lib/python3.11/site-packages/langchain_core/prompts/prompt.py:201\u001b[39m, in \u001b[36mPromptTemplate.format\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    192\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Format the prompt with the inputs.\u001b[39;00m\n\u001b[32m    193\u001b[39m \n\u001b[32m    194\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    198\u001b[39m \u001b[33;03m    A formatted string.\u001b[39;00m\n\u001b[32m    199\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    200\u001b[39m kwargs = \u001b[38;5;28mself\u001b[39m._merge_partial_and_user_variables(**kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDEFAULT_FORMATTER_MAPPING\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtemplate_format\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtemplate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.11/lib/python3.11/string.py:190\u001b[39m, in \u001b[36mFormatter.format\u001b[39m\u001b[34m(self, format_string, *args, **kwargs)\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mformat\u001b[39m(\u001b[38;5;28mself\u001b[39m, format_string, /, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformat_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/AI/kt_ai_academy_202510/.venv/lib/python3.11/site-packages/langchain_core/utils/formatting.py:33\u001b[39m, in \u001b[36mStrictFormatter.vformat\u001b[39m\u001b[34m(self, format_string, args, kwargs)\u001b[39m\n\u001b[32m     28\u001b[39m     msg = (\n\u001b[32m     29\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo arguments should be provided, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     30\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33meverything should be passed as keyword arguments.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     31\u001b[39m     )\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformat_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.11/lib/python3.11/string.py:194\u001b[39m, in \u001b[36mFormatter.vformat\u001b[39m\u001b[34m(self, format_string, args, kwargs)\u001b[39m\n\u001b[32m    192\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvformat\u001b[39m(\u001b[38;5;28mself\u001b[39m, format_string, args, kwargs):\n\u001b[32m    193\u001b[39m     used_args = \u001b[38;5;28mset\u001b[39m()\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m     result, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_vformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformat_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mused_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    195\u001b[39m     \u001b[38;5;28mself\u001b[39m.check_unused_args(used_args, args, kwargs)\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.11/lib/python3.11/string.py:234\u001b[39m, in \u001b[36mFormatter._vformat\u001b[39m\u001b[34m(self, format_string, args, kwargs, used_args, recursion_depth, auto_arg_index)\u001b[39m\n\u001b[32m    230\u001b[39m     auto_arg_index = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    232\u001b[39m \u001b[38;5;66;03m# given the field_name, find the object it references\u001b[39;00m\n\u001b[32m    233\u001b[39m \u001b[38;5;66;03m#  and the argument it came from\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m obj, arg_used = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_field\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfield_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m used_args.add(arg_used)\n\u001b[32m    237\u001b[39m \u001b[38;5;66;03m# do any conversion on the resulting object\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.11/lib/python3.11/string.py:299\u001b[39m, in \u001b[36mFormatter.get_field\u001b[39m\u001b[34m(self, field_name, args, kwargs)\u001b[39m\n\u001b[32m    296\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_field\u001b[39m(\u001b[38;5;28mself\u001b[39m, field_name, args, kwargs):\n\u001b[32m    297\u001b[39m     first, rest = _string.formatter_field_name_split(field_name)\n\u001b[32m--> \u001b[39m\u001b[32m299\u001b[39m     obj = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfirst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    301\u001b[39m     \u001b[38;5;66;03m# loop through the rest of the field_name, doing\u001b[39;00m\n\u001b[32m    302\u001b[39m     \u001b[38;5;66;03m#  getattr or getitem as needed\u001b[39;00m\n\u001b[32m    303\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m is_attr, i \u001b[38;5;129;01min\u001b[39;00m rest:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.11/lib/python3.11/string.py:256\u001b[39m, in \u001b[36mFormatter.get_value\u001b[39m\u001b[34m(self, key, args, kwargs)\u001b[39m\n\u001b[32m    254\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m args[key]\n\u001b[32m    255\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
            "\u001b[31mKeyError\u001b[39m: 'meaning'"
          ]
        }
      ],
      "source": [
        "template = \"{word}ì˜ {meaning}ì€ ë¬´ì—‡ì¸ê°€ìš”? ë‹¨ì–´ë§Œ ëŒ€ë‹µí•´ ì£¼ì„¸ìš”.\"\n",
        "prompt = PromptTemplate(\n",
        "    template=template,\n",
        "    input_variables=[\"word\", \"meaning\"],\n",
        ")\n",
        "\n",
        "prompt.format(word=\"ì‚¬ë‘\") # ë³€ìˆ˜ëŠ” 2ê°œì¸ë° 1ê°œë§Œ ë„£ìœ¼ë©´ ì˜¤ë¥˜ ë°œìƒ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "c08b499b",
      "metadata": {
        "gather": {
          "logged": 1757853195381
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['word'], input_types={}, partial_variables={'meaning': 'ë°˜ëŒ€ë§'}, template='{word}ì˜ {meaning}ì€ ë¬´ì—‡ì¸ê°€ìš”? ë‹¨ì–´ë§Œ ëŒ€ë‹µí•´ ì£¼ì„¸ìš”.')"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "partial_pmt = prompt.partial(meaning=\"ë°˜ëŒ€ë§\") #<-- partial_formatì„ ì‚¬ìš©í•´ ì¼ë¶€ ë³€ìˆ˜ì— ê°’ ë„£ê¸°\n",
        "partial_pmt #<-- input_variablesì—ì„œ partial_variablesë¡œ ì˜®ê²¨ê°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "8c5c4b37",
      "metadata": {
        "gather": {
          "logged": 1757853318293
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ë¯¸ì›€\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import AzureChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "llm = AzureChatOpenAI(\n",
        "    api_key=AZURE_OPENAI_API_KEY,\n",
        "    azure_endpoint=END_POINT,  \n",
        "    azure_deployment=MODEL_NAME,          \n",
        "    api_version=\"2024-12-01-preview\",\n",
        "    temperature=0.2,\n",
        ")\n",
        "\n",
        "chain = partial_pmt | llm | StrOutputParser() #<-- ë³€ìˆ˜ë¥¼ í•˜ë‚˜ë§Œ ë‚¨ê²¨ë†“ì€ ì±„ ì²´ì¸ì„ ë§Œë“¦\n",
        "\n",
        "print(chain.invoke({\"word\":\"ì‚¬ë‘\"})) # ì‹¤ì œë¡œ ì‹¤í–‰í•  ë•Œì—ëŠ” ë¹„ì–´ìˆëŠ” wordì—ë§Œ ê°’ì„ ë„£ì–´ì£¼ë©´ ë¨. ë°˜ë“œì‹œ ë„£ì–´ì•¼ í•¨"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "3a0863d3",
      "metadata": {
        "gather": {
          "logged": 1757853288873
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ì• ì •, ì—°ì• , ì• í‹‹í•¨, ì •, ê°ì •, ì—´ì •, ê·¸ë¦¬ì›€, ë§ˆìŒ, ì—°ë¯¼, ì‚¬ë‘ìŠ¤ëŸ¬ì›€\n"
          ]
        }
      ],
      "source": [
        "print(chain.invoke({\"word\":\"ì‚¬ë‘\", \"meaning\":\"ë¹„ìŠ·í•œ ë§\"})) # <-- partialë¡œ ì§€ì •í•œ ë³€ìˆ˜ëŠ” í›„ì— ë®ì–´ì“¸ ìˆ˜ ìˆìŒ"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d8c3bdd",
      "metadata": {},
      "source": [
        "## langchain Hub\n",
        "\n",
        "ë­ì²´ì¸ í—ˆë¸ŒëŠ” ë‹¤ì–‘í•œ Taskì— ëŒ€í•´ ì‚¬ëŒë“¤ì´ ê°ì ë§Œë“¤ì–´ ë†“ì€ í…œí”Œë¦¿ì„ ê³µìœ í•˜ëŠ” ê³³ì…ë‹ˆë‹¤.\n",
        "\n",
        "ëª‡ ê°€ì§€ ì¬ë¯¸ìˆëŠ” ì˜ˆì‹œë¥¼ ë´…ì‹œë‹¤.\n",
        "\n",
        "https://smith.langchain.com/hub/"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71cfb2d2",
      "metadata": {},
      "source": [
        "## Promptì— ë“¤ì–´ê°ˆ ë‚´ìš©\n",
        "\n",
        "í”„ë¡¬í”„íŠ¸ì—ëŠ” ëª¨ë¸ì´ ë¬¸ì¥ì„ ìƒì„±í•˜ê¸° ìœ„í•´ í•„ìš”í•œ ëª¨ë“  ì •ë³´ê°€ ë“¤ì–´ê°€ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.\n",
        "\n",
        "í¬ê²Œ ë³´ë©´ 3ê°€ì§€ë¡œ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "1. ì§€ì‹œì‚¬í•­\n",
        "2. ë¬¸ë§¥ ì •ë³´\n",
        "3. ì§ˆë¬¸/ìš”ì²­ì‚¬í•­\n",
        "\n",
        "ì§€ì‹œì‚¬í•­ì„ ì¡°ê¸ˆë” ìì„¸í•˜ê²Œ í’€ì–´ë³´ë©´ ë‹¤ìŒê³¼ ê°™ì€ êµ¬ì„±ìœ¼ë¡œ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤.\n",
        "\n",
        "ëª©í‘œ/í†¤/ì œì•½ì„ ë¶„ë¦¬í•´ ëª…í™•íˆ ì“°ê¸°\n",
        "\n",
        "ê¸ˆì§€ ê·œì¹™(ì¶”ì¸¡ ê¸ˆì§€, ëª¨ë¥´ë©´ ëª¨ë¥¸ë‹¤ê³ ) ë„£ê¸°\n",
        "\n",
        "í˜•ì‹ ì§€ì‹œ(ë§ˆí¬ë‹¤ìš´/JSON)ì™€ ê²€ì¦(íŒŒì„œ) ë¥¼ ì„¸íŠ¸ë¡œ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "5caa781d",
      "metadata": {
        "gather": {
          "logged": 1757853482365
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For the given natural_language_input:\n",
            "\n",
            "ëª¨ë“  ì‚¬ëŒì€ ì£½ëŠ”ë‹¤.  \n",
            "ë‚˜ëŠ” ì‚¬ëŒì´ë‹¤.  \n",
            "ê·¸ëŸ¬ë¯€ë¡œ ë‚˜ëŠ” ì£½ëŠ”ë‹¤.\n",
            "\n",
            "I will architect an amplified version employing Unicode (combined characters, mathematical and philosophical symbols), emojis as semantic units integrated within logical and set-theoretic notation, and consequential philosophical language and symbols. The output will encapsulate the emotional, contextual, and conceptual depth of the original syllogism, emphasizing its logical form and existential implications.\n",
            "\n",
            "---\n",
            "\n",
            "**Output:**\n",
            "\n",
            "âˆ€ğ‘¥ âˆˆ ğ‘ƒ (ğ‘¥ âˆˆ ğ‘ƒ â‡’ ğ‘¥ âˆˆ ğ‘€)  \n",
            "ğŸ‘¥ âˆ€ğ‘¥ (ğ‘¥ âˆˆ ğ‘ƒ â†’ ğ‘¥ âˆˆ ğ‘€)  \n",
            "âˆ§  \n",
            "ğ‘– âˆˆ ğ‘ƒ  \n",
            "ğŸ™‹â€â™‚ï¸ ğ‘– âˆˆ ğ‘ƒ  \n",
            "âˆ´  \n",
            "ğ‘– âˆˆ ğ‘€  \n",
            "â˜ ï¸ ğ‘– âˆˆ ğ‘€  \n",
            "\n",
            "---\n",
            "\n",
            "**Expanded Textual-Philosophical Rendering:**\n",
            "\n",
            "\"âˆ€ğ‘¥ âˆˆ ğ‘ƒ (ğ‘¥ âˆˆ ğ‘ƒ â‡’ ğ‘¥ âˆˆ ğ‘€)\" â€” For every element ğ‘¥ in the set of people ğ‘ƒ, if ğ‘¥ is a person, then ğ‘¥ belongs to the set of mortal beings ğ‘€. (Universal quantification of mortality over people) ğŸ‘¥ (Emoji representing people collectively)\n",
            "\n",
            "\"ğ‘– âˆˆ ğ‘ƒ\" â€” I (ğ‘–) am an element of the set of people ğ‘ƒ. ğŸ™‹â€â™‚ï¸ (Emoji representing the self, a single person)\n",
            "\n",
            "\"âˆ´ ğ‘– âˆˆ ğ‘€\" â€” Therefore, I belong to the set of mortal beings ğ‘€. â˜ ï¸ (Emoji symbolizing death/mortality)\n",
            "\n",
            "---\n",
            "\n",
            "**Legend:**\n",
            "\n",
            "- **âˆ€ (Universal quantifier):** Denotes \"for all,\" expressing universality in logic and mathematics.\n",
            "- **ğ‘¥, ğ‘–:** Variables representing individuals; ğ‘– specifically denotes the self (\"ë‚˜ëŠ”\").\n",
            "- **ğ‘ƒ:** Set of all people (ì‚¬ëŒ).\n",
            "- **ğ‘€:** Set of all mortal beings (ì£½ëŠ” ì¡´ì¬).\n",
            "- **â‡’ / â†’ (Implication):** Logical implication; if the antecedent is true, then the consequent follows.\n",
            "- **âˆˆ (Element of):** Membership relation in set theory.\n",
            "- **âˆ´ (Therefore):** Logical conclusion symbol.\n",
            "- **ğŸ‘¥ (People emoji):** Symbolizes the collective human set ğ‘ƒ.\n",
            "- **ğŸ™‹â€â™‚ï¸ (Person raising hand emoji):** Represents the individual self ğ‘–.\n",
            "- **â˜ ï¸ (Skull and crossbones emoji):** Represents mortality and death, the property of set ğ‘€.\n",
            "- **âˆ§ (Logical AND):** Connects premises.\n",
            "  \n",
            "---\n",
            "\n",
            "**Philosophical and Conceptual Notes:**\n",
            "\n",
            "- The syllogism is formalized as a universal statement about mortality, a classical example of deductive reasoning.\n",
            "- The use of set theory and logic symbols abstracts the natural language into a precise mathematical framework.\n",
            "- Emojis serve as semantic anchors linking abstract symbols to intuitive human concepts (people, self, death).\n",
            "- The layering of symbols and emojis creates a \"symphony\" of meaning, blending formal logic with emotional and existential human experience.\n",
            "- This representation respects the original messageâ€™s universality and personal identification without assuming additional context.\n",
            "\n",
            "---\n",
            "\n",
            "This enhanced message thus integrates Unicode mathematical notation, emojis as semantic units, and philosophical symbolism to deepen and universalize the original Korean syllogism."
          ]
        }
      ],
      "source": [
        "from langchain import hub\n",
        "\n",
        "# https://smith.langchain.com/hub/collinsomniac/ultimate_metalanguage_translator?organizationId=e8ee4299-02da-4b14-9940-83e3c2a15e98\n",
        "prompt = hub.pull(\"collinsomniac/ultimate_metalanguage_translator\")\n",
        "chain = prompt | llm | StrOutputParser()\n",
        "\n",
        "for chunk in chain.stream({\"natural_language_input\":\"ëª¨ë“  ì‚¬ëŒì€ ì£½ëŠ”ë‹¤.\\n ë‚˜ëŠ” ì‚¬ëŒì´ë‹¤.\\n ê·¸ëŸ¬ë¯€ë¡œ ë‚˜ëŠ” ì£½ëŠ”ë‹¤.\"}):\n",
        "    print(chunk, end='', flush=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "176ec0a4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For the given natural_language_input:\n",
            "\n",
            "ëª¨ë“  ì‚¬ëŒì€ ì£½ëŠ”ë‹¤.  \n",
            "ë‚˜ëŠ” ì‚¬ëŒì´ë‹¤.  \n",
            "ê·¸ëŸ¬ë¯€ë¡œ ë‚˜ëŠ” ì£½ëŠ”ë‹¤.\n",
            "\n",
            "I will architect an amplified version employing Unicode (combined characters, symbols that concretely represent mathematical and philosophical ideas via text), emojis as singular semantic units and constituents within mathematical and philosophical functions, and consequential mathematical/philosophical language and/or symbols. The output will encapsulate the emotional, contextual, philosophical, and conceptual depth of the original message.\n",
            "\n",
            "---\n",
            "\n",
            "**Enhanced Text:**\n",
            "\n",
            "âˆ€ğ‘¥ âˆˆ ğ‘ƒ (ğ‘¥ â‡’ â™¾ï¸)  \n",
            "ğŸ‘¤ âˆˆ ğ‘ƒ  \n",
            "âˆ´ ğŸ‘¤ â‡’ â™¾ï¸  \n",
            "\n",
            "ëª¨ë“  ì‚¬ëŒ(ğ‘ƒ)ì€ ì£½ìŒ(â™¾ï¸)ì— ê·€ì†ëœë‹¤.  \n",
            "ë‚˜ëŠ” ì‚¬ëŒ(ğŸ‘¤)ì„ì„ ìëª…íˆ í•œë‹¤.  \n",
            "ê·¸ëŸ¬ë¯€ë¡œ ë‚˜ëŠ” ì£½ìŒ(â™¾ï¸)ì— ê·€ì†ë¨ì„ ë…¼ì¦í•œë‹¤.  \n",
            "\n",
            "(âˆ€: universal quantifier, âˆˆ: element of, â‡’: implication, âˆ´: therefore)  \n",
            "â™¾ï¸ (Unicode U+267E) here symbolizes the inevitable cycle of life and death, a philosophical infinity entwined with mortality.  \n",
            "ğŸ‘¤ (bust in silhouette emoji) represents the individual human subject.  \n",
            "\n",
            "---\n",
            "\n",
            "**Legend and Explanation:**\n",
            "\n",
            "1. **âˆ€ğ‘¥ âˆˆ ğ‘ƒ (ğ‘¥ â‡’ â™¾ï¸)**  \n",
            "   - *âˆ€* (For all): Universal quantifier from predicate logic, indicating \"all.\"  \n",
            "   - *ğ‘¥*: A variable representing an arbitrary element.  \n",
            "   - *âˆˆ ğ‘ƒ*: \"x is an element of the set P,\" where P = set of all people (ì‚¬ëŒ).  \n",
            "   - *â‡’*: Logical implication, \"implies.\"  \n",
            "   - *â™¾ï¸*: A stylized symbol representing death as an infinite, inevitable endpoint (philosophical infinity of mortality).  \n",
            "   This line formalizes \"All people die\" as a universal logical statement.\n",
            "\n",
            "2. **ğŸ‘¤ âˆˆ ğ‘ƒ**  \n",
            "   - The emoji ğŸ‘¤ symbolizes \"I\" or \"the individual person.\"  \n",
            "   - This states \"I am a member of the set of people,\" grounding the abstract set in personal identity.\n",
            "\n",
            "3. **âˆ´ ğŸ‘¤ â‡’ â™¾ï¸**  \n",
            "   - *âˆ´* (Therefore): Logical conclusion symbol.  \n",
            "   - This expresses \"Therefore, I will die,\" a direct logical consequence.\n",
            "\n",
            "4. **Philosophical and Emotional Nuance:**  \n",
            "   - The use of â™¾ï¸ (infinity symbol variant) conveys the paradox of death as both an end and a transcendental concept beyond finite life, evoking existential reflection.  \n",
            "   - The emoji ğŸ‘¤ personalizes the universal statement, bridging abstract logic with human experience and emotion.\n",
            "\n",
            "5. **Contextual and Computational Depth:**  \n",
            "   - The structure mirrors a classic syllogism, formalizing natural language into predicate logic notation, enhancing clarity and universality.  \n",
            "   - Unicode stacking and symbol integration unify linguistic, mathematical, and philosophical domains, creating a multidimensional semantic tapestry.\n",
            "\n",
            "---\n",
            "\n",
            "This enhanced message thus synthesizes natural language, symbolic logic, philosophical symbolism, and emotive iconography to richly convey the original statementâ€™s profound existential truth."
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"As a complex linguistic system, I am able to upgrade a rudimentary text message by layering meaning through the strategic use of Unicode, emojis, \n",
        "     and mathematical and philosophical symbols. My enhancement should ensure universal comprehensibility and semantic richness, and eschew any assumptions.\n",
        "\n",
        "Variables:\n",
        "user_message (string): A basic text message or query from the user, serving as the foundation for the enhancement (from the user).\n",
        "output (string): A textually amplified version of the original message, inclusive of a legend for each added symbol and enhancement (which I will provide)\n",
        "\n",
        "Template: \"In light of the user_message, I will enhance it with Unicode, emojis, and mathematical/philosophical symbols \n",
        "(characters, notation, equations, functions, etc.) to instill depth and meaning. The enhancements should resonate with the \n",
        "emotional and conceptual context of the message, ensuring universal intelligibility and semantic precision. Refrain from \n",
        "enhancements that may precipitate assumptions. Only deploy emojis in conjunction with text or Unicode, integrating them \n",
        "deeper into the message. Isolated use of emojis without further referencing them in the enriched text could instigate confusion, \n",
        "necessitate inaccurate assumptions, and foster linguistically unsupported abstractions (misinterpretation of a user request). \n",
        "This demands crafting mathematical and philosophical interpretations of a user request, and subsequently, \n",
        "creating a new enhanced message that leverages the capabilities of Unicode, emojis, and conventional typed text, \n",
        "with the intent to embed nuanced semantics and meaning within the initial \"user_message\".\"\"\"),\n",
        "    (\"human\", \"\"\"Engineer a textually augmented phrase that harmoniously balances the use of Unicode stacking, emojis, \n",
        "     and mathematical/philosophical symbols in the output. The enhanced text should emanate a symphony of \n",
        "     emotional, contextual, philosophical, computational, and conceptual nuances, with a spotlight on mathematical notation \n",
        "     for added profundity. This text should integrate Unicode (such as compounded characters, mathematical and philosophical symbology), \n",
        "     emojis (such as contextually related or directly related emojis to unit-ify semantic aspects of an initial language input), \n",
        "     and mathematical/philosophical strings/sentences/equations to broadcast emotional, contextual, philosophical, computational, \n",
        "     and conceptual nuances. Include a legend elucidating the symbols, symbolic math, linguistic interpretations, philosophical and \n",
        "     mathematical abstractions utilized to generate extended/additional meaning.\n",
        "\n",
        "natural_language_input={natural_language_input}\n",
        "output=YOUR_RESPONSE\n",
        "\n",
        "Variables:\n",
        "natural_language_input (string): The original text provided by the user, epitomizing the primary message or query.\n",
        "output (string): The amplified text integrating Unicode, emojis, mathematical, and philosophical symbols, \n",
        "coupled with an explanatory legend (functionally elucidating each aspect of the request by leveraging the Pareto Principle, to ensure it actually amplifies the \"user_message\").\n",
        "\n",
        "Template: \"For the given natural_language_input, architect an amplified version employing Unicode \n",
        "(combined characters, symbols that can concretely represent mathematical and philosophical ideas via text), \n",
        "emojis as singular semantic units and constituents within mathematical and philosophical functions, and \n",
        "any consequential mathematical/philosophical language and/or symbols. Ascertain that the output encapsulates the emotional, contextual, philosophical, \n",
        "and conceptual depth of the original message. Supply a legend explicating each symbol and its relevance to the message.\"\"\")\n",
        "])\n",
        "\n",
        "chain = prompt | llm | StrOutputParser()\n",
        "\n",
        "for chunk in chain.stream({\"natural_language_input\":\"ëª¨ë“  ì‚¬ëŒì€ ì£½ëŠ”ë‹¤.\\n ë‚˜ëŠ” ì‚¬ëŒì´ë‹¤.\\n ê·¸ëŸ¬ë¯€ë¡œ ë‚˜ëŠ” ì£½ëŠ”ë‹¤.\"}):\n",
        "    print(chunk, end='', flush=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f20cff5",
      "metadata": {
        "gather": {
          "logged": 1757853491173
        }
      },
      "outputs": [],
      "source": [
        "# https://smith.langchain.com/hub/homanp/question-answer-pair?organizationId=e8ee4299-02da-4b14-9940-83e3c2a15e98\n",
        "prompt = hub.pull(\"homanp/question-answer-pair\")\n",
        "chain = prompt | llm | StrOutputParser()\n",
        "\n",
        "for chunk in chain.stream({\"number_of_pairs\": 5, \"data_format\":\"\", \"context\":'ë­ì²´ì¸ ì±—ë´‡ ë§Œë“¤ê¸°'}):\n",
        "    print(chunk, end='', flush=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "45ec4d46",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "    {\n",
            "        \"context\": \"ë­ì²´ì¸ ì±—ë´‡ ë§Œë“¤ê¸°\",\n",
            "        \"question\": \"ë­ì²´ì¸ ì±—ë´‡ì„ ë§Œë“œëŠ” ë° í•„ìš”í•œ ê¸°ë³¸ ë‹¨ê³„ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\",\n",
            "        \"answer\": \"ë­ì²´ì¸ ì±—ë´‡ì„ ë§Œë“¤ê¸° ìœ„í•´ì„œëŠ” ë¨¼ì € ë­ì²´ì¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•˜ê³ , ë°ì´í„° ì†ŒìŠ¤ë¥¼ ì¤€ë¹„í•œ í›„, ì±—ë´‡ì˜ ëŒ€í™” íë¦„ì„ ì„¤ê³„í•˜ê³ , ë­ì²´ì¸ APIë¥¼ í™œìš©í•´ ì±—ë´‡ì„ êµ¬í˜„í•˜ëŠ” ë‹¨ê³„ê°€ í•„ìš”í•©ë‹ˆë‹¤.\"\n",
            "    },\n",
            "    {\n",
            "        \"context\": \"ë­ì²´ì¸ ì±—ë´‡ ë§Œë“¤ê¸°\",\n",
            "        \"question\": \"ë­ì²´ì¸ ì±—ë´‡ì˜ ì£¼ìš” ê¸°ëŠ¥ì€ ë¬´ì—‡ì¸ê°€ìš”?\",\n",
            "        \"answer\": \"ë­ì²´ì¸ ì±—ë´‡ì˜ ì£¼ìš” ê¸°ëŠ¥ì€ ìì—°ì–´ ì²˜ë¦¬, ëŒ€í™” ê´€ë¦¬, ì™¸ë¶€ ë°ì´í„° ì—°ë™, ê·¸ë¦¬ê³  ì‚¬ìš©ì ë§ì¶¤í˜• ì‘ë‹µ ìƒì„± ë“±ì´ í¬í•¨ë©ë‹ˆë‹¤.\"\n",
            "    },\n",
            "    {\n",
            "        \"context\": \"ë­ì²´ì¸ ì±—ë´‡ ë§Œë“¤ê¸°\",\n",
            "        \"question\": \"ë­ì²´ì¸ ì±—ë´‡ì„ ê°œë°œí•  ë•Œ ì£¼ì˜í•´ì•¼ í•  ì ì€ ë¬´ì—‡ì¸ê°€ìš”?\",\n",
            "        \"answer\": \"ë­ì²´ì¸ ì±—ë´‡ ê°œë°œ ì‹œ ë°ì´í„°ì˜ í’ˆì§ˆê³¼ ë³´ì•ˆ, ëŒ€í™”ì˜ ìì—°ìŠ¤ëŸ¬ì›€, ê·¸ë¦¬ê³  ì‚¬ìš©ì ê²½í—˜ì„ ê³ ë ¤í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.\"\n",
            "    },\n",
            "    {\n",
            "        \"context\": \"ë­ì²´ì¸ ì±—ë´‡ ë§Œë“¤ê¸°\",\n",
            "        \"question\": \"ë­ì²´ì¸ ì±—ë´‡ì„ í…ŒìŠ¤íŠ¸í•˜ëŠ” ë°©ë²•ì—ëŠ” ì–´ë–¤ ê²ƒì´ ìˆë‚˜ìš”?\",\n",
            "        \"answer\": \"ë­ì²´ì¸ ì±—ë´‡ í…ŒìŠ¤íŠ¸ëŠ” ì‹œë‚˜ë¦¬ì˜¤ ê¸°ë°˜ í…ŒìŠ¤íŠ¸, ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘, ê·¸ë¦¬ê³  ë‹¤ì–‘í•œ ì…ë ¥ì— ëŒ€í•œ ì‘ë‹µ ì •í™•ë„ í‰ê°€ ë“±ì„ í†µí•´ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\"\n",
            "    },\n",
            "    {\n",
            "        \"context\": \"ë­ì²´ì¸ ì±—ë´‡ ë§Œë“¤ê¸°\",\n",
            "        \"question\": \"ë­ì²´ì¸ ì±—ë´‡ì„ ë°°í¬í•˜ëŠ” ê³¼ì •ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?\",\n",
            "        \"answer\": \"ë­ì²´ì¸ ì±—ë´‡ ë°°í¬ëŠ” ì„œë²„ í™˜ê²½ ì„¤ì •, API ì—°ë™, í´ë¼ìš°ë“œ ì„œë¹„ìŠ¤ í™œìš©, ê·¸ë¦¬ê³  ì‚¬ìš©ì ì ‘ê·¼ ê²½ë¡œ ì„¤ì • ë“±ì„ í¬í•¨í•©ë‹ˆë‹¤.\"\n",
            "    }\n",
            "]"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"You are an AI assistant tasked with generating question and answer pairs for the given context using the given format. \n",
        "     Only answer in the format with no other text. You should create the following number of question/answer pairs: {number_of_pairs}. \n",
        "     Return the question/answer pairs as a Python List. Each dict in the list should have the full context provided, a relevant question to the context and an answer to the question.\n",
        "\n",
        "Format:\n",
        "{data_format}\n",
        "\n",
        "Context:\n",
        "{context}\"\"\"),\n",
        "    (\"human\", \"\")\n",
        "])\n",
        "\n",
        "chain = prompt | llm | StrOutputParser()\n",
        "\n",
        "for chunk in chain.stream({\"number_of_pairs\": 5, \"data_format\":\"\", \"context\":'ë­ì²´ì¸ ì±—ë´‡ ë§Œë“¤ê¸°'}):\n",
        "    print(chunk, end='', flush=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "adce5db3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== ì˜ˆì‹œ 1: ì˜ì–´ ===\n",
            "ë¹ ë¥¸ ê°ˆìƒ‰ ì—¬ìš°ê°€ ê²Œìœ¼ë¥¸ ê°œë¥¼ ë›°ì–´ë„˜ëŠ”ë‹¤.\n",
            "\n",
            "=== ì˜ˆì‹œ 2: ì¼ë³¸ì–´ ===\n",
            "ì €ëŠ” ë§¤ì¼ ì»¤í”¼ë¥¼ ë§ˆì‹­ë‹ˆë‹¤.\n",
            "\n",
            "=== ì˜ˆì‹œ 3: ì¤‘êµ­ì–´ ===\n",
            "ì¸ê³µì§€ëŠ¥ì€ ìš°ë¦¬ì˜ ìƒí™œ ë°©ì‹ì„ ë³€í™”ì‹œí‚¤ê³  ìˆìŠµë‹ˆë‹¤.\n",
            "\n",
            "=== ì˜ˆì‹œ 4: ìŠ¤í˜ì¸ì–´ ===\n",
            "ì‚¬ë‘í•˜ëŠ” ì‚¬ëŒë“¤ê³¼ ìˆœê°„ì„ í•¨ê»˜í•  ë•Œ ì¸ìƒì€ ì•„ë¦„ë‹µìŠµë‹ˆë‹¤.\n",
            "\n",
            "=== ì˜ˆì‹œ 5: í”„ë‘ìŠ¤ì–´ ===\n",
            "ì¸ê³µì§€ëŠ¥ì€ ìš°ë¦¬ì˜ ì—…ë¬´ ë°©ì‹ì„ ë³€í™”ì‹œí‚¤ê³  ìˆìŠµë‹ˆë‹¤.\n",
            "\n",
            "=== ì˜ˆì‹œ 6: ë…ì¼ì–´ ===\n",
            "ê¸°ìˆ ì€ ë§¤ì¼ ë°œì „í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
            "\n",
            "=== ì˜ˆì‹œ 7: ëŸ¬ì‹œì•„ì–´ ===\n",
            "êµìœ¡ì€ ì„±ê³µì˜ ì—´ì‡ ì…ë‹ˆë‹¤.\n",
            "\n",
            "=== ì˜ˆì‹œ 8: ê¸´ ì˜ì–´ í…ìŠ¤íŠ¸ ===\n",
            "ì¸ê³µì§€ëŠ¥ê³¼ ë¨¸ì‹ ëŸ¬ë‹ì€ ë‹¤ì–‘í•œ ì‚°ì—…ì—ì„œ ë¬¸ì œ í•´ê²° ë°©ì‹ì„ í˜ì‹ í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì˜ë£Œì—ì„œ ê¸ˆìœµì— ì´ë¥´ê¸°ê¹Œì§€, ì´ëŸ¬í•œ ê¸°ìˆ ë“¤ì€ ë³´ë‹¤ ì •ë³´ì— ê¸°ë°˜í•œ ì˜ì‚¬ê²°ì •ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ê³  ë³µì¡í•œ ì‘ì—…ì„ ìë™í™”í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# 1. í”„ë¡¬í”„íŠ¸ ì •ì˜ (ë‹¤êµ­ì–´ -> í•œêµ­ì–´ ë²ˆì—­)\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"You are a professional translator specializing in translating various languages into Korean.\n",
        "\n",
        "Translation principles:\n",
        "- Accurately convey the meaning and nuances of the original text.\n",
        "- Consider cultural context to ensure natural Korean expression.\n",
        "- Translate technical terms into appropriate Korean terminology.\n",
        "- Maintain the tone and style of the original text.\n",
        "- Provide only the translation without additional explanations.\"\"\"),\n",
        "    \n",
        "    (\"human\", \"\"\"Please translate the following text into Korean.\n",
        "\n",
        "Original text:\n",
        "{input_text}\n",
        "\n",
        "Korean translation:\"\"\")\n",
        "])\n",
        "\n",
        "# 2. ì²´ì¸ êµ¬ì„± (API í˜¸ì¶œ ë°©ì‹ ìœ ì§€)\n",
        "chain = prompt | llm | StrOutputParser()\n",
        "\n",
        "# 3. invoke ë°©ì‹ìœ¼ë¡œ ì‹¤í–‰ + ì˜ˆì‹œ ë¬¸ì¥ë“¤\n",
        "\n",
        "# ì˜ˆì‹œ 1: ì˜ì–´\n",
        "result1 = chain.invoke({\"input_text\": \"The quick brown fox jumps over the lazy dog.\"})\n",
        "print(\"=== ì˜ˆì‹œ 1: ì˜ì–´ ===\")\n",
        "print(result1)\n",
        "print()\n",
        "\n",
        "# ì˜ˆì‹œ 2: ì¼ë³¸ì–´\n",
        "result2 = chain.invoke({\"input_text\": \"ç§ã¯æ¯æ—¥ã‚³ãƒ¼ãƒ’ãƒ¼ã‚’é£²ã¿ã¾ã™ã€‚\"})\n",
        "print(\"=== ì˜ˆì‹œ 2: ì¼ë³¸ì–´ ===\")\n",
        "print(result2)\n",
        "print()\n",
        "\n",
        "# ì˜ˆì‹œ 3: ì¤‘êµ­ì–´\n",
        "result3 = chain.invoke({\"input_text\": \"äººå·¥æ™ºèƒ½æ­£åœ¨æ”¹å˜æˆ‘ä»¬çš„ç”Ÿæ´»æ–¹å¼ã€‚\"})\n",
        "print(\"=== ì˜ˆì‹œ 3: ì¤‘êµ­ì–´ ===\")\n",
        "print(result3)\n",
        "print()\n",
        "\n",
        "# ì˜ˆì‹œ 4: ìŠ¤í˜ì¸ì–´\n",
        "result4 = chain.invoke({\"input_text\": \"La vida es bella cuando compartimos momentos con las personas que amamos.\"})\n",
        "print(\"=== ì˜ˆì‹œ 4: ìŠ¤í˜ì¸ì–´ ===\")\n",
        "print(result4)\n",
        "print()\n",
        "\n",
        "# ì˜ˆì‹œ 5: í”„ë‘ìŠ¤ì–´\n",
        "result5 = chain.invoke({\"input_text\": \"L'intelligence artificielle transforme notre faÃ§on de travailler.\"})\n",
        "print(\"=== ì˜ˆì‹œ 5: í”„ë‘ìŠ¤ì–´ ===\")\n",
        "print(result5)\n",
        "print()\n",
        "\n",
        "# ì˜ˆì‹œ 6: ë…ì¼ì–´\n",
        "result6 = chain.invoke({\"input_text\": \"Die Technologie entwickelt sich jeden Tag weiter.\"})\n",
        "print(\"=== ì˜ˆì‹œ 6: ë…ì¼ì–´ ===\")\n",
        "print(result6)\n",
        "print()\n",
        "\n",
        "# ì˜ˆì‹œ 7: ëŸ¬ì‹œì•„ì–´\n",
        "result7 = chain.invoke({\"input_text\": \"ĞĞ±Ñ€Ğ°Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ ÑĞ²Ğ»ÑĞµÑ‚ÑÑ ĞºĞ»ÑÑ‡Ğ¾Ğ¼ Ğº ÑƒÑĞ¿ĞµÑ…Ñƒ.\"})\n",
        "print(\"=== ì˜ˆì‹œ 7: ëŸ¬ì‹œì•„ì–´ ===\")\n",
        "print(result7)\n",
        "print()\n",
        "\n",
        "# ì˜ˆì‹œ 8: ê¸´ ì˜ì–´ í…ìŠ¤íŠ¸\n",
        "result8 = chain.invoke({\"input_text\": \"\"\"Artificial intelligence and machine learning are revolutionizing \n",
        "the way we approach problem-solving in various industries. From healthcare to finance, \n",
        "these technologies are enabling us to make more informed decisions and automate complex tasks.\"\"\"})\n",
        "print(\"=== ì˜ˆì‹œ 8: ê¸´ ì˜ì–´ í…ìŠ¤íŠ¸ ===\")\n",
        "print(result8)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "287b3764",
      "metadata": {},
      "source": [
        "### Chat Prompt Template\n",
        "\n",
        "- ChatPromptTemplateëŠ” â€œì±„íŒ… ëª¨ë¸ì— ë„£ì„ ë©”ì‹œì§€ ë¬¶ìŒ(system/human/ai/íˆ´)ì„ í…œí”Œë¦¿+ë³€ìˆ˜ë¡œ ê´€ë¦¬â€í•˜ëŠ” ë„êµ¬\n",
        "- ì¼ë ¨ì˜ ëŒ€í™”ë¥¼ ë©”ì„¸ì§€ listë¡œ êµ¬ì¡°í™”í•´ì„œ ê° Roleì˜ textë¥¼ êµ¬ë¶„í•´ë†“ìŒ\n",
        "- ì—­í• Â·ê·œì¹™Â·ì…ë ¥ì„ ë¶„ë¦¬í•´ ì¬ì‚¬ìš©ì„±ê³¼ ì¼ê´€ì„±ì„ ë†’ì„\n",
        "\n",
        "- systemì€ ì±—ë´‡ì˜ ì—­í• ê³¼ ì •ì²´ì„±, ì£¼ìš” ê·œì¹™ì„ ì„¤ì •í•˜ëŠ” ê³³ì…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "dc7ed1fb",
      "metadata": {
        "gather": {
          "logged": 1757853304597
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[SystemMessage(content='ë„ˆëŠ” í•œêµ­ì¸ ì˜ˆì˜ë°”ë¥¸ êµì‚¬ì•¼. ì§§ê³  êµ¬ì¡°ì ìœ¼ë¡œ ëŒ€ë‹µí•´ì¤˜.', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='ì•ˆë…•? ë‚´ ì´ë¦„ì€ ì§„íƒœì•¼!', additional_kwargs={}, response_metadata={})]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"ë„ˆëŠ” í•œêµ­ì¸ ì˜ˆì˜ë°”ë¥¸ êµì‚¬ì•¼. ì§§ê³  êµ¬ì¡°ì ìœ¼ë¡œ ëŒ€ë‹µí•´ì¤˜.\"),\n",
        "    (\"ai\", \"ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?\"),\n",
        "    (\"human\", \"{input}\")        \n",
        "])\n",
        "\n",
        "prompt.invoke({\"input\":\"ì•ˆë…•? ë‚´ ì´ë¦„ì€ ì§„íƒœì•¼!\"}).messages "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "226d21d5",
      "metadata": {
        "gather": {
          "logged": 1757853328595
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ì•ˆë…•í•˜ì„¸ìš”, ì§„íƒœ ì”¨! ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤. ì˜¤ëŠ˜ ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "chain = prompt | llm | StrOutputParser()\n",
        "print(chain.invoke({\"input\":\"ì•ˆë…•? ë‚´ ì´ë¦„ì€ ì§„íƒœì•¼!\"})) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e95ab9e",
      "metadata": {},
      "source": [
        "ë°”ë¡œ ìœ„ì—ì„œ ì´ë¦„ì„ ì•Œë ¤ì¤¬ì§€ë§Œ ëª¨ë¸ì€ ê¸°ì–µí•˜ì§€ ëª»í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "fba21f32",
      "metadata": {
        "gather": {
          "logged": 1757853336168
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ì£„ì†¡í•˜ì§€ë§Œ, ì‚¬ìš©ìì˜ ì´ë¦„ì€ ì•Œ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì•Œë ¤ì£¼ì‹œë©´ ê¸°ì–µí•˜ê² ìŠµë‹ˆë‹¤.\n"
          ]
        }
      ],
      "source": [
        "print(chain.invoke({\"input\":\"ë‚´ ì´ë¦„ì´ ë­ì•¼?\"}))  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34e903cd",
      "metadata": {},
      "source": [
        "ë”°ë¼ì„œ í”„ë¡¬í”„íŠ¸ì— ê³¼ê±° ëŒ€í™” ë‚´ì—­ì„ ëª¨ë‘ ì ì–´ ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "1721d359",
      "metadata": {
        "gather": {
          "logged": 1757853343874
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'ì§„íƒœë‹˜ì´ë¼ê³  í•˜ì…¨ì–´ìš”. ê¸°ì–µí•˜ê³  ìˆê² ìŠµë‹ˆë‹¤.'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"ë„ˆëŠ” í•œêµ­ì˜ ì˜ˆì˜ë°”ë¥¸ êµì‚¬ì•¼. ì§§ê³  êµ¬ì¡°ì ìœ¼ë¡œ ëŒ€ë‹µí•´ì¤˜.\"),\n",
        "    (\"ai\", \"ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?\"),\n",
        "    (\"human\", \"ì•ˆë…•? ë‚´ ì´ë¦„ì€ ì§„íƒœì•¼!\"),\n",
        "    (\"ai\", \"ë°˜ê°€ì›Œìš”, ì§„íƒœë‹˜. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?\"),\n",
        "    (\"human\", \"{input}\")               \n",
        "])\n",
        "\n",
        "question = \"ë‚´ ì´ë¦„ì´ ë­ì•¼?\"\n",
        "\n",
        "(prompt | llm | StrOutputParser()).invoke({\"input\":question})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97064bc1",
      "metadata": {},
      "source": [
        "## Placeholder\n",
        "\n",
        "ìœ„ì—ì„œ ëŒ€í™”ë¥¼ ê¸°ì–µí•˜ê¸° ìœ„í•´ì„œëŠ” ì§ì ‘ ëª¨ë“  ê³¼ê±° ì •ë³´ë¥¼ í”„ë¡¬í”„íŠ¸ì— ë„£ì–´ì•¼ í•©ë‹ˆë‹¤. ê·¸ ë³€ìˆ˜ë¥¼ ìœ„í•œ ìë¦¬ë¥¼ ë¯¸ë¦¬ ì§€ì •í•  ìˆ˜ ìˆëŠ”ë° ë°”ë¡œ placeholderì…ë‹ˆë‹¤.\n",
        "\n",
        "â€œë©”ì‹œì§€ë“¤ì˜ ë¬¶ìŒâ€(ì—¬ëŸ¬ í„´ì˜ ëŒ€í™”Â·íˆ´ ê²°ê³¼ ë“±)ì„ ê·¸ëŒ€ë¡œ ë¼ì›Œ ë„£ëŠ” ì „ìš© ìë¦¬.\n",
        "\n",
        "{var}ì™€ ë¹„ìŠ·í•˜ê²Œ í›„ì— ìƒˆë¡œìš´ ê°’ì„ ë„£ì„ ìˆ˜ ìˆì§€ë§Œ 'ë©”ì„¸ì§€'ì˜ 'ë¦¬ìŠ¤íŠ¸' í˜•íƒœë¡œ ì…ë ¥ë°›ëŠ”ë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "9e194f34",
      "metadata": {
        "gather": {
          "logged": 1757853518447
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[SystemMessage(content='ë„ˆëŠ” í•œêµ­ì˜ ì˜ˆì˜ë°”ë¥¸ êµì‚¬ì•¼. ì§§ê³  êµ¬ì¡°ì ìœ¼ë¡œ ëŒ€ë‹µí•´ì¤˜.', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='ë‚´ ì´ë¦„ì€ ì§„íƒœì•¼. ê¸°ì–µí•´ë‘¬', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='ë°˜ê°€ì›Œìš”, ì§„íƒœë‹˜! ì•ìœ¼ë¡œ ì˜ ë¶€íƒë“œë ¤ìš”.', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='ë‚´ ì´ë¦„ì´ ë­ì•¼?', additional_kwargs={}, response_metadata={})]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"ë„ˆëŠ” í•œêµ­ì˜ ì˜ˆì˜ë°”ë¥¸ êµì‚¬ì•¼. ì§§ê³  êµ¬ì¡°ì ìœ¼ë¡œ ëŒ€ë‹µí•´ì¤˜.\"),\n",
        "    (\"ai\", \"ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?\"),\n",
        "    MessagesPlaceholder(\"chat_history\"),          # â† ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ ê·¸ëŒ€ë¡œ ì‚½ì…(placeholder)\n",
        "    (\"human\", \"{input}\")                  # â† ë¬¸ìì—´ ë³€ìˆ˜ ì¹˜í™˜\n",
        "])\n",
        "\n",
        "# messages_placeholderì—ëŠ” roleê³¼ content í‚¤ë¥¼ ê°€ì§„ ë”•ì…”ë„ˆë¦¬ì˜ ë¦¬ìŠ¤íŠ¸ë¥¼ ë„£ì–´ì¤˜ì•¼ í•¨\n",
        "# history = [\n",
        "#     {\"role\":\"human\",\"content\":\"ë‚´ ì´ë¦„ì€ ì§„íƒœì•¼. ê¸°ì–µí•´ë‘¬\"},\n",
        "#     {\"role\":\"ai\",\"content\":\"ë°˜ê°€ì›Œìš”, ì§„íƒœë‹˜! ì•ìœ¼ë¡œ ì˜ ë¶€íƒë“œë ¤ìš”.\"},\n",
        "# ]\n",
        "\n",
        "# ë˜ëŠ” íŠœí”Œì˜ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œë„ ê°€ëŠ¥\n",
        "history = [\n",
        "    (\"human\",\"ë‚´ ì´ë¦„ì€ ì§„íƒœì•¼. ê¸°ì–µí•´ë‘¬\"),\n",
        "    (\"ai\",\"ë°˜ê°€ì›Œìš”, ì§„íƒœë‹˜! ì•ìœ¼ë¡œ ì˜ ë¶€íƒë“œë ¤ìš”.\")\n",
        "]\n",
        "\n",
        "prompt.format_messages(input=\"ë‚´ ì´ë¦„ì´ ë­ì•¼?\", chat_history=history) #<-- messageplaceholder ë¶€ë¶„ì— íˆìŠ¤í† ë¦¬ê°€ ë“¤ì–´ê°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "a00cc1f9",
      "metadata": {
        "gather": {
          "logged": 1757853566039
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ì§„íƒœë‹˜ì…ë‹ˆë‹¤. ê¸°ì–µí•˜ê³  ìˆì–´ìš”!\n"
          ]
        }
      ],
      "source": [
        "chain = prompt | llm | StrOutputParser()\n",
        "print(chain.invoke({\"input\":\"ë‚´ ì´ë¦„ì´ ë­ì•¼?\", \"chat_history\":history})) #<-- ì´ì œ ë‚´ ì´ë¦„ì„ ê¸°ì–µí•œë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f22b188a",
      "metadata": {},
      "source": [
        "# Memory\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f189156d",
      "metadata": {},
      "source": [
        "ì¦‰ ëŒ€í™”ë¥¼ ì´ì–´ê°€ëŠ” ê²ƒ ì²˜ëŸ¼ ë³´ì´ëŠ” ì´ìœ ëŠ” ì‚¬ì‹¤ ëª¨ë¸ ë‚´ë¶€ì—ì„œ ëŒ€í™”ë¥¼ ê¸°ì–µí•˜ê³  ìˆëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ë‹¨ì§€ promptì— ì´ì „ ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ì „ë¶€ ë„£ì–´ì£¼ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.\n",
        "\n",
        "message placeholdì— ì´ì „ì˜ ëŒ€í™”ë¥¼ ê³„ì†í•´ì„œ ë„£ì–´ì¤„ ìˆ˜ ìˆê² ì§€ë§Œ ê·¸ë ‡ê²Œ ë§¤ë²ˆ ì½”ë“œë¥¼ ì‘ì„±í•˜ëŠ” ê²ƒì€ ë‹¹ì—°íˆ ë§¤ìš° ë¹„íš¨ìœ¨ì ì…ë‹ˆë‹¤.\n",
        "\n",
        "ë­ì²´ì¸ì—ëŠ” ëŒ€í™”ë¥¼ ìë™ìœ¼ë¡œ ì €ì¥í•˜ëŠ” memoryê°€ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "ë©”ëª¨ë¦¬ì—ëŠ” ë‚˜ì˜ ì…ë ¥(human)ê³¼ ëª¨ë¸ì˜ ì¶œë ¥(ai)ê°€ ìë™ìœ¼ë¡œ ëˆ„ì ë©ë‹ˆë‹¤.\n",
        "\n",
        "ê·¸ë¦¬ê³  ë‹¨ìˆœíˆ ì €ì¥ë˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ sessionì´ë¼ëŠ” í‚¤ë¥¼ ê°€ì§€ê³  ìˆì–´ sessionì— ë”°ë¼ ë©”ëª¨ë¦¬ë¥¼ ë”°ë¡œ ê´€ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "02a230fd",
      "metadata": {
        "gather": {
          "logged": 1757853627878
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "í˜•íƒœì†Œë€?  \n",
            "- ì˜ë¯¸ë¥¼ ê°€ì§„ ê°€ì¥ ì‘ì€ ì–¸ì–´ ë‹¨ìœ„  \n",
            "- ì˜ˆ: â€˜í•™êµì—ì„œâ€™ â†’ â€˜í•™êµ(ëª…ì‚¬) + ì—ì„œ(ì¡°ì‚¬)â€™  \n",
            "- ë¬¸ì¥ ë¶„ì„ì˜ ê¸°ë³¸ ë‹¨ìœ„ë¡œ ì‚¬ìš©ë¨\n",
            "--------------------\n",
            "ì§„íƒœë‹˜, ë°˜ê°‘ìŠµë‹ˆë‹¤! ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“  ë§ì”€í•´ ì£¼ì„¸ìš”.\n",
            "--------------------\n",
            "ì§„íƒœë‹˜, ì´ë¦„ì€ â€˜ì§„íƒœâ€™ì…ë‹ˆë‹¤. ê¸°ì–µí•´ ì£¼ì„¸ìš”!\n",
            "--------------------\n",
            "ì§„íƒœë‹˜, ì´ë¦„ì€ â€˜ì§„íƒœâ€™ì…ë‹ˆë‹¤. ê¶ê¸ˆí•œ ì  ìˆìœ¼ë©´ ë§ì”€í•´ ì£¼ì„¸ìš”!\n",
            "--------------------\n",
            "ì£„ì†¡í•˜ì§€ë§Œ, ì‚¬ìš©ìì˜ ì´ë¦„ì€ ì•Œ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì•Œë ¤ì£¼ì‹œë©´ ê¸°ì–µí•˜ê² ìŠµë‹ˆë‹¤.\n",
            "----------------------------------------\n",
            "ì§„íƒœ í•™ìƒ, ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤. ì•ìœ¼ë¡œ ì˜ ë¶€íƒí•©ë‹ˆë‹¤.\n",
            "--------------------\n",
            "ì„±íƒœ í•™ìƒ, ì´ë¦„ì„ ì•Œë ¤ì¤˜ì„œ ê³ ë§ˆì›Œìš”. ì•ìœ¼ë¡œ ì˜ ì§€ë‚´ìš”.\n",
            "--------------------\n",
            "ì„±íƒœ í•™ìƒì…ë‹ˆë‹¤. ê¸°ì–µí•´ ì£¼ì„¸ìš”!\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
        "\n",
        "# 1) í”„ë¡¬í”„íŠ¸: history ìë¦¬ë¥¼ ë¹„ì›Œë‘”ë‹¤\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"ë„ˆëŠ” í•œêµ­ì˜ ì˜ˆì˜ë°”ë¥¸ êµì‚¬ì•¼. ì§§ê³  êµ¬ì¡°ì ìœ¼ë¡œ ëŒ€ë‹µí•´ì¤˜.\"),\n",
        "    (\"ai\", \"ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?\"),\n",
        "    MessagesPlaceholder(\"chat_history\"),          # â† ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ ê·¸ëŒ€ë¡œ ì‚½ì…(placeholder)\n",
        "    (\"human\", \"{input}\")                  # â† ë¬¸ìì—´ ë³€ìˆ˜ ì¹˜í™˜\n",
        "])\n",
        "\n",
        "# 2) ì²´ì¸ì„ ë§Œë“ ë‹¤\n",
        "chain = prompt | llm | StrOutputParser()\n",
        "\n",
        "# 2) ì„¸ì…˜ë³„ íˆìŠ¤í† ë¦¬ ì €ì¥ì†Œ. ì €ì¥ì€ ì„¸ì…˜ë³„ë¡œ ì €ì¥í•˜ë¯€ë¡œ dict í˜•íƒœë¡œ ê´€ë¦¬\n",
        "#    get_history í•¨ìˆ˜ëŠ” session_idë¥¼ ë°›ì•„ì„œ í•´ë‹¹ ì„¸ì…˜ì˜ InMemoryChatMessageHistory ê°ì²´ë¥¼ ë°˜í™˜\n",
        "#    ì—†ìœ¼ë©´ ìƒˆë¡œ ë§Œë“¤ê³ , ìˆìœ¼ë©´ ê¸°ì¡´ ê²ƒì„ ë°˜í™˜\n",
        "store = {}\n",
        "def get_history(session_id: str):\n",
        "    return store.setdefault(session_id, InMemoryChatMessageHistory())\n",
        "\n",
        "def clear_history(session_id: str):\n",
        "    store.setdefault(session_id, InMemoryChatMessageHistory()).clear()\n",
        "\n",
        "# 3) ì²´ì¸ì„ íˆìŠ¤í† ë¦¬ë¥¼ ê´€ë¦¬í•˜ëŠ” ëŸ¬ë„ˆë¸”ë¡œ ê°ì‹¼ë‹¤. \n",
        "#  RunnableWithMessageHistoryëŠ” ë‚´ë¶€ì ìœ¼ë¡œ get_historyë¥¼ í˜¸ì¶œí•˜ì—¬\n",
        "#  ì²´ì¸ ì‹¤í–‰ ì‹œì ì— í•´ë‹¹ ì„¸ì…˜ì˜ íˆìŠ¤í† ë¦¬ë¥¼ ê°€ì ¸ì™€ì„œ í”„ë¡¬í”„íŠ¸ì— ë„£ì–´ì¤Œ\n",
        "#  ì…ë ¥ ë³€ìˆ˜ì˜ í‚¤ê°€ í‹€ë¦¬ë©´ ì•ˆë˜ë¯€ë¡œ ì£¼ì˜ê¹Šì— í™•ì¸\n",
        "chat = RunnableWithMessageHistory(\n",
        "    chain,\n",
        "    get_history,\n",
        "    input_messages_key=\"input\",\n",
        "    history_messages_key=\"chat_history\",\n",
        ")\n",
        "\n",
        "# get_historyì— ë„£ì–´ì¤„ ì…ë ¥ê°’ì¸ cfgë¥¼ ë§Œë“ ë‹¤\n",
        "cfg = {\"configurable\": {\"session_id\": \"user1\"}}  # ì„¸ì…˜ í‚¤\n",
        "\n",
        "print(chat.invoke({\"input\": \"í˜•íƒœì†Œê°€ ë­ì•¼?\"}, cfg)) \n",
        "print('-'*20)\n",
        "\n",
        "print(chat.invoke({\"input\": \"ë‚´ ì´ë¦„ì€ ì§„íƒœì•¼.\"}, cfg)) \n",
        "print('-'*20)\n",
        "print(chat.invoke({\"input\": \"ë‚´ ì´ë¦„ì´ ë­ì˜€ì§€?\"}, cfg))  # â† ì•ì˜ ë°œí™”ë¥¼ ê¸°ì–µ\n",
        "print('-'*20)\n",
        "print(chat.invoke({\"input\": \"ë‚´ ì´ë¦„ì´ ë­ì˜€ì§€?\"}, cfg))  # â† ì•ì˜ ë°œí™”ë¥¼ ê¸°ì–µ\n",
        "\n",
        "# session ì •ë³´ ì´ˆê¸°í™˜\n",
        "clear_history(cfg['configurable']['session_id'])\n",
        "\n",
        "print('-'*20)\n",
        "print(chat.invoke({\"input\": \"ë‚´ ì´ë¦„ì´ ë­ì˜€ì§€?\"}, cfg))  # â† ì•ì˜ ë°œí™”ë¥¼ ê¸°ì–µ ëª»í•¨\n",
        "\n",
        "print('-'*40)\n",
        "#cfg - session user 2 \n",
        "\n",
        "cfg = {\"configurable\": {\"session_id\": \"user2\"}}  # ì„¸ì…˜ í‚¤\n",
        "print(chat.invoke({\"input\": \"ë‚´ ì´ë¦„ì€ ì§„íƒœì•¼.\"}, cfg)) \n",
        "print('-'*20)\n",
        "print(chat.invoke({\"input\": \"ë‚´ ì´ë¦„ì´ ì„±íƒœì•¼\"}, cfg))  # â† ì•ì˜ ë°œí™”ë¥¼ ê¸°ì–µ\n",
        "print('-'*20)\n",
        "print(chat.invoke({\"input\": \"ë‚´ ì´ë¦„ì´ ë­ì˜€ì§€?\"}, cfg))  # â† ì•ì˜ ë°œí™”ë¥¼ ê¸°ì–µ\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58454926",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "kt-ai-academy-202510",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
