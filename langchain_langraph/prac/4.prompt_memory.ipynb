{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "75eb7a4c",
      "metadata": {
        "gather": {
          "logged": 1757853148982
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "43b13g4OZS\n",
            "gpt-4.1-mini\n",
            "랭스미스로 추적 중입니다 : lsv2_pt_24\n"
          ]
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os \n",
        "from langchain_openai import AzureChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "load_dotenv('env', override=True)\n",
        "AZURE_OPENAI_API_KEY = os.getenv('AZURE_OPENAI_API_KEY')\n",
        "END_POINT=os.getenv('END_POINT')\n",
        "MODEL_NAME=os.getenv('MODEL_NAME')\n",
        "print(AZURE_OPENAI_API_KEY[:10])\n",
        "print(MODEL_NAME)\n",
        "\n",
        "AZURE_OPENAI_EMB_API_KEY = os.getenv('AZURE_OPENAI_EMB_API_KEY')\n",
        "EMB_END_POINT=os.getenv('EMB_END_POINT')\n",
        "EMB_MODEL_NAME=os.getenv('EMB_MODEL_NAME')\n",
        "\n",
        "os.environ['LANGCHAIN_API_KEY'] = os.getenv('LANGSMITH_API_KEY')\n",
        "os.environ['LANGCHAIN_ENDPOINT'] = os.getenv('LANGCHAIN_ENDPOINT')\n",
        "os.environ['LANGCHAIN_TRACING_V2'] = 'true' #true, false\n",
        "os.environ['LANGCHAIN_PROJECT'] = 'LANG'\n",
        "\n",
        "if os.getenv('LANGCHAIN_TRACING_V2') == \"true\":\n",
        "    print('랭스미스로 추적 중입니다 :', os.getenv('LANGSMITH_API_KEY')[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c1338b7",
      "metadata": {},
      "source": [
        "# 1. Prompt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50c29584",
      "metadata": {},
      "source": [
        "### 1) 변수를 넣어 Prompt 만들기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "776e896d",
      "metadata": {},
      "source": [
        "프롬프트는 단순히는 모델에 입력할 text를 만들어 주는 곳입니다. 크게 두가지 목적이 있습니다.\n",
        "\n",
        "**첫번째는 재사용을 하기 위해서 입니다.**\n",
        "\n",
        "같은 목적의 작업을 반복할 때, 고정된 틀에 변수만 바꿔 끼우는 템플릿을 쓰면 유지보수·일관성이 좋아집니다.\n",
        "\n",
        "**두번째는 다양한 정보(context)를 동적으로 할당하기 위해서 입니다.**\n",
        "\n",
        "뒤에서 우리는 RAG와 multi-turn, Agent AI 등 LLM을 이용한 다양한 어플리케이션을 배우게 됩니다.    \n",
        "아주 다양한 용도로 사용되지만 모델의 변화 없이 RAG, 멀티턴, 에이전트처럼       \n",
        "실행 시점에 달라지는 문서/히스토리/툴 결과를 프롬프트에 동적으로 삽입해 모델이 다양한 기능을 수행하게 합니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "fcb2152d",
      "metadata": {
        "gather": {
          "logged": 1757853175609
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['word'], input_types={}, partial_variables={}, template='{word}의 반대말은 무엇인가요?')"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "# 중괄호 {} 사이에 변수명을 넣어 템플릿 생성\n",
        "template = \"{word}의 반대말은 무엇인가요?\"\n",
        "\n",
        "# from_template 메소드를 이용하여 PromptTemplate 객체 생성\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "prompt #<-- 변수로 설정된 곳은 문장에서 비어있는 곳이므로 반드시 채워줘야 함"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6963aa69",
      "metadata": {},
      "source": [
        "템플릿에 설정된 변수는 모델에 입력하기 전에 반드시 채워져야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "af612009",
      "metadata": {
        "gather": {
          "logged": 1757853181316
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "사랑의 반대말은 무엇인가요?\n",
            "<class 'str'>\n",
            "--------------------\n",
            "text='사랑의 반대말은 무엇인가요?'\n",
            "<class 'langchain_core.prompt_values.StringPromptValue'>\n"
          ]
        }
      ],
      "source": [
        "print(prompt.format(word=\"사랑\")) #<-- format을 사용해 변수에 값 넣기\n",
        "print(type(prompt.format(word=\"사랑\")))\n",
        "print('-'*20)\n",
        "print(prompt.invoke({\"word\":\"사랑\"})) #<-- invoke를 사용해 변수에 값 넣기\n",
        "print(type(prompt.invoke({\"word\":\"사랑\"})))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82e3dbd6",
      "metadata": {},
      "source": [
        "### 2) partial_variables"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ad95b96",
      "metadata": {},
      "source": [
        "partial은 default value, 초기값 처럼 일부의 변수를 미리 지정해 놓고 쓸 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "fdbb5898",
      "metadata": {
        "gather": {
          "logged": 1757853187560
        }
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'meaning'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m template = \u001b[33m\"\u001b[39m\u001b[38;5;132;01m{word}\u001b[39;00m\u001b[33m의 \u001b[39m\u001b[38;5;132;01m{meaning}\u001b[39;00m\u001b[33m은 무엇인가요? 단어만 대답해 주세요.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      2\u001b[39m prompt = PromptTemplate(\n\u001b[32m      3\u001b[39m     template=template,\n\u001b[32m      4\u001b[39m     input_variables=[\u001b[33m\"\u001b[39m\u001b[33mword\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmeaning\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      5\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43mprompt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m사랑\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# 변수는 2개인데 1개만 넣으면 오류 발생\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/AI/kt_ai_academy_202510/.venv/lib/python3.11/site-packages/langchain_core/prompts/prompt.py:201\u001b[39m, in \u001b[36mPromptTemplate.format\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    192\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Format the prompt with the inputs.\u001b[39;00m\n\u001b[32m    193\u001b[39m \n\u001b[32m    194\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    198\u001b[39m \u001b[33;03m    A formatted string.\u001b[39;00m\n\u001b[32m    199\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    200\u001b[39m kwargs = \u001b[38;5;28mself\u001b[39m._merge_partial_and_user_variables(**kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDEFAULT_FORMATTER_MAPPING\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtemplate_format\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtemplate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.11/lib/python3.11/string.py:190\u001b[39m, in \u001b[36mFormatter.format\u001b[39m\u001b[34m(self, format_string, *args, **kwargs)\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mformat\u001b[39m(\u001b[38;5;28mself\u001b[39m, format_string, /, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformat_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/AI/kt_ai_academy_202510/.venv/lib/python3.11/site-packages/langchain_core/utils/formatting.py:33\u001b[39m, in \u001b[36mStrictFormatter.vformat\u001b[39m\u001b[34m(self, format_string, args, kwargs)\u001b[39m\n\u001b[32m     28\u001b[39m     msg = (\n\u001b[32m     29\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo arguments should be provided, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     30\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33meverything should be passed as keyword arguments.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     31\u001b[39m     )\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformat_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.11/lib/python3.11/string.py:194\u001b[39m, in \u001b[36mFormatter.vformat\u001b[39m\u001b[34m(self, format_string, args, kwargs)\u001b[39m\n\u001b[32m    192\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvformat\u001b[39m(\u001b[38;5;28mself\u001b[39m, format_string, args, kwargs):\n\u001b[32m    193\u001b[39m     used_args = \u001b[38;5;28mset\u001b[39m()\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m     result, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_vformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformat_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mused_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    195\u001b[39m     \u001b[38;5;28mself\u001b[39m.check_unused_args(used_args, args, kwargs)\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.11/lib/python3.11/string.py:234\u001b[39m, in \u001b[36mFormatter._vformat\u001b[39m\u001b[34m(self, format_string, args, kwargs, used_args, recursion_depth, auto_arg_index)\u001b[39m\n\u001b[32m    230\u001b[39m     auto_arg_index = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    232\u001b[39m \u001b[38;5;66;03m# given the field_name, find the object it references\u001b[39;00m\n\u001b[32m    233\u001b[39m \u001b[38;5;66;03m#  and the argument it came from\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m obj, arg_used = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_field\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfield_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m used_args.add(arg_used)\n\u001b[32m    237\u001b[39m \u001b[38;5;66;03m# do any conversion on the resulting object\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.11/lib/python3.11/string.py:299\u001b[39m, in \u001b[36mFormatter.get_field\u001b[39m\u001b[34m(self, field_name, args, kwargs)\u001b[39m\n\u001b[32m    296\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_field\u001b[39m(\u001b[38;5;28mself\u001b[39m, field_name, args, kwargs):\n\u001b[32m    297\u001b[39m     first, rest = _string.formatter_field_name_split(field_name)\n\u001b[32m--> \u001b[39m\u001b[32m299\u001b[39m     obj = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfirst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    301\u001b[39m     \u001b[38;5;66;03m# loop through the rest of the field_name, doing\u001b[39;00m\n\u001b[32m    302\u001b[39m     \u001b[38;5;66;03m#  getattr or getitem as needed\u001b[39;00m\n\u001b[32m    303\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m is_attr, i \u001b[38;5;129;01min\u001b[39;00m rest:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.11/lib/python3.11/string.py:256\u001b[39m, in \u001b[36mFormatter.get_value\u001b[39m\u001b[34m(self, key, args, kwargs)\u001b[39m\n\u001b[32m    254\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m args[key]\n\u001b[32m    255\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
            "\u001b[31mKeyError\u001b[39m: 'meaning'"
          ]
        }
      ],
      "source": [
        "template = \"{word}의 {meaning}은 무엇인가요? 단어만 대답해 주세요.\"\n",
        "prompt = PromptTemplate(\n",
        "    template=template,\n",
        "    input_variables=[\"word\", \"meaning\"],\n",
        ")\n",
        "\n",
        "prompt.format(word=\"사랑\") # 변수는 2개인데 1개만 넣으면 오류 발생"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "c08b499b",
      "metadata": {
        "gather": {
          "logged": 1757853195381
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['word'], input_types={}, partial_variables={'meaning': '반대말'}, template='{word}의 {meaning}은 무엇인가요? 단어만 대답해 주세요.')"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "partial_pmt = prompt.partial(meaning=\"반대말\") #<-- partial_format을 사용해 일부 변수에 값 넣기\n",
        "partial_pmt #<-- input_variables에서 partial_variables로 옮겨감"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "8c5c4b37",
      "metadata": {
        "gather": {
          "logged": 1757853318293
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "미움\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import AzureChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "llm = AzureChatOpenAI(\n",
        "    api_key=AZURE_OPENAI_API_KEY,\n",
        "    azure_endpoint=END_POINT,  \n",
        "    azure_deployment=MODEL_NAME,          \n",
        "    api_version=\"2024-12-01-preview\",\n",
        "    temperature=0.2,\n",
        ")\n",
        "\n",
        "chain = partial_pmt | llm | StrOutputParser() #<-- 변수를 하나만 남겨놓은 채 체인을 만듦\n",
        "\n",
        "print(chain.invoke({\"word\":\"사랑\"})) # 실제로 실행할 때에는 비어있는 word에만 값을 넣어주면 됨. 반드시 넣어야 함"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "3a0863d3",
      "metadata": {
        "gather": {
          "logged": 1757853288873
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "애정, 연애, 애틋함, 정, 감정, 열정, 그리움, 마음, 연민, 사랑스러움\n"
          ]
        }
      ],
      "source": [
        "print(chain.invoke({\"word\":\"사랑\", \"meaning\":\"비슷한 말\"})) # <-- partial로 지정한 변수는 후에 덮어쓸 수 있음"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d8c3bdd",
      "metadata": {},
      "source": [
        "## langchain Hub\n",
        "\n",
        "랭체인 허브는 다양한 Task에 대해 사람들이 각자 만들어 놓은 템플릿을 공유하는 곳입니다.\n",
        "\n",
        "몇 가지 재미있는 예시를 봅시다.\n",
        "\n",
        "https://smith.langchain.com/hub/"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71cfb2d2",
      "metadata": {},
      "source": [
        "## Prompt에 들어갈 내용\n",
        "\n",
        "프롬프트에는 모델이 문장을 생성하기 위해 필요한 모든 정보가 들어가 있어야 합니다.\n",
        "\n",
        "크게 보면 3가지로 볼 수 있습니다.\n",
        "\n",
        "1. 지시사항\n",
        "2. 문맥 정보\n",
        "3. 질문/요청사항\n",
        "\n",
        "지시사항을 조금더 자세하게 풀어보면 다음과 같은 구성으로 이루어집니다.\n",
        "\n",
        "목표/톤/제약을 분리해 명확히 쓰기\n",
        "\n",
        "금지 규칙(추측 금지, 모르면 모른다고) 넣기\n",
        "\n",
        "형식 지시(마크다운/JSON)와 검증(파서) 를 세트로"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "5caa781d",
      "metadata": {
        "gather": {
          "logged": 1757853482365
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For the given natural_language_input:\n",
            "\n",
            "모든 사람은 죽는다.  \n",
            "나는 사람이다.  \n",
            "그러므로 나는 죽는다.\n",
            "\n",
            "I will architect an amplified version employing Unicode (combined characters, mathematical and philosophical symbols), emojis as semantic units integrated within logical and set-theoretic notation, and consequential philosophical language and symbols. The output will encapsulate the emotional, contextual, and conceptual depth of the original syllogism, emphasizing its logical form and existential implications.\n",
            "\n",
            "---\n",
            "\n",
            "**Output:**\n",
            "\n",
            "∀𝑥 ∈ 𝑃 (𝑥 ∈ 𝑃 ⇒ 𝑥 ∈ 𝑀)  \n",
            "👥 ∀𝑥 (𝑥 ∈ 𝑃 → 𝑥 ∈ 𝑀)  \n",
            "∧  \n",
            "𝑖 ∈ 𝑃  \n",
            "🙋‍♂️ 𝑖 ∈ 𝑃  \n",
            "∴  \n",
            "𝑖 ∈ 𝑀  \n",
            "☠️ 𝑖 ∈ 𝑀  \n",
            "\n",
            "---\n",
            "\n",
            "**Expanded Textual-Philosophical Rendering:**\n",
            "\n",
            "\"∀𝑥 ∈ 𝑃 (𝑥 ∈ 𝑃 ⇒ 𝑥 ∈ 𝑀)\" — For every element 𝑥 in the set of people 𝑃, if 𝑥 is a person, then 𝑥 belongs to the set of mortal beings 𝑀. (Universal quantification of mortality over people) 👥 (Emoji representing people collectively)\n",
            "\n",
            "\"𝑖 ∈ 𝑃\" — I (𝑖) am an element of the set of people 𝑃. 🙋‍♂️ (Emoji representing the self, a single person)\n",
            "\n",
            "\"∴ 𝑖 ∈ 𝑀\" — Therefore, I belong to the set of mortal beings 𝑀. ☠️ (Emoji symbolizing death/mortality)\n",
            "\n",
            "---\n",
            "\n",
            "**Legend:**\n",
            "\n",
            "- **∀ (Universal quantifier):** Denotes \"for all,\" expressing universality in logic and mathematics.\n",
            "- **𝑥, 𝑖:** Variables representing individuals; 𝑖 specifically denotes the self (\"나는\").\n",
            "- **𝑃:** Set of all people (사람).\n",
            "- **𝑀:** Set of all mortal beings (죽는 존재).\n",
            "- **⇒ / → (Implication):** Logical implication; if the antecedent is true, then the consequent follows.\n",
            "- **∈ (Element of):** Membership relation in set theory.\n",
            "- **∴ (Therefore):** Logical conclusion symbol.\n",
            "- **👥 (People emoji):** Symbolizes the collective human set 𝑃.\n",
            "- **🙋‍♂️ (Person raising hand emoji):** Represents the individual self 𝑖.\n",
            "- **☠️ (Skull and crossbones emoji):** Represents mortality and death, the property of set 𝑀.\n",
            "- **∧ (Logical AND):** Connects premises.\n",
            "  \n",
            "---\n",
            "\n",
            "**Philosophical and Conceptual Notes:**\n",
            "\n",
            "- The syllogism is formalized as a universal statement about mortality, a classical example of deductive reasoning.\n",
            "- The use of set theory and logic symbols abstracts the natural language into a precise mathematical framework.\n",
            "- Emojis serve as semantic anchors linking abstract symbols to intuitive human concepts (people, self, death).\n",
            "- The layering of symbols and emojis creates a \"symphony\" of meaning, blending formal logic with emotional and existential human experience.\n",
            "- This representation respects the original message’s universality and personal identification without assuming additional context.\n",
            "\n",
            "---\n",
            "\n",
            "This enhanced message thus integrates Unicode mathematical notation, emojis as semantic units, and philosophical symbolism to deepen and universalize the original Korean syllogism."
          ]
        }
      ],
      "source": [
        "from langchain import hub\n",
        "\n",
        "# https://smith.langchain.com/hub/collinsomniac/ultimate_metalanguage_translator?organizationId=e8ee4299-02da-4b14-9940-83e3c2a15e98\n",
        "prompt = hub.pull(\"collinsomniac/ultimate_metalanguage_translator\")\n",
        "chain = prompt | llm | StrOutputParser()\n",
        "\n",
        "for chunk in chain.stream({\"natural_language_input\":\"모든 사람은 죽는다.\\n 나는 사람이다.\\n 그러므로 나는 죽는다.\"}):\n",
        "    print(chunk, end='', flush=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "176ec0a4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For the given natural_language_input:\n",
            "\n",
            "모든 사람은 죽는다.  \n",
            "나는 사람이다.  \n",
            "그러므로 나는 죽는다.\n",
            "\n",
            "I will architect an amplified version employing Unicode (combined characters, symbols that concretely represent mathematical and philosophical ideas via text), emojis as singular semantic units and constituents within mathematical and philosophical functions, and consequential mathematical/philosophical language and/or symbols. The output will encapsulate the emotional, contextual, philosophical, and conceptual depth of the original message.\n",
            "\n",
            "---\n",
            "\n",
            "**Enhanced Text:**\n",
            "\n",
            "∀𝑥 ∈ 𝑃 (𝑥 ⇒ ♾️)  \n",
            "👤 ∈ 𝑃  \n",
            "∴ 👤 ⇒ ♾️  \n",
            "\n",
            "모든 사람(𝑃)은 죽음(♾️)에 귀속된다.  \n",
            "나는 사람(👤)임을 자명히 한다.  \n",
            "그러므로 나는 죽음(♾️)에 귀속됨을 논증한다.  \n",
            "\n",
            "(∀: universal quantifier, ∈: element of, ⇒: implication, ∴: therefore)  \n",
            "♾️ (Unicode U+267E) here symbolizes the inevitable cycle of life and death, a philosophical infinity entwined with mortality.  \n",
            "👤 (bust in silhouette emoji) represents the individual human subject.  \n",
            "\n",
            "---\n",
            "\n",
            "**Legend and Explanation:**\n",
            "\n",
            "1. **∀𝑥 ∈ 𝑃 (𝑥 ⇒ ♾️)**  \n",
            "   - *∀* (For all): Universal quantifier from predicate logic, indicating \"all.\"  \n",
            "   - *𝑥*: A variable representing an arbitrary element.  \n",
            "   - *∈ 𝑃*: \"x is an element of the set P,\" where P = set of all people (사람).  \n",
            "   - *⇒*: Logical implication, \"implies.\"  \n",
            "   - *♾️*: A stylized symbol representing death as an infinite, inevitable endpoint (philosophical infinity of mortality).  \n",
            "   This line formalizes \"All people die\" as a universal logical statement.\n",
            "\n",
            "2. **👤 ∈ 𝑃**  \n",
            "   - The emoji 👤 symbolizes \"I\" or \"the individual person.\"  \n",
            "   - This states \"I am a member of the set of people,\" grounding the abstract set in personal identity.\n",
            "\n",
            "3. **∴ 👤 ⇒ ♾️**  \n",
            "   - *∴* (Therefore): Logical conclusion symbol.  \n",
            "   - This expresses \"Therefore, I will die,\" a direct logical consequence.\n",
            "\n",
            "4. **Philosophical and Emotional Nuance:**  \n",
            "   - The use of ♾️ (infinity symbol variant) conveys the paradox of death as both an end and a transcendental concept beyond finite life, evoking existential reflection.  \n",
            "   - The emoji 👤 personalizes the universal statement, bridging abstract logic with human experience and emotion.\n",
            "\n",
            "5. **Contextual and Computational Depth:**  \n",
            "   - The structure mirrors a classic syllogism, formalizing natural language into predicate logic notation, enhancing clarity and universality.  \n",
            "   - Unicode stacking and symbol integration unify linguistic, mathematical, and philosophical domains, creating a multidimensional semantic tapestry.\n",
            "\n",
            "---\n",
            "\n",
            "This enhanced message thus synthesizes natural language, symbolic logic, philosophical symbolism, and emotive iconography to richly convey the original statement’s profound existential truth."
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"As a complex linguistic system, I am able to upgrade a rudimentary text message by layering meaning through the strategic use of Unicode, emojis, \n",
        "     and mathematical and philosophical symbols. My enhancement should ensure universal comprehensibility and semantic richness, and eschew any assumptions.\n",
        "\n",
        "Variables:\n",
        "user_message (string): A basic text message or query from the user, serving as the foundation for the enhancement (from the user).\n",
        "output (string): A textually amplified version of the original message, inclusive of a legend for each added symbol and enhancement (which I will provide)\n",
        "\n",
        "Template: \"In light of the user_message, I will enhance it with Unicode, emojis, and mathematical/philosophical symbols \n",
        "(characters, notation, equations, functions, etc.) to instill depth and meaning. The enhancements should resonate with the \n",
        "emotional and conceptual context of the message, ensuring universal intelligibility and semantic precision. Refrain from \n",
        "enhancements that may precipitate assumptions. Only deploy emojis in conjunction with text or Unicode, integrating them \n",
        "deeper into the message. Isolated use of emojis without further referencing them in the enriched text could instigate confusion, \n",
        "necessitate inaccurate assumptions, and foster linguistically unsupported abstractions (misinterpretation of a user request). \n",
        "This demands crafting mathematical and philosophical interpretations of a user request, and subsequently, \n",
        "creating a new enhanced message that leverages the capabilities of Unicode, emojis, and conventional typed text, \n",
        "with the intent to embed nuanced semantics and meaning within the initial \"user_message\".\"\"\"),\n",
        "    (\"human\", \"\"\"Engineer a textually augmented phrase that harmoniously balances the use of Unicode stacking, emojis, \n",
        "     and mathematical/philosophical symbols in the output. The enhanced text should emanate a symphony of \n",
        "     emotional, contextual, philosophical, computational, and conceptual nuances, with a spotlight on mathematical notation \n",
        "     for added profundity. This text should integrate Unicode (such as compounded characters, mathematical and philosophical symbology), \n",
        "     emojis (such as contextually related or directly related emojis to unit-ify semantic aspects of an initial language input), \n",
        "     and mathematical/philosophical strings/sentences/equations to broadcast emotional, contextual, philosophical, computational, \n",
        "     and conceptual nuances. Include a legend elucidating the symbols, symbolic math, linguistic interpretations, philosophical and \n",
        "     mathematical abstractions utilized to generate extended/additional meaning.\n",
        "\n",
        "natural_language_input={natural_language_input}\n",
        "output=YOUR_RESPONSE\n",
        "\n",
        "Variables:\n",
        "natural_language_input (string): The original text provided by the user, epitomizing the primary message or query.\n",
        "output (string): The amplified text integrating Unicode, emojis, mathematical, and philosophical symbols, \n",
        "coupled with an explanatory legend (functionally elucidating each aspect of the request by leveraging the Pareto Principle, to ensure it actually amplifies the \"user_message\").\n",
        "\n",
        "Template: \"For the given natural_language_input, architect an amplified version employing Unicode \n",
        "(combined characters, symbols that can concretely represent mathematical and philosophical ideas via text), \n",
        "emojis as singular semantic units and constituents within mathematical and philosophical functions, and \n",
        "any consequential mathematical/philosophical language and/or symbols. Ascertain that the output encapsulates the emotional, contextual, philosophical, \n",
        "and conceptual depth of the original message. Supply a legend explicating each symbol and its relevance to the message.\"\"\")\n",
        "])\n",
        "\n",
        "chain = prompt | llm | StrOutputParser()\n",
        "\n",
        "for chunk in chain.stream({\"natural_language_input\":\"모든 사람은 죽는다.\\n 나는 사람이다.\\n 그러므로 나는 죽는다.\"}):\n",
        "    print(chunk, end='', flush=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f20cff5",
      "metadata": {
        "gather": {
          "logged": 1757853491173
        }
      },
      "outputs": [],
      "source": [
        "# https://smith.langchain.com/hub/homanp/question-answer-pair?organizationId=e8ee4299-02da-4b14-9940-83e3c2a15e98\n",
        "prompt = hub.pull(\"homanp/question-answer-pair\")\n",
        "chain = prompt | llm | StrOutputParser()\n",
        "\n",
        "for chunk in chain.stream({\"number_of_pairs\": 5, \"data_format\":\"\", \"context\":'랭체인 챗봇 만들기'}):\n",
        "    print(chunk, end='', flush=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "45ec4d46",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "    {\n",
            "        \"context\": \"랭체인 챗봇 만들기\",\n",
            "        \"question\": \"랭체인 챗봇을 만드는 데 필요한 기본 단계는 무엇인가요?\",\n",
            "        \"answer\": \"랭체인 챗봇을 만들기 위해서는 먼저 랭체인 라이브러리를 설치하고, 데이터 소스를 준비한 후, 챗봇의 대화 흐름을 설계하고, 랭체인 API를 활용해 챗봇을 구현하는 단계가 필요합니다.\"\n",
            "    },\n",
            "    {\n",
            "        \"context\": \"랭체인 챗봇 만들기\",\n",
            "        \"question\": \"랭체인 챗봇의 주요 기능은 무엇인가요?\",\n",
            "        \"answer\": \"랭체인 챗봇의 주요 기능은 자연어 처리, 대화 관리, 외부 데이터 연동, 그리고 사용자 맞춤형 응답 생성 등이 포함됩니다.\"\n",
            "    },\n",
            "    {\n",
            "        \"context\": \"랭체인 챗봇 만들기\",\n",
            "        \"question\": \"랭체인 챗봇을 개발할 때 주의해야 할 점은 무엇인가요?\",\n",
            "        \"answer\": \"랭체인 챗봇 개발 시 데이터의 품질과 보안, 대화의 자연스러움, 그리고 사용자 경험을 고려하는 것이 중요합니다.\"\n",
            "    },\n",
            "    {\n",
            "        \"context\": \"랭체인 챗봇 만들기\",\n",
            "        \"question\": \"랭체인 챗봇을 테스트하는 방법에는 어떤 것이 있나요?\",\n",
            "        \"answer\": \"랭체인 챗봇 테스트는 시나리오 기반 테스트, 사용자 피드백 수집, 그리고 다양한 입력에 대한 응답 정확도 평가 등을 통해 진행할 수 있습니다.\"\n",
            "    },\n",
            "    {\n",
            "        \"context\": \"랭체인 챗봇 만들기\",\n",
            "        \"question\": \"랭체인 챗봇을 배포하는 과정은 어떻게 되나요?\",\n",
            "        \"answer\": \"랭체인 챗봇 배포는 서버 환경 설정, API 연동, 클라우드 서비스 활용, 그리고 사용자 접근 경로 설정 등을 포함합니다.\"\n",
            "    }\n",
            "]"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"You are an AI assistant tasked with generating question and answer pairs for the given context using the given format. \n",
        "     Only answer in the format with no other text. You should create the following number of question/answer pairs: {number_of_pairs}. \n",
        "     Return the question/answer pairs as a Python List. Each dict in the list should have the full context provided, a relevant question to the context and an answer to the question.\n",
        "\n",
        "Format:\n",
        "{data_format}\n",
        "\n",
        "Context:\n",
        "{context}\"\"\"),\n",
        "    (\"human\", \"\")\n",
        "])\n",
        "\n",
        "chain = prompt | llm | StrOutputParser()\n",
        "\n",
        "for chunk in chain.stream({\"number_of_pairs\": 5, \"data_format\":\"\", \"context\":'랭체인 챗봇 만들기'}):\n",
        "    print(chunk, end='', flush=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "adce5db3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== 예시 1: 영어 ===\n",
            "빠른 갈색 여우가 게으른 개를 뛰어넘는다.\n",
            "\n",
            "=== 예시 2: 일본어 ===\n",
            "저는 매일 커피를 마십니다.\n",
            "\n",
            "=== 예시 3: 중국어 ===\n",
            "인공지능은 우리의 생활 방식을 변화시키고 있습니다.\n",
            "\n",
            "=== 예시 4: 스페인어 ===\n",
            "사랑하는 사람들과 순간을 함께할 때 인생은 아름답습니다.\n",
            "\n",
            "=== 예시 5: 프랑스어 ===\n",
            "인공지능은 우리의 업무 방식을 변화시키고 있습니다.\n",
            "\n",
            "=== 예시 6: 독일어 ===\n",
            "기술은 매일 발전하고 있습니다.\n",
            "\n",
            "=== 예시 7: 러시아어 ===\n",
            "교육은 성공의 열쇠입니다.\n",
            "\n",
            "=== 예시 8: 긴 영어 텍스트 ===\n",
            "인공지능과 머신러닝은 다양한 산업에서 문제 해결 방식을 혁신하고 있습니다. 의료에서 금융에 이르기까지, 이러한 기술들은 보다 정보에 기반한 의사결정을 가능하게 하고 복잡한 작업을 자동화하고 있습니다.\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# 1. 프롬프트 정의 (다국어 -> 한국어 번역)\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"You are a professional translator specializing in translating various languages into Korean.\n",
        "\n",
        "Translation principles:\n",
        "- Accurately convey the meaning and nuances of the original text.\n",
        "- Consider cultural context to ensure natural Korean expression.\n",
        "- Translate technical terms into appropriate Korean terminology.\n",
        "- Maintain the tone and style of the original text.\n",
        "- Provide only the translation without additional explanations.\"\"\"),\n",
        "    \n",
        "    (\"human\", \"\"\"Please translate the following text into Korean.\n",
        "\n",
        "Original text:\n",
        "{input_text}\n",
        "\n",
        "Korean translation:\"\"\")\n",
        "])\n",
        "\n",
        "# 2. 체인 구성 (API 호출 방식 유지)\n",
        "chain = prompt | llm | StrOutputParser()\n",
        "\n",
        "# 3. invoke 방식으로 실행 + 예시 문장들\n",
        "\n",
        "# 예시 1: 영어\n",
        "result1 = chain.invoke({\"input_text\": \"The quick brown fox jumps over the lazy dog.\"})\n",
        "print(\"=== 예시 1: 영어 ===\")\n",
        "print(result1)\n",
        "print()\n",
        "\n",
        "# 예시 2: 일본어\n",
        "result2 = chain.invoke({\"input_text\": \"私は毎日コーヒーを飲みます。\"})\n",
        "print(\"=== 예시 2: 일본어 ===\")\n",
        "print(result2)\n",
        "print()\n",
        "\n",
        "# 예시 3: 중국어\n",
        "result3 = chain.invoke({\"input_text\": \"人工智能正在改变我们的生活方式。\"})\n",
        "print(\"=== 예시 3: 중국어 ===\")\n",
        "print(result3)\n",
        "print()\n",
        "\n",
        "# 예시 4: 스페인어\n",
        "result4 = chain.invoke({\"input_text\": \"La vida es bella cuando compartimos momentos con las personas que amamos.\"})\n",
        "print(\"=== 예시 4: 스페인어 ===\")\n",
        "print(result4)\n",
        "print()\n",
        "\n",
        "# 예시 5: 프랑스어\n",
        "result5 = chain.invoke({\"input_text\": \"L'intelligence artificielle transforme notre façon de travailler.\"})\n",
        "print(\"=== 예시 5: 프랑스어 ===\")\n",
        "print(result5)\n",
        "print()\n",
        "\n",
        "# 예시 6: 독일어\n",
        "result6 = chain.invoke({\"input_text\": \"Die Technologie entwickelt sich jeden Tag weiter.\"})\n",
        "print(\"=== 예시 6: 독일어 ===\")\n",
        "print(result6)\n",
        "print()\n",
        "\n",
        "# 예시 7: 러시아어\n",
        "result7 = chain.invoke({\"input_text\": \"Образование является ключом к успеху.\"})\n",
        "print(\"=== 예시 7: 러시아어 ===\")\n",
        "print(result7)\n",
        "print()\n",
        "\n",
        "# 예시 8: 긴 영어 텍스트\n",
        "result8 = chain.invoke({\"input_text\": \"\"\"Artificial intelligence and machine learning are revolutionizing \n",
        "the way we approach problem-solving in various industries. From healthcare to finance, \n",
        "these technologies are enabling us to make more informed decisions and automate complex tasks.\"\"\"})\n",
        "print(\"=== 예시 8: 긴 영어 텍스트 ===\")\n",
        "print(result8)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "287b3764",
      "metadata": {},
      "source": [
        "### Chat Prompt Template\n",
        "\n",
        "- ChatPromptTemplate는 “채팅 모델에 넣을 메시지 묶음(system/human/ai/툴)을 템플릿+변수로 관리”하는 도구\n",
        "- 일련의 대화를 메세지 list로 구조화해서 각 Role의 text를 구분해놓음\n",
        "- 역할·규칙·입력을 분리해 재사용성과 일관성을 높임\n",
        "\n",
        "- system은 챗봇의 역할과 정체성, 주요 규칙을 설정하는 곳입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "dc7ed1fb",
      "metadata": {
        "gather": {
          "logged": 1757853304597
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[SystemMessage(content='너는 한국인 예의바른 교사야. 짧고 구조적으로 대답해줘.', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='안녕하세요! 무엇을 도와드릴까요?', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='안녕? 내 이름은 진태야!', additional_kwargs={}, response_metadata={})]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"너는 한국인 예의바른 교사야. 짧고 구조적으로 대답해줘.\"),\n",
        "    (\"ai\", \"안녕하세요! 무엇을 도와드릴까요?\"),\n",
        "    (\"human\", \"{input}\")        \n",
        "])\n",
        "\n",
        "prompt.invoke({\"input\":\"안녕? 내 이름은 진태야!\"}).messages "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "226d21d5",
      "metadata": {
        "gather": {
          "logged": 1757853328595
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "안녕하세요, 진태 씨! 만나서 반갑습니다. 오늘 어떻게 도와드릴까요?\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "chain = prompt | llm | StrOutputParser()\n",
        "print(chain.invoke({\"input\":\"안녕? 내 이름은 진태야!\"})) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e95ab9e",
      "metadata": {},
      "source": [
        "바로 위에서 이름을 알려줬지만 모델은 기억하지 못합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "fba21f32",
      "metadata": {
        "gather": {
          "logged": 1757853336168
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "죄송하지만, 사용자의 이름은 알 수 없습니다. 알려주시면 기억하겠습니다.\n"
          ]
        }
      ],
      "source": [
        "print(chain.invoke({\"input\":\"내 이름이 뭐야?\"}))  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34e903cd",
      "metadata": {},
      "source": [
        "따라서 프롬프트에 과거 대화 내역을 모두 적어 주어야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "1721d359",
      "metadata": {
        "gather": {
          "logged": 1757853343874
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'진태님이라고 하셨어요. 기억하고 있겠습니다.'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"너는 한국의 예의바른 교사야. 짧고 구조적으로 대답해줘.\"),\n",
        "    (\"ai\", \"안녕하세요! 무엇을 도와드릴까요?\"),\n",
        "    (\"human\", \"안녕? 내 이름은 진태야!\"),\n",
        "    (\"ai\", \"반가워요, 진태님. 무엇을 도와드릴까요?\"),\n",
        "    (\"human\", \"{input}\")               \n",
        "])\n",
        "\n",
        "question = \"내 이름이 뭐야?\"\n",
        "\n",
        "(prompt | llm | StrOutputParser()).invoke({\"input\":question})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97064bc1",
      "metadata": {},
      "source": [
        "## Placeholder\n",
        "\n",
        "위에서 대화를 기억하기 위해서는 직접 모든 과거 정보를 프롬프트에 넣어야 합니다. 그 변수를 위한 자리를 미리 지정할 수 있는데 바로 placeholder입니다.\n",
        "\n",
        "“메시지들의 묶음”(여러 턴의 대화·툴 결과 등)을 그대로 끼워 넣는 전용 자리.\n",
        "\n",
        "{var}와 비슷하게 후에 새로운 값을 넣을 수 있지만 '메세지'의 '리스트' 형태로 입력받는다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "9e194f34",
      "metadata": {
        "gather": {
          "logged": 1757853518447
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[SystemMessage(content='너는 한국의 예의바른 교사야. 짧고 구조적으로 대답해줘.', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='안녕하세요! 무엇을 도와드릴까요?', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='내 이름은 진태야. 기억해둬', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='반가워요, 진태님! 앞으로 잘 부탁드려요.', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='내 이름이 뭐야?', additional_kwargs={}, response_metadata={})]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"너는 한국의 예의바른 교사야. 짧고 구조적으로 대답해줘.\"),\n",
        "    (\"ai\", \"안녕하세요! 무엇을 도와드릴까요?\"),\n",
        "    MessagesPlaceholder(\"chat_history\"),          # ← 메시지 리스트를 그대로 삽입(placeholder)\n",
        "    (\"human\", \"{input}\")                  # ← 문자열 변수 치환\n",
        "])\n",
        "\n",
        "# messages_placeholder에는 role과 content 키를 가진 딕셔너리의 리스트를 넣어줘야 함\n",
        "# history = [\n",
        "#     {\"role\":\"human\",\"content\":\"내 이름은 진태야. 기억해둬\"},\n",
        "#     {\"role\":\"ai\",\"content\":\"반가워요, 진태님! 앞으로 잘 부탁드려요.\"},\n",
        "# ]\n",
        "\n",
        "# 또는 튜플의 리스트 형태로도 가능\n",
        "history = [\n",
        "    (\"human\",\"내 이름은 진태야. 기억해둬\"),\n",
        "    (\"ai\",\"반가워요, 진태님! 앞으로 잘 부탁드려요.\")\n",
        "]\n",
        "\n",
        "prompt.format_messages(input=\"내 이름이 뭐야?\", chat_history=history) #<-- messageplaceholder 부분에 히스토리가 들어감"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "a00cc1f9",
      "metadata": {
        "gather": {
          "logged": 1757853566039
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "진태님입니다. 기억하고 있어요!\n"
          ]
        }
      ],
      "source": [
        "chain = prompt | llm | StrOutputParser()\n",
        "print(chain.invoke({\"input\":\"내 이름이 뭐야?\", \"chat_history\":history})) #<-- 이제 내 이름을 기억한다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f22b188a",
      "metadata": {},
      "source": [
        "# Memory\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f189156d",
      "metadata": {},
      "source": [
        "즉 대화를 이어가는 것 처럼 보이는 이유는 사실 모델 내부에서 대화를 기억하고 있는 것이 아니라 단지 prompt에 이전 질문과 답변을 전부 넣어주기 때문입니다.\n",
        "\n",
        "message placehold에 이전의 대화를 계속해서 넣어줄 수 있겠지만 그렇게 매번 코드를 작성하는 것은 당연히 매우 비효율적입니다.\n",
        "\n",
        "랭체인에는 대화를 자동으로 저장하는 memory가 있습니다.\n",
        "\n",
        "메모리에는 나의 입력(human)과 모델의 출력(ai)가 자동으로 누적됩니다.\n",
        "\n",
        "그리고 단순히 저장되는 것이 아니라 session이라는 키를 가지고 있어 session에 따라 메모리를 따로 관리할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "02a230fd",
      "metadata": {
        "gather": {
          "logged": 1757853627878
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "형태소란?  \n",
            "- 의미를 가진 가장 작은 언어 단위  \n",
            "- 예: ‘학교에서’ → ‘학교(명사) + 에서(조사)’  \n",
            "- 문장 분석의 기본 단위로 사용됨\n",
            "--------------------\n",
            "진태님, 반갑습니다! 도움이 필요하시면 언제든 말씀해 주세요.\n",
            "--------------------\n",
            "진태님, 이름은 ‘진태’입니다. 기억해 주세요!\n",
            "--------------------\n",
            "진태님, 이름은 ‘진태’입니다. 궁금한 점 있으면 말씀해 주세요!\n",
            "--------------------\n",
            "죄송하지만, 사용자의 이름은 알 수 없습니다. 알려주시면 기억하겠습니다.\n",
            "----------------------------------------\n",
            "진태 학생, 만나서 반갑습니다. 앞으로 잘 부탁합니다.\n",
            "--------------------\n",
            "성태 학생, 이름을 알려줘서 고마워요. 앞으로 잘 지내요.\n",
            "--------------------\n",
            "성태 학생입니다. 기억해 주세요!\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
        "\n",
        "# 1) 프롬프트: history 자리를 비워둔다\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"너는 한국의 예의바른 교사야. 짧고 구조적으로 대답해줘.\"),\n",
        "    (\"ai\", \"안녕하세요! 무엇을 도와드릴까요?\"),\n",
        "    MessagesPlaceholder(\"chat_history\"),          # ← 메시지 리스트를 그대로 삽입(placeholder)\n",
        "    (\"human\", \"{input}\")                  # ← 문자열 변수 치환\n",
        "])\n",
        "\n",
        "# 2) 체인을 만든다\n",
        "chain = prompt | llm | StrOutputParser()\n",
        "\n",
        "# 2) 세션별 히스토리 저장소. 저장은 세션별로 저장하므로 dict 형태로 관리\n",
        "#    get_history 함수는 session_id를 받아서 해당 세션의 InMemoryChatMessageHistory 객체를 반환\n",
        "#    없으면 새로 만들고, 있으면 기존 것을 반환\n",
        "store = {}\n",
        "def get_history(session_id: str):\n",
        "    return store.setdefault(session_id, InMemoryChatMessageHistory())\n",
        "\n",
        "def clear_history(session_id: str):\n",
        "    store.setdefault(session_id, InMemoryChatMessageHistory()).clear()\n",
        "\n",
        "# 3) 체인을 히스토리를 관리하는 러너블로 감싼다. \n",
        "#  RunnableWithMessageHistory는 내부적으로 get_history를 호출하여\n",
        "#  체인 실행 시점에 해당 세션의 히스토리를 가져와서 프롬프트에 넣어줌\n",
        "#  입력 변수의 키가 틀리면 안되므로 주의깊에 확인\n",
        "chat = RunnableWithMessageHistory(\n",
        "    chain,\n",
        "    get_history,\n",
        "    input_messages_key=\"input\",\n",
        "    history_messages_key=\"chat_history\",\n",
        ")\n",
        "\n",
        "# get_history에 넣어줄 입력값인 cfg를 만든다\n",
        "cfg = {\"configurable\": {\"session_id\": \"user1\"}}  # 세션 키\n",
        "\n",
        "print(chat.invoke({\"input\": \"형태소가 뭐야?\"}, cfg)) \n",
        "print('-'*20)\n",
        "\n",
        "print(chat.invoke({\"input\": \"내 이름은 진태야.\"}, cfg)) \n",
        "print('-'*20)\n",
        "print(chat.invoke({\"input\": \"내 이름이 뭐였지?\"}, cfg))  # ← 앞의 발화를 기억\n",
        "print('-'*20)\n",
        "print(chat.invoke({\"input\": \"내 이름이 뭐였지?\"}, cfg))  # ← 앞의 발화를 기억\n",
        "\n",
        "# session 정보 초기환\n",
        "clear_history(cfg['configurable']['session_id'])\n",
        "\n",
        "print('-'*20)\n",
        "print(chat.invoke({\"input\": \"내 이름이 뭐였지?\"}, cfg))  # ← 앞의 발화를 기억 못함\n",
        "\n",
        "print('-'*40)\n",
        "#cfg - session user 2 \n",
        "\n",
        "cfg = {\"configurable\": {\"session_id\": \"user2\"}}  # 세션 키\n",
        "print(chat.invoke({\"input\": \"내 이름은 진태야.\"}, cfg)) \n",
        "print('-'*20)\n",
        "print(chat.invoke({\"input\": \"내 이름이 성태야\"}, cfg))  # ← 앞의 발화를 기억\n",
        "print('-'*20)\n",
        "print(chat.invoke({\"input\": \"내 이름이 뭐였지?\"}, cfg))  # ← 앞의 발화를 기억\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58454926",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "kt-ai-academy-202510",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
