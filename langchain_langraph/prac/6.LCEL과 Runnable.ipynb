{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8839ad0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43b13g4OZS\n",
      "gpt-4.1-mini\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os \n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "load_dotenv('env', override=True)\n",
    "AZURE_OPENAI_API_KEY = os.getenv('AZURE_OPENAI_API_KEY')\n",
    "END_POINT=os.getenv('END_POINT')\n",
    "MODEL_NAME=os.getenv('MODEL_NAME')\n",
    "print(AZURE_OPENAI_API_KEY[:10])\n",
    "print(MODEL_NAME)\n",
    "\n",
    "AZURE_OPENAI_EMB_API_KEY = os.getenv('AZURE_OPENAI_EMB_API_KEY')\n",
    "EMB_END_POINT=os.getenv('EMB_END_POINT')\n",
    "EMB_MODEL_NAME=os.getenv('EMB_MODEL_NAME')\n",
    "\n",
    "os.environ['LANGCHAIN_API_KEY'] = os.getenv('LANGSMITH_API_KEY')\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = os.getenv('LANGCHAIN_ENDPOINT')\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true' #true, false\n",
    "os.environ['LANGCHAIN_PROJECT'] = 'LANG'\n",
    "\n",
    "if os.getenv('LANGCHAIN_TRACING_V2') == \"true\":\n",
    "    print('랭스미스로 추적 중입니다 :', os.getenv('LANGSMITH_API_KEY')[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1c4e5e",
   "metadata": {},
   "source": [
    "## LCEL\n",
    "\n",
    "LangChain Expression Language (LCEL)은 LangChain 라이브러리에서 제공하는 선언적 방식의 인터페이스\n",
    "\n",
    "특징 : \n",
    "- 선복잡한 로직을 간결하고 읽기 쉬움\n",
    "- 다양한 컴포넌트를 쉽게 조합하고 재사용\n",
    "- 다양한 유형의 LLM 애플리케이션 구축\n",
    "- 사용자 정의 컴포넌트를 쉽게 통합"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2542cace",
   "metadata": {},
   "source": [
    "### 1) RunnablePassthrough\n",
    "\n",
    "입력을 그대로 출력하고 아무 처리도 안 합니다.\n",
    "\n",
    "체인의 중간에 변수를 바로 넘길 때 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0ffadf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['question'] input_types={} partial_variables={} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='이 질문에 간단하게 답변해줘: [질문] - {question}'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "template = \"이 질문에 간단하게 답변해줘: [질문] - {question}\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c37f9a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[HumanMessage(content='이 질문에 간단하게 답변해줘: [질문] - 내일 해는 어디에서 뜨지?', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "pt = {\"question\": RunnablePassthrough()} | prompt \n",
    "\n",
    "print(pt.invoke(\"내일 해는 어디에서 뜨지?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f26a41d",
   "metadata": {},
   "source": [
    "### 2) RunnableLambda\n",
    "\n",
    "임의의 파이썬 함수(콜러블)를 Runnable로 감싸서 러너블화 시킴\n",
    "\n",
    "--> 랭체인에서 LCEL로 쉽게 사용가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67767434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "double = RunnableLambda(lambda x: x + x)\n",
    "print(double.invoke(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "805b3062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, Alice!\n"
     ]
    }
   ],
   "source": [
    "def say_hello(name: str) -> str:\n",
    "    return f\"Hello, {name}!\"\n",
    "\n",
    "hello_runnable = RunnableLambda(say_hello)\n",
    "print(hello_runnable.invoke(\"Alice\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8431eea9",
   "metadata": {},
   "source": [
    "### 3) RunnableParallel\n",
    "\n",
    "여러 Runnable을 병렬로 실행해서 결과를 딕셔너리로 반환합니다.\n",
    "\n",
    "같은 입력을 서로 다른 체인/함수에 동시에 넣고, 결과를 한꺼번에 받고 싶을 때 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc9232e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parallel 결과\n",
      "{'customer_number': '132', 'counter_number': '4'}\n",
      "\n",
      "chain 결과\n",
      "messages=[HumanMessage(content='132 고객님 4번 창구에 오시기 바랍니다.', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "def get_customer_number(_ : str) -> str:  \n",
    "    return \"132\"\n",
    "\n",
    "def get_counter_number(_ : str) -> str:  \n",
    "    return \"4\"\n",
    "\n",
    "parallel = RunnableParallel({\n",
    "    \"customer_number\": get_customer_number,\n",
    "    \"counter_number\": get_counter_number,\n",
    "})\n",
    "\n",
    "print('parallel 결과')\n",
    "print(parallel.invoke(\"Jintae\"))\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"{customer_number} 고객님 {counter_number}번 창구에 오시기 바랍니다.\")\n",
    "\n",
    "chain = parallel | prompt\n",
    "\n",
    "print('\\nchain 결과')\n",
    "print(chain.invoke(\"Jintae\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1478970e",
   "metadata": {},
   "source": [
    "랭그래프에서는 입력이 dict인 state가 들어오는데 itemgetter와 결합하면 편리합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7ef04e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content='132 고객님 4번 창구에 오시기 바랍니다.', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "template = \"{_customer_number} 고객님 {_counter_number}번 창구에 오시기 바랍니다.\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "chain = (\n",
    "    {\n",
    "        \"_customer_number\": itemgetter(\"customer_number\"),\n",
    "        \"_counter_number\": itemgetter(\"counter_number\"),\n",
    "    }\n",
    "    | prompt\n",
    ")\n",
    "\n",
    "chain.invoke({\"customer_number\": \"132\", \"counter_number\": \"4\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06472c03",
   "metadata": {},
   "source": [
    "### 4) RunnableSequence\n",
    "\n",
    "여러 Runnable을 순차적으로 연결한 파이프라인입니다.\n",
    "\n",
    "앞선 러너블의 결과가 다음 러너블의 입력으로 들어갑니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6935c6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, JintaeJintae!\n",
      "Hello, JintaeJintae!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableSequence\n",
    "\n",
    "r = RunnableSequence(first=double, last=hello_runnable)\n",
    "print(r.invoke('Jintae'))\n",
    "\n",
    "# RunnableSequence 대신 파이프라인 연산자(|)를 사용할 수 있습니다.\n",
    "\n",
    "print((double | hello_runnable).invoke('Jintae'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238e1e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KT AI Academy",
   "language": "python",
   "name": "kt_ai_academy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
