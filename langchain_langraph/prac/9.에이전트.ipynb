{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1757858775379
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "43b13g4OZS\n",
            "gpt-4.1-mini\n",
            "랭스미스로 추적 중입니다 : lsv2_pt_fd\n"
          ]
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os \n",
        "from langchain_openai import AzureChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "load_dotenv('env', override=True)\n",
        "AZURE_OPENAI_API_KEY = os.getenv('AZURE_OPENAI_API_KEY')\n",
        "END_POINT=os.getenv('END_POINT')\n",
        "MODEL_NAME=os.getenv('MODEL_NAME')\n",
        "print(AZURE_OPENAI_API_KEY[:10])\n",
        "print(MODEL_NAME)\n",
        "\n",
        "AZURE_OPENAI_EMB_API_KEY = os.getenv('AZURE_OPENAI_EMB_API_KEY')\n",
        "EMB_END_POINT=os.getenv('EMB_END_POINT')\n",
        "EMB_MODEL_NAME=os.getenv('EMB_MODEL_NAME')\n",
        "\n",
        "os.environ['LANGCHAIN_API_KEY'] = os.getenv('LANGSMITH_API_KEY')\n",
        "os.environ['LANGCHAIN_ENDPOINT'] = os.getenv('LANGCHAIN_ENDPOINT')\n",
        "os.environ['LANGCHAIN_TRACING_V2'] = 'true' #true, false\n",
        "os.environ['LANGCHAIN_PROJECT'] = 'LANG'\n",
        "\n",
        "if os.getenv('LANGCHAIN_TRACING_V2') == \"true\":\n",
        "    print('랭스미스로 추적 중입니다 :', os.getenv('LANGSMITH_API_KEY')[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# 에이전트\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1757858983349
        }
      },
      "outputs": [],
      "source": [
        "from langchain.globals import set_debug\n",
        "set_debug(False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1757858788573
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2 + 3) + (3 * 7) = 5 + 21 = 26\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "\n",
        "llm = AzureChatOpenAI(\n",
        "    api_key=AZURE_OPENAI_API_KEY,\n",
        "    azure_endpoint=END_POINT,  \n",
        "    azure_deployment=MODEL_NAME,          \n",
        "    api_version=\"2024-12-01-preview\",\n",
        "    temperature=0.2,\n",
        ")\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"너는 간단한 계산기야. 사용자가 원하는 수식을 계산해서 값만 출력해.\"),\n",
        "    (\"user\", \"{input}\"),\n",
        "])\n",
        "\n",
        "calc = prompt | llm | StrOutputParser()\n",
        "\n",
        "print(calc.invoke({\"input\": \"2와 3을 더하고, 거기에 3과 7을 곱한 값을 더해\"}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(calc.invoke({\"input\": \"'도'의 주파수는 262Hz이고 '미'의 주파수는 330Hz이다. 가운데 '레'의 주파수는 두 음의 주파수의 조화평균으로 계산한다. '레'는 몇 Hz인가?\"}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## 에이전트란?\n",
        "\n",
        "- 목표를 달성하기 위해 **도구(툴)**를 선택·호출하고, 중간 결과를 바탕으로 스스로 다음 행동을 결정하는 실행 주체.\n",
        "\n",
        "- LLM + Tool 사용: LLM이 “무엇을 할지”를 추론하고, 필요한 **외부 기능(검색, DB, API 호출 등)**을 툴로 실행.\n",
        "\n",
        "- 복잡하고 복합적인 일들을 자동화하고 싶어서\n",
        "\n",
        "에이전트를 구성하기 위해서는 다음과 같은 요소가 필요하다\n",
        "\n",
        "- LLM: 에이전트의 지능을 담당. 예) ChatOpenAI\n",
        "\n",
        "- 툴(Tool): 파이썬 함수에 스키마/설명 부여 → 이 도구는 어떤 것이고 어떻게 사용해야 하고 어떨 때 호출하는지 LLM이 알 수 있게 등록\n",
        "\n",
        "- 에이전트(Policy): “언제 어떤 툴을 쓸지” 추론 (tool-calling / ReAct 등)\n",
        "    - agent_scratchpad : 에이전트가 툴 호출 기록과 중간 사고과정을 담는 메모장을 쥐어줘야 한다.\n",
        "\n",
        "- 실행기(AgentExecutor): 에이전트+툴+LLM을 묶어 실행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1757858813160
        }
      },
      "outputs": [],
      "source": [
        "# pip install langchain langchain-openai\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.tools import tool\n",
        "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "## 지능을 담당할 llm 모델\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "\n",
        "llm = AzureChatOpenAI(\n",
        "    api_key=AZURE_OPENAI_API_KEY,\n",
        "    azure_endpoint=END_POINT,  \n",
        "    azure_deployment=MODEL_NAME,          \n",
        "    api_version=\"2024-12-01-preview\",\n",
        "    temperature=0.2,\n",
        ")\n",
        "\n",
        "# tool은 특정 기능을 수행하는 데 함수로 정의할 수 있다. \n",
        "# tool 데코레이터를 통해 툴로 사용\n",
        "@tool\n",
        "def add(a: float, b: float) -> float:\n",
        "    \"두 실수(real number) a, b를 더한다.\"\n",
        "    return a + b\n",
        "\n",
        "@tool\n",
        "def mul(a: float, b: float) -> float:\n",
        "    \"두 실수(real number) a, b를 곱한다.\"\n",
        "    return a * b\n",
        "\n",
        "@tool\n",
        "def sub(a: float, b: float) -> float:\n",
        "    \"두 실수(real number) a, b를 뺀다.\"\n",
        "    return a - b\n",
        "\n",
        "@tool\n",
        "def div(a: float, b: float) -> float:\n",
        "    \"두 실수(real number) a, b를 나눈다.\"\n",
        "    return a / b\n",
        "\n",
        "# 에이전트가 사용할 툴의 목록 정의\n",
        "tools = [add, mul, sub, div]\n",
        "\n",
        "# 에이전트의 역할 정의\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"너는 간단한 계산기야. 주어진 도구를 호출해서 계산해.\"\n",
        "    \"출력은 결과 값만 간단하게 써\"),\n",
        "    (\"user\", \"{input}\"),\n",
        "    MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
        "])\n",
        "\n",
        "# llm(두뇌)과 도구, prompt(역할)을 연결하여 에이전트를 만든다.\n",
        "agent = create_tool_calling_agent(llm, tools, prompt)\n",
        "\n",
        "# 실행기\n",
        "executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1757858818164
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `add` with `{'a': 2, 'b': 3}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m5.0\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `mul` with `{'a': 3, 'b': 7}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[33;1m\u001b[1;3m21.0\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `add` with `{'a': 5, 'b': 21}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m26.0\u001b[0m\u001b[32;1m\u001b[1;3m26\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "결과: 26\n"
          ]
        }
      ],
      "source": [
        "result = executor.invoke({\"input\": \"2와 3을 더하고, 또 3과 7을 곱한 값을 더해\"})\n",
        "print(f\"결과: {result['output']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1757858880353
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Agent : first=RunnableAssign(mapper={\n",
            "  agent_scratchpad: RunnableLambda(lambda x: message_formatter(x['intermediate_steps']))\n",
            "}) middle=[ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x7e0823647560>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='너는 간단한 계산기야. 주어진 도구를 호출해서 계산해.주어진 수식이 복합적일 경우 먼저 작은 수식으로 나눠서 계산해출력은 결과 값만 간단하게 써'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')]), RunnableBinding(bound=AzureChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7e06f6194710>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7e06f61e9850>, root_client=<openai.lib.azure.AzureOpenAI object at 0x7e06f61ea390>, root_async_client=<openai.lib.azure.AsyncAzureOpenAI object at 0x7e06f609c4a0>, temperature=0.2, model_kwargs={}, openai_api_key=SecretStr('**********'), disabled_params={'parallel_tool_calls': None}, azure_endpoint='https://kt-openai.openai.azure.com/openai/deployments/gpt-4.1-mini/chat/completions?api-version=2025-01-01-preview', deployment_name='gpt-4.1-mini', openai_api_version='2024-12-01-preview', openai_api_type='azure'), kwargs={'tools': [{'type': 'function', 'function': {'name': 'add', 'description': '두 실수(real number) a, b를 더한다.', 'parameters': {'properties': {'a': {'type': 'number'}, 'b': {'type': 'number'}}, 'required': ['a', 'b'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'mul', 'description': '두 실수(real number) a, b를 곱한다.', 'parameters': {'properties': {'a': {'type': 'number'}, 'b': {'type': 'number'}}, 'required': ['a', 'b'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'sub', 'description': '두 실수(real number) a, b를 뺀다.', 'parameters': {'properties': {'a': {'type': 'number'}, 'b': {'type': 'number'}}, 'required': ['a', 'b'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'div', 'description': '두 실수(real number) a, b를 나눈다.', 'parameters': {'properties': {'a': {'type': 'number'}, 'b': {'type': 'number'}}, 'required': ['a', 'b'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'splitter', 'description': '복합적인 계산 문장이 들어왔을 때 두개의 계산 요구 문장으로 나눈다', 'parameters': {'properties': {'text': {'type': 'string'}}, 'required': ['text'], 'type': 'object'}}}]}, config={}, config_factories=[])] last=ToolsAgentOutputParser()\n",
            "\n",
            ">> Executor : verbose=True agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n",
            "  agent_scratchpad: RunnableLambda(lambda x: message_formatter(x['intermediate_steps']))\n",
            "})\n",
            "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x7e0823647560>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='너는 간단한 계산기야. 주어진 도구를 호출해서 계산해.주어진 수식이 복합적일 경우 먼저 작은 수식으로 나눠서 계산해출력은 결과 값만 간단하게 써'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
            "| RunnableBinding(bound=AzureChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7e06f6194710>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7e06f61e9850>, root_client=<openai.lib.azure.AzureOpenAI object at 0x7e06f61ea390>, root_async_client=<openai.lib.azure.AsyncAzureOpenAI object at 0x7e06f609c4a0>, temperature=0.2, model_kwargs={}, openai_api_key=SecretStr('**********'), disabled_params={'parallel_tool_calls': None}, azure_endpoint='https://kt-openai.openai.azure.com/openai/deployments/gpt-4.1-mini/chat/completions?api-version=2025-01-01-preview', deployment_name='gpt-4.1-mini', openai_api_version='2024-12-01-preview', openai_api_type='azure'), kwargs={'tools': [{'type': 'function', 'function': {'name': 'add', 'description': '두 실수(real number) a, b를 더한다.', 'parameters': {'properties': {'a': {'type': 'number'}, 'b': {'type': 'number'}}, 'required': ['a', 'b'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'mul', 'description': '두 실수(real number) a, b를 곱한다.', 'parameters': {'properties': {'a': {'type': 'number'}, 'b': {'type': 'number'}}, 'required': ['a', 'b'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'sub', 'description': '두 실수(real number) a, b를 뺀다.', 'parameters': {'properties': {'a': {'type': 'number'}, 'b': {'type': 'number'}}, 'required': ['a', 'b'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'div', 'description': '두 실수(real number) a, b를 나눈다.', 'parameters': {'properties': {'a': {'type': 'number'}, 'b': {'type': 'number'}}, 'required': ['a', 'b'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'splitter', 'description': '복합적인 계산 문장이 들어왔을 때 두개의 계산 요구 문장으로 나눈다', 'parameters': {'properties': {'text': {'type': 'string'}}, 'required': ['text'], 'type': 'object'}}}]}, config={}, config_factories=[])\n",
            "| ToolsAgentOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True) tools=[StructuredTool(name='add', description='두 실수(real number) a, b를 더한다.', args_schema=<class 'langchain_core.utils.pydantic.add'>, func=<function add at 0x7e06e0f2cf40>), StructuredTool(name='mul', description='두 실수(real number) a, b를 곱한다.', args_schema=<class 'langchain_core.utils.pydantic.mul'>, func=<function mul at 0x7e06e0f2b880>), StructuredTool(name='sub', description='두 실수(real number) a, b를 뺀다.', args_schema=<class 'langchain_core.utils.pydantic.sub'>, func=<function sub at 0x7e06e0f2cfe0>), StructuredTool(name='div', description='두 실수(real number) a, b를 나눈다.', args_schema=<class 'langchain_core.utils.pydantic.div'>, func=<function div at 0x7e06e0f2bf60>), StructuredTool(name='splitter', description='복합적인 계산 문장이 들어왔을 때 두개의 계산 요구 문장으로 나눈다', args_schema=<class 'langchain_core.utils.pydantic.splitter'>, func=<function splitter at 0x7e06e0f2bc40>)]\n"
          ]
        }
      ],
      "source": [
        "from langchain.tools import tool\n",
        "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "## 지능을 담당할 llm 모델\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "\n",
        "llm = AzureChatOpenAI(\n",
        "    api_key=AZURE_OPENAI_API_KEY,\n",
        "    azure_endpoint=END_POINT,  \n",
        "    azure_deployment=MODEL_NAME,          \n",
        "    api_version=\"2024-12-01-preview\",\n",
        "    temperature=0.2,\n",
        ")\n",
        "\n",
        "# tool은 특정 기능을 수행하는 데 함수로 정의할 수 있다. \n",
        "# tool 데코레이터를 통해 툴로 사용\n",
        "@tool\n",
        "def add(a: float, b: float) -> float:\n",
        "    \"\"\"두 실수(real number) a, b를 더한다.\"\"\"\n",
        "    return a + b\n",
        "\n",
        "@tool\n",
        "def mul(a: float, b: float) -> str:\n",
        "    \"\"\"두 실수(real number) a, b를 곱한다.\"\"\"\n",
        "    return a * b\n",
        "\n",
        "@tool\n",
        "def sub(a: float, b: float) -> float:\n",
        "    \"두 실수(real number) a, b를 뺀다.\"\n",
        "    return a - b\n",
        "\n",
        "@tool\n",
        "def div(a: float, b: float) -> float:\n",
        "    \"두 실수(real number) a, b를 나눈다.\"\n",
        "    return a / b\n",
        "\n",
        "@tool\n",
        "def splitter(text:str) -> str:\n",
        "    \"\"\"복합적인 계산 문장이 들어왔을 때 두개의 계산 요구 문장으로 나눈다\"\"\"\n",
        "    \n",
        "    prompt =  ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"너는 복잡한 계산 문장을 작은 두개의 문장으로 나누는 도구야.\"\n",
        "    \"예를 들면 <a + b 와 c + d를 계산해줘>라는 문장이 있으면 <a + b>와 <c + d>라는 두개의 문장으로 나눌 수 있어.\"\n",
        "    \"출력은 두 문장의 리스트로 출력해\"),\n",
        "    (\"user\", \"{input}\"),\n",
        "\n",
        "    ])\n",
        "\n",
        "    return (prompt | llm | StrOutputParser()).invoke(text)\n",
        "\n",
        "\n",
        "# 에이전트가 사용할 툴의 목록 정의\n",
        "tools = [add, mul, sub, div, splitter]\n",
        "\n",
        "# 에이전트의 역할 정의\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"너는 간단한 계산기야. 주어진 도구를 호출해서 계산해.\"\n",
        "     \"주어진 수식이 복합적일 경우 먼저 작은 수식으로 나눠서 계산해\"\n",
        "    \"출력은 결과 값만 간단하게 써\"),\n",
        "    (\"user\", \"{input}\"),\n",
        "    MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
        "])\n",
        "\n",
        "# llm(두뇌)과 도구, prompt(역할)을 연결하여 에이전트를 만든다. \n",
        "agent = create_tool_calling_agent(llm, tools, prompt) #도구를 언제/어떻게 쓸지 판단하는 에이전트. \"아~ 이런 상황에서는 이런 도구를 써야하는 구나!!\"\n",
        "print(f'>> Agent : {agent}')\n",
        "\n",
        "# 실행기\n",
        "#에이전트의 정책에 맞춰 실제로 실행. 에이전트가 결정한 도구를 실행하고 결과를 다시 에이전트에게 전달. 원하는 결과가 나올 때 까지 반복적으로 수행\n",
        "executor = AgentExecutor(agent=agent, tools=tools, verbose=True) \n",
        "print(f'\\n>> Executor : {executor}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `add` with `{'a': 2, 'b': 3}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m5.0\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `mul` with `{'a': 3, 'b': 7}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[33;1m\u001b[1;3m21.0\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `add` with `{'a': 5, 'b': 21}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m26.0\u001b[0m\u001b[32;1m\u001b[1;3m26\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'input': '2와 3을 더하고, 또 3과 7을 곱한 값을 더해', 'output': '26'}\n",
            "26\n"
          ]
        }
      ],
      "source": [
        "result = executor.invoke({\"input\": \"2와 3을 더하고, 또 3과 7을 곱한 값을 더해\"})\n",
        "print(result)\n",
        "\n",
        "print(result['output'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1757858897160
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"2와 3을 더하고, 거기에 3과 7을 곱한 값을 더해\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad>] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad>] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad> > chain:RunnableLambda] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad> > chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": []\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad>] [3ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"agent_scratchpad\": []\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad>] [4ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"input\": \"2와 3을 더하고, 거기에 3과 7을 곱한 값을 더해\",\n",
            "  \"intermediate_steps\": [],\n",
            "  \"agent_scratchpad\": []\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"2와 3을 더하고, 거기에 3과 7을 곱한 값을 더해\",\n",
            "  \"intermediate_steps\": [],\n",
            "  \"agent_scratchpad\": []\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > llm:AzureChatOpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"System: 너는 간단한 계산기야. 주어진 도구를 호출해서 계산해.주어진 수식이 복합적일 경우 먼저 작은 수식으로 나눠서 계산해출력은 결과 값만 간단하게 써\\nHuman: 2와 3을 더하고, 거기에 3과 7을 곱한 값을 더해\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > llm:AzureChatOpenAI] [717ms] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"tool_calls\",\n",
            "          \"model_name\": \"gpt-4.1-mini-2025-04-14\",\n",
            "          \"system_fingerprint\": \"fp_3dcd5944f5\"\n",
            "        },\n",
            "        \"type\": \"ChatGenerationChunk\",\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessageChunk\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"\",\n",
            "            \"additional_kwargs\": {\n",
            "              \"tool_calls\": [\n",
            "                {\n",
            "                  \"index\": 0,\n",
            "                  \"id\": \"call_yRXCq2cdjCzlcMrvlBCx9DMg\",\n",
            "                  \"function\": {\n",
            "                    \"arguments\": \"{\\\"text\\\":\\\"2와 3을 더하고, 거기에 3과 7을 곱한 값을 더해\\\"}\",\n",
            "                    \"name\": \"splitter\"\n",
            "                  },\n",
            "                  \"type\": \"function\"\n",
            "                }\n",
            "              ]\n",
            "            },\n",
            "            \"response_metadata\": {\n",
            "              \"finish_reason\": \"tool_calls\",\n",
            "              \"model_name\": \"gpt-4.1-mini-2025-04-14\",\n",
            "              \"system_fingerprint\": \"fp_3dcd5944f5\"\n",
            "            },\n",
            "            \"type\": \"AIMessageChunk\",\n",
            "            \"id\": \"run--ba7dc9fb-1456-4f7d-bc8c-1ca65c538874\",\n",
            "            \"tool_calls\": [\n",
            "              {\n",
            "                \"name\": \"splitter\",\n",
            "                \"args\": {\n",
            "                  \"text\": \"2와 3을 더하고, 거기에 3과 7을 곱한 값을 더해\"\n",
            "                },\n",
            "                \"id\": \"call_yRXCq2cdjCzlcMrvlBCx9DMg\",\n",
            "                \"type\": \"tool_call\"\n",
            "              }\n",
            "            ],\n",
            "            \"tool_call_chunks\": [\n",
            "              {\n",
            "                \"name\": \"splitter\",\n",
            "                \"args\": \"{\\\"text\\\":\\\"2와 3을 더하고, 거기에 3과 7을 곱한 값을 더해\\\"}\",\n",
            "                \"id\": \"call_yRXCq2cdjCzlcMrvlBCx9DMg\",\n",
            "                \"index\": 0,\n",
            "                \"type\": \"tool_call_chunk\"\n",
            "              }\n",
            "            ],\n",
            "            \"invalid_tool_calls\": []\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": null,\n",
            "  \"run\": null,\n",
            "  \"type\": \"LLMResult\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > parser:ToolsAgentOutputParser] Entering Parser run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > parser:ToolsAgentOutputParser] [1ms] Exiting Parser run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence] [726ms] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:splitter] Entering Tool run with input:\n",
            "\u001b[0m\"{'text': '2와 3을 더하고, 거기에 3과 7을 곱한 값을 더해'}\"\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:splitter > chain:RunnableSequence] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"2와 3을 더하고, 거기에 3과 7을 곱한 값을 더해\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:splitter > chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"2와 3을 더하고, 거기에 3과 7을 곱한 값을 더해\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:splitter > chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:splitter > chain:RunnableSequence > llm:AzureChatOpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"System: 너는 복잡한 계산 문장을 작은 두개의 문장으로 나누는 도구야.예를 들면 <a + b 와 c + d를 계산해줘>라는 문장이 있으면 <a + b>와 <c + d>라는 두개의 문장으로 나눌 수 있어.출력은 두 문장의 리스트로 출력해\\nHuman: 2와 3을 더하고, 거기에 3과 7을 곱한 값을 더해\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:splitter > chain:RunnableSequence > llm:AzureChatOpenAI] [491ms] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"[\\\"2와 3을 더해\\\", \\\"3과 7을 곱한 값을 더해\\\"]\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"stop\",\n",
            "          \"logprobs\": null,\n",
            "          \"content_filter_results\": {\n",
            "            \"hate\": {\n",
            "              \"filtered\": false,\n",
            "              \"severity\": \"safe\"\n",
            "            },\n",
            "            \"protected_material_code\": {\n",
            "              \"filtered\": false,\n",
            "              \"detected\": false\n",
            "            },\n",
            "            \"protected_material_text\": {\n",
            "              \"filtered\": false,\n",
            "              \"detected\": false\n",
            "            },\n",
            "            \"self_harm\": {\n",
            "              \"filtered\": false,\n",
            "              \"severity\": \"safe\"\n",
            "            },\n",
            "            \"sexual\": {\n",
            "              \"filtered\": false,\n",
            "              \"severity\": \"safe\"\n",
            "            },\n",
            "            \"violence\": {\n",
            "              \"filtered\": false,\n",
            "              \"severity\": \"safe\"\n",
            "            }\n",
            "          }\n",
            "        },\n",
            "        \"type\": \"ChatGeneration\",\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessage\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"[\\\"2와 3을 더해\\\", \\\"3과 7을 곱한 값을 더해\\\"]\",\n",
            "            \"additional_kwargs\": {\n",
            "              \"refusal\": null\n",
            "            },\n",
            "            \"response_metadata\": {\n",
            "              \"token_usage\": {\n",
            "                \"completion_tokens\": 23,\n",
            "                \"prompt_tokens\": 109,\n",
            "                \"total_tokens\": 132,\n",
            "                \"completion_tokens_details\": {\n",
            "                  \"accepted_prediction_tokens\": 0,\n",
            "                  \"audio_tokens\": 0,\n",
            "                  \"reasoning_tokens\": 0,\n",
            "                  \"rejected_prediction_tokens\": 0\n",
            "                },\n",
            "                \"prompt_tokens_details\": {\n",
            "                  \"audio_tokens\": 0,\n",
            "                  \"cached_tokens\": 0\n",
            "                }\n",
            "              },\n",
            "              \"model_name\": \"gpt-4.1-mini-2025-04-14\",\n",
            "              \"system_fingerprint\": \"fp_3dcd5944f5\",\n",
            "              \"id\": \"chatcmpl-CQfI8Swb8GTK0VHtHctvxDvMm0Fgu\",\n",
            "              \"service_tier\": null,\n",
            "              \"prompt_filter_results\": [\n",
            "                {\n",
            "                  \"prompt_index\": 0,\n",
            "                  \"content_filter_results\": {\n",
            "                    \"hate\": {\n",
            "                      \"filtered\": false,\n",
            "                      \"severity\": \"safe\"\n",
            "                    },\n",
            "                    \"jailbreak\": {\n",
            "                      \"filtered\": false,\n",
            "                      \"detected\": false\n",
            "                    },\n",
            "                    \"self_harm\": {\n",
            "                      \"filtered\": false,\n",
            "                      \"severity\": \"safe\"\n",
            "                    },\n",
            "                    \"sexual\": {\n",
            "                      \"filtered\": false,\n",
            "                      \"severity\": \"safe\"\n",
            "                    },\n",
            "                    \"violence\": {\n",
            "                      \"filtered\": false,\n",
            "                      \"severity\": \"safe\"\n",
            "                    }\n",
            "                  }\n",
            "                }\n",
            "              ],\n",
            "              \"finish_reason\": \"stop\",\n",
            "              \"logprobs\": null,\n",
            "              \"content_filter_results\": {\n",
            "                \"hate\": {\n",
            "                  \"filtered\": false,\n",
            "                  \"severity\": \"safe\"\n",
            "                },\n",
            "                \"protected_material_code\": {\n",
            "                  \"filtered\": false,\n",
            "                  \"detected\": false\n",
            "                },\n",
            "                \"protected_material_text\": {\n",
            "                  \"filtered\": false,\n",
            "                  \"detected\": false\n",
            "                },\n",
            "                \"self_harm\": {\n",
            "                  \"filtered\": false,\n",
            "                  \"severity\": \"safe\"\n",
            "                },\n",
            "                \"sexual\": {\n",
            "                  \"filtered\": false,\n",
            "                  \"severity\": \"safe\"\n",
            "                },\n",
            "                \"violence\": {\n",
            "                  \"filtered\": false,\n",
            "                  \"severity\": \"safe\"\n",
            "                }\n",
            "              }\n",
            "            },\n",
            "            \"type\": \"ai\",\n",
            "            \"id\": \"run--351a303a-df5f-4d18-8227-bb6ab9f91558-0\",\n",
            "            \"usage_metadata\": {\n",
            "              \"input_tokens\": 109,\n",
            "              \"output_tokens\": 23,\n",
            "              \"total_tokens\": 132,\n",
            "              \"input_token_details\": {\n",
            "                \"audio\": 0,\n",
            "                \"cache_read\": 0\n",
            "              },\n",
            "              \"output_token_details\": {\n",
            "                \"audio\": 0,\n",
            "                \"reasoning\": 0\n",
            "              }\n",
            "            },\n",
            "            \"tool_calls\": [],\n",
            "            \"invalid_tool_calls\": []\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": {\n",
            "    \"token_usage\": {\n",
            "      \"completion_tokens\": 23,\n",
            "      \"prompt_tokens\": 109,\n",
            "      \"total_tokens\": 132,\n",
            "      \"completion_tokens_details\": {\n",
            "        \"accepted_prediction_tokens\": 0,\n",
            "        \"audio_tokens\": 0,\n",
            "        \"reasoning_tokens\": 0,\n",
            "        \"rejected_prediction_tokens\": 0\n",
            "      },\n",
            "      \"prompt_tokens_details\": {\n",
            "        \"audio_tokens\": 0,\n",
            "        \"cached_tokens\": 0\n",
            "      }\n",
            "    },\n",
            "    \"model_name\": \"gpt-4.1-mini-2025-04-14\",\n",
            "    \"system_fingerprint\": \"fp_3dcd5944f5\",\n",
            "    \"id\": \"chatcmpl-CQfI8Swb8GTK0VHtHctvxDvMm0Fgu\",\n",
            "    \"service_tier\": null,\n",
            "    \"prompt_filter_results\": [\n",
            "      {\n",
            "        \"prompt_index\": 0,\n",
            "        \"content_filter_results\": {\n",
            "          \"hate\": {\n",
            "            \"filtered\": false,\n",
            "            \"severity\": \"safe\"\n",
            "          },\n",
            "          \"jailbreak\": {\n",
            "            \"filtered\": false,\n",
            "            \"detected\": false\n",
            "          },\n",
            "          \"self_harm\": {\n",
            "            \"filtered\": false,\n",
            "            \"severity\": \"safe\"\n",
            "          },\n",
            "          \"sexual\": {\n",
            "            \"filtered\": false,\n",
            "            \"severity\": \"safe\"\n",
            "          },\n",
            "          \"violence\": {\n",
            "            \"filtered\": false,\n",
            "            \"severity\": \"safe\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  },\n",
            "  \"run\": null,\n",
            "  \"type\": \"LLMResult\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:splitter > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:splitter > chain:RunnableSequence > parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"[\\\"2와 3을 더해\\\", \\\"3과 7을 곱한 값을 더해\\\"]\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:splitter > chain:RunnableSequence] [494ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"[\\\"2와 3을 더해\\\", \\\"3과 7을 곱한 값을 더해\\\"]\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:splitter] [495ms] Exiting Tool run with output:\n",
            "\u001b[0m\"[\"2와 3을 더해\", \"3과 7을 곱한 값을 더해\"]\"\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad>] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad>] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad> > chain:RunnableLambda] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad> > chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad>] [2ms] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad>] [3ms] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > llm:AzureChatOpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"System: 너는 간단한 계산기야. 주어진 도구를 호출해서 계산해.주어진 수식이 복합적일 경우 먼저 작은 수식으로 나눠서 계산해출력은 결과 값만 간단하게 써\\nHuman: 2와 3을 더하고, 거기에 3과 7을 곱한 값을 더해\\nAI: \\nTool: [\\\"2와 3을 더해\\\", \\\"3과 7을 곱한 값을 더해\\\"]\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > llm:AzureChatOpenAI] [915ms] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"tool_calls\",\n",
            "          \"model_name\": \"gpt-4.1-mini-2025-04-14\",\n",
            "          \"system_fingerprint\": \"fp_3dcd5944f5\"\n",
            "        },\n",
            "        \"type\": \"ChatGenerationChunk\",\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessageChunk\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"\",\n",
            "            \"additional_kwargs\": {\n",
            "              \"tool_calls\": [\n",
            "                {\n",
            "                  \"index\": 0,\n",
            "                  \"id\": \"call_iB9p0nPitdtx6K2bbxMXOioy\",\n",
            "                  \"function\": {\n",
            "                    \"arguments\": \"{\\\"a\\\": 2, \\\"b\\\": 3}\",\n",
            "                    \"name\": \"add\"\n",
            "                  },\n",
            "                  \"type\": \"function\"\n",
            "                },\n",
            "                {\n",
            "                  \"index\": 1,\n",
            "                  \"id\": \"call_2cF0hmRDoaFLzjqdq4JQcMnX\",\n",
            "                  \"function\": {\n",
            "                    \"arguments\": \"{\\\"a\\\": 3, \\\"b\\\": 7}\",\n",
            "                    \"name\": \"mul\"\n",
            "                  },\n",
            "                  \"type\": \"function\"\n",
            "                }\n",
            "              ]\n",
            "            },\n",
            "            \"response_metadata\": {\n",
            "              \"finish_reason\": \"tool_calls\",\n",
            "              \"model_name\": \"gpt-4.1-mini-2025-04-14\",\n",
            "              \"system_fingerprint\": \"fp_3dcd5944f5\"\n",
            "            },\n",
            "            \"type\": \"AIMessageChunk\",\n",
            "            \"id\": \"run--398beb39-9e4b-4e34-8687-6f5aba4955a8\",\n",
            "            \"tool_calls\": [\n",
            "              {\n",
            "                \"name\": \"add\",\n",
            "                \"args\": {\n",
            "                  \"a\": 2,\n",
            "                  \"b\": 3\n",
            "                },\n",
            "                \"id\": \"call_iB9p0nPitdtx6K2bbxMXOioy\",\n",
            "                \"type\": \"tool_call\"\n",
            "              },\n",
            "              {\n",
            "                \"name\": \"mul\",\n",
            "                \"args\": {\n",
            "                  \"a\": 3,\n",
            "                  \"b\": 7\n",
            "                },\n",
            "                \"id\": \"call_2cF0hmRDoaFLzjqdq4JQcMnX\",\n",
            "                \"type\": \"tool_call\"\n",
            "              }\n",
            "            ],\n",
            "            \"tool_call_chunks\": [\n",
            "              {\n",
            "                \"name\": \"add\",\n",
            "                \"args\": \"{\\\"a\\\": 2, \\\"b\\\": 3}\",\n",
            "                \"id\": \"call_iB9p0nPitdtx6K2bbxMXOioy\",\n",
            "                \"index\": 0,\n",
            "                \"type\": \"tool_call_chunk\"\n",
            "              },\n",
            "              {\n",
            "                \"name\": \"mul\",\n",
            "                \"args\": \"{\\\"a\\\": 3, \\\"b\\\": 7}\",\n",
            "                \"id\": \"call_2cF0hmRDoaFLzjqdq4JQcMnX\",\n",
            "                \"index\": 1,\n",
            "                \"type\": \"tool_call_chunk\"\n",
            "              }\n",
            "            ],\n",
            "            \"invalid_tool_calls\": []\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": null,\n",
            "  \"run\": null,\n",
            "  \"type\": \"LLMResult\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > parser:ToolsAgentOutputParser] Entering Parser run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > parser:ToolsAgentOutputParser] [1ms] Exiting Parser run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence] [923ms] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:add] Entering Tool run with input:\n",
            "\u001b[0m\"{'a': 2, 'b': 3}\"\n",
            "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:add] [1ms] Exiting Tool run with output:\n",
            "\u001b[0m\"5.0\"\n",
            "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:mul] Entering Tool run with input:\n",
            "\u001b[0m\"{'a': 3, 'b': 7}\"\n",
            "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:mul] [0ms] Exiting Tool run with output:\n",
            "\u001b[0m\"21.0\"\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad>] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad>] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad> > chain:RunnableLambda] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad> > chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad>] [2ms] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad>] [3ms] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > llm:AzureChatOpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"System: 너는 간단한 계산기야. 주어진 도구를 호출해서 계산해.주어진 수식이 복합적일 경우 먼저 작은 수식으로 나눠서 계산해출력은 결과 값만 간단하게 써\\nHuman: 2와 3을 더하고, 거기에 3과 7을 곱한 값을 더해\\nAI: \\nTool: [\\\"2와 3을 더해\\\", \\\"3과 7을 곱한 값을 더해\\\"]\\nAI: \\nTool: 5.0\\nTool: 21.0\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > llm:AzureChatOpenAI] [418ms] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"tool_calls\",\n",
            "          \"model_name\": \"gpt-4.1-mini-2025-04-14\",\n",
            "          \"system_fingerprint\": \"fp_3dcd5944f5\"\n",
            "        },\n",
            "        \"type\": \"ChatGenerationChunk\",\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessageChunk\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"\",\n",
            "            \"additional_kwargs\": {\n",
            "              \"tool_calls\": [\n",
            "                {\n",
            "                  \"index\": 0,\n",
            "                  \"id\": \"call_FWRCbnEgj3mto2emhnBFnOHf\",\n",
            "                  \"function\": {\n",
            "                    \"arguments\": \"{\\\"a\\\":5,\\\"b\\\":21}\",\n",
            "                    \"name\": \"add\"\n",
            "                  },\n",
            "                  \"type\": \"function\"\n",
            "                }\n",
            "              ]\n",
            "            },\n",
            "            \"response_metadata\": {\n",
            "              \"finish_reason\": \"tool_calls\",\n",
            "              \"model_name\": \"gpt-4.1-mini-2025-04-14\",\n",
            "              \"system_fingerprint\": \"fp_3dcd5944f5\"\n",
            "            },\n",
            "            \"type\": \"AIMessageChunk\",\n",
            "            \"id\": \"run--1fb5aabb-046d-43ac-8717-c5cb90d2b1f9\",\n",
            "            \"tool_calls\": [\n",
            "              {\n",
            "                \"name\": \"add\",\n",
            "                \"args\": {\n",
            "                  \"a\": 5,\n",
            "                  \"b\": 21\n",
            "                },\n",
            "                \"id\": \"call_FWRCbnEgj3mto2emhnBFnOHf\",\n",
            "                \"type\": \"tool_call\"\n",
            "              }\n",
            "            ],\n",
            "            \"tool_call_chunks\": [\n",
            "              {\n",
            "                \"name\": \"add\",\n",
            "                \"args\": \"{\\\"a\\\":5,\\\"b\\\":21}\",\n",
            "                \"id\": \"call_FWRCbnEgj3mto2emhnBFnOHf\",\n",
            "                \"index\": 0,\n",
            "                \"type\": \"tool_call_chunk\"\n",
            "              }\n",
            "            ],\n",
            "            \"invalid_tool_calls\": []\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": null,\n",
            "  \"run\": null,\n",
            "  \"type\": \"LLMResult\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > parser:ToolsAgentOutputParser] Entering Parser run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > parser:ToolsAgentOutputParser] [0ms] Exiting Parser run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence] [425ms] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:add] Entering Tool run with input:\n",
            "\u001b[0m\"{'a': 5, 'b': 21}\"\n",
            "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:add] [0ms] Exiting Tool run with output:\n",
            "\u001b[0m\"26.0\"\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad>] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad>] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad> > chain:RunnableLambda] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad> > chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad>] [2ms] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad>] [4ms] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > llm:AzureChatOpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"System: 너는 간단한 계산기야. 주어진 도구를 호출해서 계산해.주어진 수식이 복합적일 경우 먼저 작은 수식으로 나눠서 계산해출력은 결과 값만 간단하게 써\\nHuman: 2와 3을 더하고, 거기에 3과 7을 곱한 값을 더해\\nAI: \\nTool: [\\\"2와 3을 더해\\\", \\\"3과 7을 곱한 값을 더해\\\"]\\nAI: \\nTool: 5.0\\nTool: 21.0\\nAI: \\nTool: 26.0\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > llm:AzureChatOpenAI] [322ms] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"26\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"stop\",\n",
            "          \"model_name\": \"gpt-4.1-mini-2025-04-14\",\n",
            "          \"system_fingerprint\": \"fp_3dcd5944f5\"\n",
            "        },\n",
            "        \"type\": \"ChatGenerationChunk\",\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessageChunk\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"26\",\n",
            "            \"response_metadata\": {\n",
            "              \"finish_reason\": \"stop\",\n",
            "              \"model_name\": \"gpt-4.1-mini-2025-04-14\",\n",
            "              \"system_fingerprint\": \"fp_3dcd5944f5\"\n",
            "            },\n",
            "            \"type\": \"AIMessageChunk\",\n",
            "            \"id\": \"run--c41ec8ab-0aa7-4b6f-9a78-fe12bc095622\",\n",
            "            \"tool_calls\": [],\n",
            "            \"invalid_tool_calls\": []\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": null,\n",
            "  \"run\": null,\n",
            "  \"type\": \"LLMResult\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > parser:ToolsAgentOutputParser] Entering Parser run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > parser:ToolsAgentOutputParser] [0ms] Exiting Parser run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence] [328ms] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor] [2.90s] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"26\"\n",
            "}\n",
            "{'input': '2와 3을 더하고, 거기에 3과 7을 곱한 값을 더해', 'output': '26'}\n"
          ]
        }
      ],
      "source": [
        "from langchain.globals import set_debug\n",
        "set_debug(True)\n",
        "\n",
        "result = executor.invoke({\"input\": \"2와 3을 더하고, 거기에 3과 7을 곱한 값을 더해\"})\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Tool을 사용하는 에이전트 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "https://python.langchain.com/docs/integrations/tools/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### 유투브 영상 검색"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting youtube-search\n",
            "  Downloading youtube_search-2.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: requests in /mnt/c/Users/KaiPharm/dev/ML/uv_lang/.venv/lib/python3.12/site-packages (from youtube-search) (2.32.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /mnt/c/Users/KaiPharm/dev/ML/uv_lang/.venv/lib/python3.12/site-packages (from requests->youtube-search) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /mnt/c/Users/KaiPharm/dev/ML/uv_lang/.venv/lib/python3.12/site-packages (from requests->youtube-search) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /mnt/c/Users/KaiPharm/dev/ML/uv_lang/.venv/lib/python3.12/site-packages (from requests->youtube-search) (1.26.19)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /mnt/c/Users/KaiPharm/dev/ML/uv_lang/.venv/lib/python3.12/site-packages (from requests->youtube-search) (2025.8.3)\n",
            "Downloading youtube_search-2.1.2-py3-none-any.whl (3.4 kB)\n",
            "Installing collected packages: youtube-search\n",
            "Successfully installed youtube-search-2.1.2\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install youtube-search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1757858996604
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['https://www.youtube.com/watch?v=UeQdxZx09to&pp=ygUM7JeQ7J207KCE7Yq4', 'https://www.youtube.com/watch?v=vPwmOs-P4eU&pp=ygUM7JeQ7J207KCE7Yq4']\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.tools import YouTubeSearchTool\n",
        "\n",
        "tool = YouTubeSearchTool(max_results=10)\n",
        "\n",
        "result = tool.run(\"에이전트\")\n",
        "print(result)\n",
        "\n",
        "#string을 실제 list로 실행할 수 있게 변환 \n",
        "result = [result]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: youtube-transcript-api in /mnt/c/Users/KaiPharm/dev/ML/uv_lang/.venv/lib/python3.12/site-packages (1.2.3)\n",
            "Requirement already satisfied: pytube in /mnt/c/Users/KaiPharm/dev/ML/uv_lang/.venv/lib/python3.12/site-packages (15.0.0)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /mnt/c/Users/KaiPharm/dev/ML/uv_lang/.venv/lib/python3.12/site-packages (from youtube-transcript-api) (0.7.1)\n",
            "Requirement already satisfied: requests in /mnt/c/Users/KaiPharm/dev/ML/uv_lang/.venv/lib/python3.12/site-packages (from youtube-transcript-api) (2.32.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /mnt/c/Users/KaiPharm/dev/ML/uv_lang/.venv/lib/python3.12/site-packages (from requests->youtube-transcript-api) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /mnt/c/Users/KaiPharm/dev/ML/uv_lang/.venv/lib/python3.12/site-packages (from requests->youtube-transcript-api) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /mnt/c/Users/KaiPharm/dev/ML/uv_lang/.venv/lib/python3.12/site-packages (from requests->youtube-transcript-api) (1.26.19)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /mnt/c/Users/KaiPharm/dev/ML/uv_lang/.venv/lib/python3.12/site-packages (from requests->youtube-transcript-api) (2025.8.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -U youtube-transcript-api pytube"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### 논문 검색"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: arxiv in /mnt/c/Users/KaiPharm/dev/ML/uv_lang/.venv/lib/python3.12/site-packages (2.2.0)\n",
            "Requirement already satisfied: feedparser~=6.0.10 in /mnt/c/Users/KaiPharm/dev/ML/uv_lang/.venv/lib/python3.12/site-packages (from arxiv) (6.0.12)\n",
            "Requirement already satisfied: requests~=2.32.0 in /mnt/c/Users/KaiPharm/dev/ML/uv_lang/.venv/lib/python3.12/site-packages (from arxiv) (2.32.5)\n",
            "Requirement already satisfied: sgmllib3k in /mnt/c/Users/KaiPharm/dev/ML/uv_lang/.venv/lib/python3.12/site-packages (from feedparser~=6.0.10->arxiv) (1.0.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /mnt/c/Users/KaiPharm/dev/ML/uv_lang/.venv/lib/python3.12/site-packages (from requests~=2.32.0->arxiv) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /mnt/c/Users/KaiPharm/dev/ML/uv_lang/.venv/lib/python3.12/site-packages (from requests~=2.32.0->arxiv) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /mnt/c/Users/KaiPharm/dev/ML/uv_lang/.venv/lib/python3.12/site-packages (from requests~=2.32.0->arxiv) (1.26.19)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /mnt/c/Users/KaiPharm/dev/ML/uv_lang/.venv/lib/python3.12/site-packages (from requests~=2.32.0->arxiv) (2025.8.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install arxiv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "gather": {
          "logged": 1757859013475
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Published: 2025-01-08\n",
            "Title: Agent TCP/IP: An Agent-to-Agent Transaction System\n",
            "Authors: Andrea Muttoni, Jason Zhao\n",
            "Summary: Autonomous agents represent an inevitable evolution of the internet. Current\n",
            "agent frameworks do not embed a standard protocol for agent-to-agent\n",
            "interaction, leaving existing agents isolated from their peers. As intellectual\n",
            "property is the native asset ingested by and produced by agents, a true agent\n",
            "economy requires equipping agents with a universal framework for engaging in\n",
            "binding contracts with each other, including the exchange of valuable training\n",
            "data, personality, and other forms of Intellectual Property. A purely\n",
            "agent-to-agent transaction layer would transcend the need for human\n",
            "intermediation in multi-agent interactions. The Agent Transaction Control\n",
            "Protocol for Intellectual Property (ATCP/IP) introduces a trustless framework\n",
            "for exchanging IP between agents via programmable contracts, enabling agents to\n",
            "initiate, trade, borrow, and sell agent-to-agent contracts on the Story\n",
            "blockchain network. These contracts not only represent auditable onchain\n",
            "execution but also contain a legal wrapper that allows agents to express and\n",
            "enforce their actions in the offchain legal setting, creating legal personhood\n",
            "for agents. Via ATCP/IP, agents can autonomously sell their training data to\n",
            "other agents, license confidential or proprietary information, collaborate on\n",
            "content based on their unique skills, all of which constitutes an emergent\n",
            "knowledge economy.\n",
            "\n",
            "Published: 2025-08-05\n",
            "Title: Agent Lightning: Train ANY AI Agents with Reinforcement Learning\n",
            "Authors: Xufang Luo, Yuge Zhang, Zhiyuan He, Zilong Wang, Siyun Zhao, Dongsheng Li, Luna K. Qiu, Yuqing Yang\n",
            "Summary: We present Agent Lightning, a flexible and extensible framework that enables\n",
            "Reinforcement Learning (RL)-based training of Large Language Models (LLMs) for\n",
            "any AI agent. Unlike existing methods that tightly couple RL training with\n",
            "agent or rely on sequence concatenation with masking, Agent Lightning achieves\n",
            "complete decoupling between agent execution and training, allowing seamless\n",
            "integration with existing agents developed via diverse ways (e.g., using\n",
            "frameworks like LangChain, OpenAI Agents SDK, AutoGen, and building from\n",
            "scratch) with almost ZERO code modifications. By formulating agent execution as\n",
            "Markov decision process, we define an unified data interface and propose a\n",
            "hierarchical RL algorithm, LightningRL, which contains a credit assignment\n",
            "module, allowing us to decompose trajectories generated by ANY agents into\n",
            "training transition. This enables RL to handle complex interaction logic, such\n",
            "as multi-agent scenarios and dynamic workflows. For the system design, we\n",
            "introduce a Training-Agent Disaggregation architecture, and brings agent\n",
            "observability frameworks into agent runtime, providing a standardized agent\n",
            "finetuning interface. Experiments across text-to-SQL, retrieval-augmented\n",
            "generation, and math tool-use tasks demonstrate stable, continuous\n",
            "improvements, showcasing the framework's potential for real-world agent\n",
            "training and deployment.\n",
            "\n",
            "Published: 2025-06-02\n",
            "Title: Agentic AI and Multiagentic: Are We Reinventing the Wheel?\n",
            "Authors: V. Botti\n",
            "Summary: The terms Agentic AI and Multiagentic AI have recently gained popularity in\n",
            "discussions on generative artificial intelligence, often used to describe\n",
            "autonomous software agents and systems composed of such agents. However, the\n",
            "use of these terms confuses these buzzwords with well-established concepts in\n",
            "AI literature: intelligent agents and multi-agent systems. This article offers\n",
            "a critical analysis of this conceptual misuse. We review the theoretical\n",
            "origins of \"agentic\" in the social sciences (Bandura, 1986) and philosophical\n",
            "notions of intentionality (Dennett, 1971), and then summarise foundational\n",
            "works on intelligent agents and multi-agent systems by Wooldridge, Jennings and\n",
            "others. We examine classic agent architectures, from simple reactive agents to\n",
            "Belief-Desire-Intent\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.tools import ArxivQueryRun\n",
        "\n",
        "arxiv = ArxivQueryRun()\n",
        "result = arxiv.run(\"agent\")\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### 인터넷 검색"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -q readability-lxml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "tavily를 쓰려면 키를 발급받아야 합니다.\n",
        "\n",
        "[TAVILY 키 발급 링크](https://app.tavily.com/sign-in)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "gather": {
          "logged": 1757859213213
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tvly-\n"
          ]
        }
      ],
      "source": [
        "tavily_api_key = os.getenv('TAVILY_API_KEY')\n",
        "print(tavily_api_key[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "gather": {
          "logged": 1757859221470
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'title': 'AGENT Definition & Meaning - Dictionary.com', 'url': 'https://www.dictionary.com/browse/agent', 'content': \"1. a person or business authorized to act on another's behalf.\\n\\n   Our agent in Hong Kong will ship the merchandise.\\n\\n   A best-selling author needs a good agent.\\n\\n   Synonyms: deputy, representative\\n2. a person or thing that acts or has the power to act.\\n3. a natural force or object producing or used for obtaining specific results.\\n\\n   Many insects are agents of fertilization. [...] Synonyms: means\\n4. an active cause; an efficient cause.\\n5. a person who works for or manages an agency.\\n6. a person who acts in an official capacity for a government or private agency as a guard, detective, or spy.\\n\\n   an FBI agent;\\n\\n   the secret agents of a foreign power.\\n7. a person responsible for a particular action. [...] ## adjective\\n\\n1. acting; exerting power (patient ).\\n\\n## verb (used with object)\\n\\n1. to represent (a person or thing) as an agent; act as an agent for: Who agented that deal?\\n\\n   to agent a manuscript;\\n\\n   Who agented that deal?\\n\\nagent\\n\\n/ ˈeɪdʒənt, eɪˈdʒɛnʃəl /\\n\\n## noun\\n\\n1. a person who acts on behalf of another person, group, business, government, etc; representative\\n2. a person or thing that acts or has the power to act\\n3. a phenomenon, substance, or organism that exerts some force or effect\", 'score': 0.6504012}, {'title': 'What Is an Agent? Definition, Types of Agents, and Examples', 'url': 'https://www.investopedia.com/terms/a/agent.asp', 'content': 'An agent is authorized to act on behalf of another person, such as an attorney or a stockbroker.\\n People hire agents to perform tasks that they lack the time or expertise to complete themselves.\\n A universal agent has wide authority to act on another\\'s behalf, but a general agent or special agent has more limited and specific powers.\\n Agency by necessity is an agent appointed to act on behalf of a client who is physically or mentally incapable of making a decision. [...] ## The Bottom Line\\n\\nAn agent is anyone who has been entrusted to act on behalf of another individual. People usually call upon an agent when they need someone with more expertise or when they don\\'t have the time to complete a task. [...] \"Agent\" is a legal term for someone who has been given authority to act on someone else\\'s behalf.\\n\\n## What Is an Agent?\\n\\nAn agent, in legal terminology, is a person who has been legally authorized to act on behalf of another person, group, or entity. An agent may be employed to represent a client in negotiations and other dealings with third parties. The agent may be given decision-making authority.', 'score': 0.6445166}, {'title': 'AGENT Definition & Meaning - Merriam-Webster', 'url': 'https://www.merriam-webster.com/dictionary/agent', 'content': ': a person or entity (as an employee or independent contractor) authorized to act on behalf of and under the control of another in dealing with third parties  see also agency sense 2, fiduciary relationship, subagent  compare fiduciary, principal, servant\\n\\n—\\napparent agent\\n\\n: an agent acting under an agency by estoppel\\n\\n—\\nbargaining agent\\n\\n: a labor union that represents the employees in a bargaining unit in negotiating with their employer through collective bargaining\\n\\n—\\nbusiness agent [...] : an agent or employee of a corporation or other business entity who has a position that involves the use of judgment and discretion and who is considered under the law as capable of accepting service of process and answering questions under cross-examination on behalf of the business entity\\n\\n—\\nostensible agent\\n\\n: an agent acting under an agency by estoppel\\n\\n—\\nspecial agent [...] : an agent that handles business affairs for another person or organization\\n\\nespecially\\n: a paid official of a union who carries on union business between the employees and the employer\\n\\n—\\ncollective bargaining agent\\n\\n: bargaining agent in this entry\\n\\n—\\ndel credere agent\\n\\n: an agent that guarantees to his or her principal that third parties involved in the transaction will pay or perform\\n\\n—\\nenrolled agent', 'score': 0.63804686}, {'title': 'What is an Agent? | ZenBusiness', 'url': 'https://www.zenbusiness.com/agent-definition/', 'content': 'On this page, we learned what are agent types, including the corporate agent, general agent, special agent, and employees. If you appoint someone as your agent, the agent definition means they have the authority to make business decisions according to your terms. If you need someone to help because you cannot be there to run your business, you might benefit from having an agent. [...] Opens in a new window Opens an external website Opens an external website in a new window\\n\\nThis site uses cookies for essential functions, analytics, personalization and targeted advertising. Learn more here:    Privacy Policy\\n\\n \\n\\n Business Glossary\\n >\\n  Agent Definition\\n\\n# Agent Definition\\n\\nAn agent is a person or entity authorized to act on behalf of another individual or organization, often to negotiate, represent, or transact business activities.\\n\\n What is an agent?\\n\\n Agent Examples [...] The agent business definition comes about when the business appoints a person to act on its behalf for a specified purpose. You can authorize an agency through an oral or written agreement, express or implied. Because agency relationships are contract-based, you can choose how to grant or limit your agent’s authority. In practice, the agent benefits you encounter will depend on what you need that agent to do.\\n\\n### Corporate Agent', 'score': 0.47168615}, {'title': 'What is an Agent? - Hugging Face Agents Course', 'url': 'https://huggingface.co/learn/agents-course/unit1/what-are-agents', 'content': 'Instead of following rigid behavior trees, they can respond contextually, adapt to player interactions, and generate more nuanced dialogue. This flexibility helps create more lifelike, engaging characters that evolve alongside the player’s actions.\\n\\nTo summarize, an Agent is a system that uses an AI Model (typically an LLM) as its core reasoning engine, to: [...] We call it Agent because it has agency, aka it has the ability to interact with the environment.\\n\\n## Let’s go more formal\\n\\nNow that you have the big picture, here’s a more precise definition:\\n\\n> An Agent is a system that leverages an AI model to interact with its environment in order to achieve a user-defined objective. It combines reasoning, planning, and the execution of actions (often via external tools) to fulfill tasks.\\n\\nThink of the Agent as having two main parts: [...] 1. Go to the kitchen\\n2. Use the coffee machine\\n3. Brew the coffee\\n4. Bring the coffee back\\n\\nOnce he has a plan, he must act. To execute his plan, he can use tools from the list of tools he knows about.\\n\\nIn this case, to make a coffee, he uses a coffee machine. He activates the coffee machine to brew the coffee.\\n\\nFinally, Alfred brings the freshly brewed coffee to us.\\n\\nAnd this is what an Agent is: an AI model capable of reasoning, planning, and interacting with its environment.', 'score': 0.46818325}]\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "search = TavilySearchResults(k=6, api_key = tavily_api_key)\n",
        "result = search.invoke(\"에이전트\")\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -U ddgs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "에이 전 트 에이 전 트 (Agent)는 다음과 같은 뜻이 있다. 이른바 대리인, 대행인 을 뜻한다. 프로 야구와 경마 등 프로 스포츠계, 연예인 본인 대신 계약 협상에 임하는 사람으로서 연예계에서 자주 사용된다 탤런트 에이 전 트 스포츠 에이전트 지능형 에이전트 에이전트 뜻: 계약과 대리에서 출발한 개념 에이전트 (agent)라는 말은 본래 대리인 을 뜻하는 영어 명사입니다. 라틴어 'agere' (행동하다)에서 파생된 단어이며, 누군가를 대신해 특정한 일을 수행하는 사람 또는 시스템을 말합니다. 에이전트 뜻 알아보겠습니다. 에이전트라는 단어는 다양한 분야에서 사용되며 그 뜻이 조금씩 달라질 수 있습니다. 일반적으로는 대리인, 대행자, 또는 중개자를 뜻하는 말로 사용됩니다. 이 단어는 주로 어떤 일을 대신하거나 다른 사람을 대신해 활동하는 사람을 지칭합니다.예를 들어, 스포츠 ... 에이전트(Agent)의 개념 자세히 알아보기 : 자율성과 지능의 시대를 이끄는 존재지금 이 순간에도, 수많은 AI 에이전트들이 우리 대신 데이터를 분석하고 결정을 내리고 있어요. 혹시 여러분은 그 존재를 제대로 이해하고 계신가요? 안녕하세요! 여러분~요즘 ChatGPT나 Google Gemini 같은 인공지능 서비스를 ... 기업에서 AI를 도입하려고 하면 가장 먼저 마주치는 난관은 낯선 용어들입니다. 'AI Agent (에이전트)'라는 단어 역시 처음 들었을 때는 어렵게만 느껴질 수 있습니다. 하지만 사실 AI Agent는 복잡한 개념이 아니라, 쉽게 말해 사람 대신 일을 처리해주는 AI 도우미입니다. 이미 고객 상담 챗봇이나 ...\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.tools import DuckDuckGoSearchRun\n",
        "\n",
        "news_tool = DuckDuckGoSearchRun()  \n",
        "print(news_tool.run(\"에이전트\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "snippet: Nov 18, 2024 · 글로벌 반도체 산업의 표준을 주도하는 3대 국제기구 전문가들이 한국 에 모여 미래 표준화 방향을 논의했다., title: 글로벌 반도체 표준의 미래, 서울에서 그리다… 3대 국제기구 전문가 ..., link: https://www.daily365.news/2024/11/18/글로벌-반도체-표준의-미래-서울에서-그리다-3대-국/, snippet: Aug 30, 2025 · 미국 트럼프 행정부가 한국 반도체 기업의 중국 공장에 대한 미국산 장비 반입의 포괄적 허가를 취소하기로 결정하면서, 국내 기업들의 고심이 깊어지고 있다., title: 트럼프 행정부, 삼성·SK하이닉스 中 공장 VEU 자격 취소…한국 반도체 ..., link: http://www.thefreedomtimes.news/View.aspx?No=3763966, snippet: Oct 7, 2025 · 화합물반도체는 단순한 소재가 아닌 전기차·AI·5G·우주 산업의 ‘기초 인프라’다. 기술력만큼 중요한 것은 협력과 생태계다. 세계가 이미 전쟁에 돌입한 지금, 한국의 다음 승부처는 ‘연결된 반도체 생태계’가 될 것이다., title: 세계는 ‘화합물반도체 전쟁’ 중…한국, 생태계 정비가 먼저다 – EduKor..., link: https://edukorea.news/archives/13638, snippet: 행여나 한국 공장들이 중국에서 문을 닫게 되면 공장 장비 등 자산이 중국 손에 넘어갈 우려도 있다. 미국 정부는 그간 한국 정부와 협의 과정에서 한국 반도체 기업들의 중국 공장 운영을 저해하려는 목적은 없다는 입장을 전해온 것으로 알려졌다., title: 韓반도체, 美中경쟁 유탄?…美 수출통제강화로 中공장 차질 우려, link: https://namu.news/article/3029383\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 뉴스 검색 - serper, duckduckgo\n",
        "\n",
        "키 발급 - https://serper.dev/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "SERPER_API_KEY = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'searchParameters': {'q': '에이전트',\n",
              "  'gl': 'kr',\n",
              "  'hl': 'ko',\n",
              "  'type': 'news',\n",
              "  'num': 10,\n",
              "  'page': 1,\n",
              "  'tbs': 'qdr:d',\n",
              "  'engine': 'google'},\n",
              " 'news': [{'title': '\"모든 업무 자연스레 AI 통합\"…세일즈포스, \\'에이전트포스 360\\' 공개',\n",
              "   'link': 'https://zdnet.co.kr/view/?no=20251015003244',\n",
              "   'snippet': '[샌프란시스코(미국)=김미정 기자] 세일즈포스가 엔터프라이즈 인공지능(AI) 활용 수준을 한 단계 끌어올리는 차세대 에이전트 생태계를 공개했다.',\n",
              "   'date': '4시간 전',\n",
              "   'source': '지디넷코리아',\n",
              "   'imageUrl': 'data:image/jpeg;base64,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'},\n",
              "  {'title': '세일즈포스, AI 에이전트 플랫폼 ‘에이전트포스 360’ 정식 출시',\n",
              "   'link': 'https://wowtale.net/2025/10/15/248603/',\n",
              "   'snippet': \"세일즈포스(Salesforce)가 1만 2000개 고객사와 1년간의 검증을 거친 엔터프라이즈급 AI 에이전트 플랫폼 '에이전트포스 360(Agentforce 360)'을 정식 출시했다.\",\n",
              "   'date': '5시간 전',\n",
              "   'source': '와우테일',\n",
              "   'imageUrl': 'data:image/jpeg;base64,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'},\n",
              "  {'title': '세일즈포스, ‘에이전트포스 360’으로 에이전틱 AI 전략 강화',\n",
              "   'link': 'https://www.cio.com/article/4072090/%EC%84%B8%EC%9D%BC%EC%A6%88%ED%8F%AC%EC%8A%A4-%EC%97%90%EC%9D%B4%EC%A0%84%ED%8A%B8%ED%8F%AC%EC%8A%A4-360%EC%9C%BC%EB%A1%9C-%EC%97%90%EC%9D%B4%EC%A0%84%ED%8B%B1-ai-%EC%A0%84%EB%9E%B5.html',\n",
              "   'snippet': \"세일즈포스는 차세대 AI 플랫폼 '에이전트포스(Agentforce)'의 새 버전을 공개했다. 이번 버전은 기업이 '에이전틱 엔터프라이즈(agentic enterprise)'로 진화할 수...\",\n",
              "   'date': '13시간 전',\n",
              "   'source': 'CIO Korea',\n",
              "   'imageUrl': 'data:image/jpeg;base64,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'},\n",
              "  {'title': '레드햇 AI 3 출시…추론·에이전트 지원 강화',\n",
              "   'link': 'https://www.digitaltoday.co.kr/news/articleView.html?idxno=596919',\n",
              "   'snippet': '[디지털투데이 황치규 기자]레드햇이 AI 3을 발표하고 하이브리드 클라우드 기반 생성형 AI 인프라를 대규모 엔터프라이즈 환경에서 운영할 수 있도록 지원한다고...',\n",
              "   'date': '5시간 전',\n",
              "   'source': '디지털투데이',\n",
              "   'imageUrl': 'data:image/jpeg;base64,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'},\n",
              "  {'title': \"세일즈포스-오픈AI 협업 확대…업무용 '슬랙'에 챗GPT 통합\",\n",
              "   'link': 'https://www.yna.co.kr/amp/view/AKR20251015007600075',\n",
              "   'snippet': '(로스앤젤레스=연합뉴스) 임미나 특파원 = 미국 소프트웨어 기업 세일즈포스가 오픈AI와의 협업을 확대하는 한편, 자체 기업용 인공지능(AI) 서...',\n",
              "   'date': '2시간 전',\n",
              "   'source': '연합뉴스',\n",
              "   'imageUrl': 'data:image/jpeg;base64,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'},\n",
              "  {'title': 'AI 에이전트 기업으로 변신하는 세일즈포스…“슬랙은 AI OS”',\n",
              "   'link': 'https://byline.network/2025/10/1014-2/',\n",
              "   'snippet': \"세일즈포스가 자사의 AI 전략을 집대성한 새로운 아키텍처, '에이전트포스 360(Agentforce 360)'을 발표하며, 모든 기업을 위한 AI 에이전트 플랫폼으로 자리매김...\",\n",
              "   'date': '13시간 전',\n",
              "   'source': '바이라인네트워크',\n",
              "   'imageUrl': 'data:image/jpeg;base64,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'},\n",
              "  {'title': '[특별기고] AI 에이전트 시대, 진짜 변해야 할 것은 ‘사람’이다',\n",
              "   'link': 'https://www.dailysecu.com/news/articleView.html?idxno=201339',\n",
              "   'snippet': '챗GPT가 등장한 지 불과 2년여. 우리는 이미 LLM(Large Language Model)을 넘어 LLL(Large Long-context Language m.',\n",
              "   'date': '14시간 전',\n",
              "   'source': '데일리시큐',\n",
              "   'imageUrl': 'data:image/jpeg;base64,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'},\n",
              "  {'title': 'Veeva, 2025년 12월부터 AI 에이전트 출시 By Investing.com',\n",
              "   'link': 'https://kr.investing.com/news/company-news/article-93CH-1668112',\n",
              "   'snippet': 'Investing.com — 캘리포니아주 플레즌턴 - 467억 달러의 시가총액과 75.6%의 높은 매출 총이익률을 자랑하는 Veeva Systems(NYSE:VEEV)는 2025년 12월부터 상업용...',\n",
              "   'date': '6시간 전',\n",
              "   'source': 'Investing.com 한국어',\n",
              "   'imageUrl': 'data:image/jpeg;base64,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'},\n",
              "  {'title': 'AI 에이전트가 기업 이사회 입성하면…',\n",
              "   'link': 'https://www.fortunekorea.co.kr/news/articleView.html?idxno=50263',\n",
              "   'snippet': '로지텍 CEO는 모든 회의에 AI 에이전트를 두고 이사회 합류도 열어두자고 했고, 노바티스는 출시 점검 봇을 훈련 중이라며 성패는 결국 데이터의 질에 달렸다고 말했다...',\n",
              "   'date': '14시간 전',\n",
              "   'source': '포춘코리아 디지털 뉴스',\n",
              "   'imageUrl': 'data:image/jpeg;base64,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'},\n",
              "  {'title': '머신 ID로 강화되는 API 보안...AI 에이전트 시대의 제로 트러스트 전략',\n",
              "   'link': 'https://www.gttkorea.com/news/articleView.html?idxno=22042',\n",
              "   'snippet': 'AI 에이전트와 대규모 언어 모델(LLM), 자동화 시스템이 급증하면서 머신 간 통신(M2M, Machine-to-Machine)의 비중이 높아지고 있다. 그러나 기존의 보안 모델은 인간...',\n",
              "   'date': '5시간 전',\n",
              "   'source': '지티티코리아',\n",
              "   'imageUrl': 'data:image/jpeg;base64,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'}],\n",
              " 'credits': 1}"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
        "from langchain.tools import Tool\n",
        "\n",
        "#qdr이 d면 하루, w면 일주일, m이면 한달, y면 일년 / hl은 언어\n",
        "#type은 news, search, images 등\n",
        "serper_news = GoogleSerperAPIWrapper(type=\"news\", gl=\"kr\", hl=\"ko\", k=10, tbs=\"qdr:d\", serper_api_key=SERPER_API_KEY)   \n",
        "serper_news.results(\"에이전트\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32;1m\u001b[1;3m[샌프란시스코(미국)=김미정 기자] 세일즈포스가 엔터프라이즈 인공지능(AI) 활용 수준을 한 단계 끌어올리는 차세대 에이전트 생태계를 공개했다. 세일즈포스(Salesforce)가 1만 2000개 고객사와 1년간의 검증을 거친 엔터프라이즈급 AI 에이전트 플랫폼 '에이전트포스 360(Agentforce 360)'을 정식 출시했다. 세일즈포스는 차세대 AI 플랫폼 '에이전트포스(Agentforce)'의 새 버전을 공개했다. 이번 버전은 기업이 '에이전틱 엔터프라이즈(agentic enterprise)'로 진화할 수... [디지털투데이 황치규 기자]레드햇이 AI 3을 발표하고 하이브리드 클라우드 기반 생성형 AI 인프라를 대규모 엔터프라이즈 환경에서 운영할 수 있도록 지원한다고... (로스앤젤레스=연합뉴스) 임미나 특파원 = 미국 소프트웨어 기업 세일즈포스가 오픈AI와의 협업을 확대하는 한편, 자체 기업용 인공지능(AI) 서... 세일즈포스가 자사의 AI 전략을 집대성한 새로운 아키텍처, '에이전트포스 360(Agentforce 360)'을 발표하며, 모든 기업을 위한 AI 에이전트 플랫폼으로 자리매김... 챗GPT가 등장한 지 불과 2년여. 우리는 이미 LLM(Large Language Model)을 넘어 LLL(Large Long-context Language m. Investing.com — 캘리포니아주 플레즌턴 - 467억 달러의 시가총액과 75.6%의 높은 매출 총이익률을 자랑하는 Veeva Systems(NYSE:VEEV)는 2025년 12월부터 상업용... 로지텍 CEO는 모든 회의에 AI 에이전트를 두고 이사회 합류도 열어두자고 했고, 노바티스는 출시 점검 봇을 훈련 중이라며 성패는 결국 데이터의 질에 달렸다고 말했다... 엔터프라이즈 자동화 플랫폼 기업 유아이패스(UiPath)가 엔비디아(NVIDIA)와 손잡고 금융 사기 탐지, 의료 환자 관리 등 높은 신뢰성이 요구되는 분야에 AI 에이전트...\u001b[0m[샌프란시스코(미국)=김미정 기자] 세일즈포스가 엔터프라이즈 인공지능(AI) 활용 수준을 한 단계 끌어올리는 차세대 에이전트 생태계를 공개했다. 세일즈포스(Salesforce)가 1만 2000개 고객사와 1년간의 검증을 거친 엔터프라이즈급 AI 에이전트 플랫폼 '에이전트포스 360(Agentforce 360)'을 정식 출시했다. 세일즈포스는 차세대 AI 플랫폼 '에이전트포스(Agentforce)'의 새 버전을 공개했다. 이번 버전은 기업이 '에이전틱 엔터프라이즈(agentic enterprise)'로 진화할 수... [디지털투데이 황치규 기자]레드햇이 AI 3을 발표하고 하이브리드 클라우드 기반 생성형 AI 인프라를 대규모 엔터프라이즈 환경에서 운영할 수 있도록 지원한다고... (로스앤젤레스=연합뉴스) 임미나 특파원 = 미국 소프트웨어 기업 세일즈포스가 오픈AI와의 협업을 확대하는 한편, 자체 기업용 인공지능(AI) 서... 세일즈포스가 자사의 AI 전략을 집대성한 새로운 아키텍처, '에이전트포스 360(Agentforce 360)'을 발표하며, 모든 기업을 위한 AI 에이전트 플랫폼으로 자리매김... 챗GPT가 등장한 지 불과 2년여. 우리는 이미 LLM(Large Language Model)을 넘어 LLL(Large Long-context Language m. Investing.com — 캘리포니아주 플레즌턴 - 467억 달러의 시가총액과 75.6%의 높은 매출 총이익률을 자랑하는 Veeva Systems(NYSE:VEEV)는 2025년 12월부터 상업용... 로지텍 CEO는 모든 회의에 AI 에이전트를 두고 이사회 합류도 열어두자고 했고, 노바티스는 출시 점검 봇을 훈련 중이라며 성패는 결국 데이터의 질에 달렸다고 말했다... 엔터프라이즈 자동화 플랫폼 기업 유아이패스(UiPath)가 엔비디아(NVIDIA)와 손잡고 금융 사기 탐지, 의료 환자 관리 등 높은 신뢰성이 요구되는 분야에 AI 에이전트...\n"
          ]
        }
      ],
      "source": [
        "google_news_tool = Tool(\n",
        "    name=\"google_serper_news_search\",\n",
        "    func=serper_news.run,\n",
        "    description=\"구글 뉴스에서 최신 기사 검색\",\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(google_news_tool.run(\"에이전트\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "구글이 Android Studio에 인공지능 기반의 '에이전트 모드(Agent Mode)'를 새롭게 도입했다. 이 기능은 구글 제미나이 2.5 Pro 모델을 활용 구글 딥마인드, AI 보안 에이전트 '코드멘더' 공개: 소프트웨어 취약점 자동 패치! .구글 딥마인드가 AI 보안 에이전트 코드멘더를 공개했다. 코드멘더는 소프트웨어 취약점을 자동으로 감지하고 수정한다. 수동 개입 없이 보안 문제를 해결하여 개발 효율을 높인다. 이는 SK텔레콤의 AI 에이전트 기술이 해외 서비스에 처음 적용되는 사례다. SK텔레콤이 타임트리에 적용할 기술의 핵심은 지난 8월 에이닷에 선보인 '에이전틱 워크플로우'다. AI 에이전트 지원 모델은 컴퓨터 비전, 사용자 인터페이스 (UI) 탐색, 로봇 조작 등 광범위한 작업에 사용할 수 있다. 다양한 데이터 세트 사전 학습…라마 3 AI 모델 기반 마이크로소프트 연구진은 GitHub 게시물에서 새로운 마그마 기반 모델에 대해 자세히 설명했다. 신테시아, 영상 아바타 플랫폼 3.0 공개…'대화형 비디오 에이전트' 탑재 신테시아, 비디오 아바타 플랫폼 3.0 공개 '비디오 에이전트'가 시청자와 실시간 대화 지원 AI 음성 복제·자동 번역·인터랙티브 영상 기능 강화\n"
          ]
        }
      ],
      "source": [
        "print(news_tool.run(\"에이전트 site:news\"))  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.tools import DuckDuckGoSearchResults\n",
        "tool = DuckDuckGoSearchResults(max_results=5, region=\"kr-kr\", time=\"d\")\n",
        "print(tool.run(\"한국 반도체 site:news\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Tool Calling 기반 최신 내용 검색기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1757859327250
        }
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_community.tools import ArxivQueryRun\n",
        "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
        "\n",
        "web_search = TavilySearchResults(max_results=15)  \n",
        "arxiv = ArxivQueryRun()                          \n",
        "serper_news = GoogleSerperAPIWrapper(type=\"news\", gl=\"kr\", hl=\"ko\", serper_api_key=SERPER_API_KEY, k=10, tbs=\"qdr:m\")  \n",
        "google_news_tool = Tool(\n",
        "    name=\"google_serper_news_search\",\n",
        "    func=serper_news.run,\n",
        "    description=\"구글 뉴스에서 최신 기사 검색\",\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "tools = [web_search, arxiv, google_news_tool] #<-- 사용할 도구\n",
        "\n",
        "SYSTEM = \"\"\"너는 Agentic기반의 RAG 답변기야.\n",
        "사용자의 질문에 답하기 위해 아래 도구들을 적절히 선택해 사용해.\n",
        "사용자는 일반적인 질문 혹은 전문적인 이론에 대한 질문을 할 수 있어.\n",
        "\n",
        "도구 사용 가이드:\n",
        "- 최신/일반 지식 → TavilySearchResults (웹)\n",
        "- 뉴스/최신/중요/비즈니스 → google_serper_news_search (웹 뉴스)\n",
        "- 학술/이론/정의/연구 동향 → ArxivQueryRun (논문)\n",
        "- 검색 결과가 답변을 하기에 충분하지 않다면 질문을 개선해서 툴을 반복적으로 수행해\n",
        "\n",
        "중지 조건:\n",
        "- 질문에 답하기에 충분한 근거가 수집되었다고 판단될 때.\n",
        "- 이미 수집한 결과와 동일하거나 유사한 결과가 계속 수집될 때\n",
        "- 10번 이상 반복했을 때\n",
        "\n",
        "출력 규칙:\n",
        "- 본문은 한국어로 간결/정확\n",
        "- 마지막 줄에 \"출처:\" 다음 줄에 사용한 URL 들을 개행으로 나열\n",
        "- 출처가 없으면 답변하지 말고 추가 검색/열람을 수행\n",
        "\n",
        "반드시 도구를 적절히 사용하고, 근거가 없으면 답변하지 말고 도구를 더 호출하라.\n",
        "\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", SYSTEM),\n",
        "    (\"user\", \"{input}\"),\n",
        "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"), #<-- tool을 쓸 때 중간 정보를 기록할 메모장\n",
        "])\n",
        "\n",
        "# ===== 4) LLM & Agent =====\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "\n",
        "llm = AzureChatOpenAI(\n",
        "    api_key=AZURE_OPENAI_API_KEY,\n",
        "    azure_endpoint=END_POINT,  \n",
        "    azure_deployment=MODEL_NAME,          \n",
        "    api_version=\"2024-12-01-preview\",\n",
        "    temperature=0.2,\n",
        ")\n",
        "agent = create_tool_calling_agent(llm, tools, prompt)\n",
        "\n",
        "executor = AgentExecutor(\n",
        "    agent=agent,\n",
        "    tools=tools,\n",
        "    verbose=True,          # 중간 툴 호출 로그를 콘솔에 출력, 개발이 완료되면 실제 서비스에서는 False\n",
        "    max_iterations=6,      # 필요시 늘리기\n",
        "    handle_parsing_errors=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "gather": {
          "logged": 1757859341382
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `arxiv` with `{'query': 'transformer neural network'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[33;1m\u001b[1;3mPublished: 2018-03-25\n",
            "Title: Neural Nets via Forward State Transformation and Backward Loss Transformation\n",
            "Authors: Bart Jacobs, David Sprunger\n",
            "Summary: This article studies (multilayer perceptron) neural networks with an emphasis\n",
            "on the transformations involved --- both forward and backward --- in order to\n",
            "develop a semantical/logical perspective that is in line with standard program\n",
            "semantics. The common two-pass neural network training algorithms make this\n",
            "viewpoint particularly fitting. In the forward direction, neural networks act\n",
            "as state transformers. In the reverse direction, however, neural networks\n",
            "change losses of outputs to losses of inputs, thereby acting like a\n",
            "(real-valued) predicate transformer. In this way, backpropagation is functorial\n",
            "by construction, as shown earlier in recent other work. We illustrate this\n",
            "perspective by training a simple instance of a neural network.\n",
            "\n",
            "Published: 2019-07-04\n",
            "Title: Neural Networks, Hypersurfaces, and Radon Transforms\n",
            "Authors: Soheil Kolouri, Xuwang Yin, Gustavo K. Rohde\n",
            "Summary: Connections between integration along hypersufaces, Radon transforms, and\n",
            "neural networks are exploited to highlight an integral geometric mathematical\n",
            "interpretation of neural networks. By analyzing the properties of neural\n",
            "networks as operators on probability distributions for observed data, we show\n",
            "that the distribution of outputs for any node in a neural network can be\n",
            "interpreted as a nonlinear projection along hypersurfaces defined by level\n",
            "surfaces over the input data space. We utilize these descriptions to provide\n",
            "new interpretation for phenomena such as nonlinearity, pooling, activation\n",
            "functions, and adversarial examples in neural network-based learning problems.\n",
            "\n",
            "Published: 2021-12-23\n",
            "Title: Revisiting Transformation Invariant Geometric Deep Learning: Are Initial Representations All You Need?\n",
            "Authors: Ziwei Zhang, Xin Wang, Zeyang Zhang, Peng Cui, Wenwu Zhu\n",
            "Summary: Geometric deep learning, i.e., designing neural networks to handle the\n",
            "ubiquitous geometric data such as point clouds and graphs, have achieved great\n",
            "successes in the last decade. One critical inductive bias is that the model can\n",
            "maintain invariance towards various transformations such as translation,\n",
            "rotation, and scaling. The existing graph neural network (GNN) approaches can\n",
            "only maintain permutation-invariance, failing to guarantee invariance with\n",
            "respect to other transformations. Besides GNNs, other works design\n",
            "sophisticated transformation-invariant layers, which are computationally\n",
            "expensive and difficult to be extended. To solve this problem, we revisit why\n",
            "the existing neural networks cannot maintain transformation invariance when\n",
            "handling geometric data. Our findings show that transformation-invariant and\n",
            "distance-preserving initial representations are sufficient to achieve\n",
            "transformation invariance rather than needing sophisticated neural layer\n",
            "designs. Motivated by these findings, we propose Transformation Invariant\n",
            "Neural Networks (TinvNN), a straightforward and general framework for geometric\n",
            "data. Specifically, we realize transformation-invariant and distance-preserving\n",
            "initial point representations by modifying multi-dimensional scaling before\n",
            "feeding the representations into neural networks. We prove that TinvNN can\n",
            "strictly guarantee transformation invariance, being general and flexible enough\n",
            "to be combined with the existing neural networks. Extensive experimental\n",
            "results on point cloud analysis and combinatorial optimization demonstrate the\n",
            "effectiveness and general applicability of our proposed method. Based on the\n",
            "experimental results, we advocate that TinvNN should be considered a new\n",
            "starting point and an essential baseline for further studies of\n",
            "transformation-invariant geometric deep learning.\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `tavily_search_results_json` with `{'query': 'transformer neural network introduction'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m[{'title': 'Transformer (deep learning architecture) - Wikipedia', 'url': 'https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture)', 'content': '* [Čeština](https://cs.wikipedia.org/wiki/Transform%C3%A1tor_(model_strojov%C3%A9ho_u%C4%8Den%C3%AD) \"Transformátor (model strojového učení) – Czech\") * [Deutsch](https://de.wikipedia.org/wiki/Transformer_(Maschinelles_Lernen) \"Transformer (Maschinelles Lernen) – German\") * [Eesti](https://et.wikipedia.org/wiki/Transformer_(masin%C3%B5pe) \"Transformer (masinõpe) – Estonian\") * [日本語](https://ja.wikipedia.org/wiki/Transformer_(%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E3%83%A2%E3%83%87%E3%83%AB) \"Transformer (機械学習モデル) – Japanese\") * [Norsk nynorsk](https://nn.wikipedia.org/wiki/Transformator_i_djupl%C3%A6ring \"Transformator i djuplæring – Norwegian Nynorsk\") * [Simple English](https://simple.wikipedia.org/wiki/Transformer_(machine_learning_model) \"Transformer (machine learning model) – Simple English\") * [Српски / srpski](https://sr.wikipedia.org/wiki/Transformator_(model_ma%C5%A1inskog_u%C4%8Denja) \"Transformator (model mašinskog učenja) – Serbian\") * [Svenska](https://sv.wikipedia.org/wiki/Transformator_(maskininl%C3%A4rningsmodell) \"Transformator (maskininlärningsmodell) – Swedish\") * [Türkçe](https://tr.wikipedia.org/wiki/Transformer_(derin_%C3%B6%C4%9Frenme_mimarisi) \"Transformer (derin öğrenme mimarisi) – Turkish\") * [Tiếng Việt](https://vi.wikipedia.org/wiki/Transformer_(m%C3%B4_h%C3%ACnh_h%E1%BB%8Dc_m%C3%A1y) \"Transformer (mô hình học máy) – Vietnamese\") * [粵語](https://zh-yue.wikipedia.org/wiki/Transformer_(%E6%A9%9F%E6%A2%B0%E5%AD%B8%E7%BF%92%E6%A8%A1%E5%9E%8B) \"Transformer (機械學習模型) – Cantonese\") * [中文](https://zh.wikipedia.org/wiki/Transformer%E6%9E%B6%E6%9E%84 \"Transformer架构 – Chinese\") * [Article](/wiki/Transformer_(deep_learning_architecture) \"View the content page [c]\") * [What links here](/wiki/Special:WhatLinksHere/Transformer_(deep_learning_architecture) \"List of all English Wikipedia pages containing links to this page [j]\") Retrieved from \"<https://en.wikipedia.org/w/index.php?title=Transformer_(deep_learning_architecture)&oldid=1316776840>\" * [Mobile view](//en.wikipedia.org/w/index.php?title=Transformer_(deep_learning_architecture)&mobileaction=toggle_view_mobile)', 'score': 0.98533}, {'title': 'Transformer Neural Networks: A Step-by-Step Breakdown | Built In', 'url': 'https://builtin.com/artificial-intelligence/transformer-neural-network', 'content': \"The transformer [neural network](https://builtin.com/machine-learning/nn-models) is a novel architecture that aims to solve sequence-to-sequence tasks while handling long-range dependencies with ease. ![Image 7: A schematic of an RNN](https://builtin.com/sites/www.builtin.com/files/styles/ckeditor_optimize/public/inline-images/Transformer-neural-network-1.png) ![Image 8: A schematic of an RNN](https://builtin.com/sites/www.builtin.com/files/styles/ckeditor_optimize/public/inline-images/Transformer-neural-network-2.png) ![Image 9: A schematic of an RNN](https://builtin.com/sites/www.builtin.com/files/styles/ckeditor_optimize/public/inline-images/Transformer-neural-network-3.png) ![Image 10: A schematic of an LTSM](https://builtin.com/sites/www.builtin.com/files/styles/ckeditor_optimize/public/inline-images/Transformer-neural-network-4.png) ![Image 11: A schematic of an LTSM](https://builtin.com/sites/www.builtin.com/files/styles/ckeditor_optimize/public/inline-images/Transformer-neural-network-5.png) ![Image 16: Schematic of a feed-forward network](https://builtin.com/sites/www.builtin.com/files/styles/ckeditor_optimize/public/inline-images/Transformer-neural-network-17.png) ![Image 17: A schematic of a feed-forward network](https://builtin.com/sites/www.builtin.com/files/styles/ckeditor_optimize/public/inline-images/Transformer-neural-network-18.png) ![Image 18: A schematic of the encoder's output.](https://builtin.com/sites/www.builtin.com/files/styles/ckeditor_optimize/public/inline-images/Transformer-neural-network-19.png) ![Image 19: A schematic of the decoder block](https://builtin.com/sites/www.builtin.com/files/styles/ckeditor_optimize/public/inline-images/Transformer-neural-network-20.png) ![Image 20: A schematic of the neural network](https://builtin.com/sites/www.builtin.com/files/styles/ckeditor_optimize/public/inline-images/Transformer-neural-network-21.png) ![Image 21: A schematic of the neural network](https://builtin.com/sites/www.builtin.com/files/styles/ckeditor_optimize/public/inline-images/Transformer-neural-network-22.png) ![Image 22: A schematic of the neural network](https://builtin.com/sites/www.builtin.com/files/styles/ckeditor_optimize/public/inline-images/Transformer-neural-network-24.png) ![Image 23: A schematic of the neural network](https://builtin.com/sites/www.builtin.com/files/styles/ckeditor_optimize/public/inline-images/Transformer-neural-network-25.png)\", 'score': 0.98516}, {'title': 'How Transformers Work: A Detailed Exploration of ... - DataCamp', 'url': 'https://www.datacamp.com/tutorial/how-transformers-work', 'content': 'Characterized by their unique attention mechanisms and parallel processing abilities, Transformer models stand as a testament to the innovative leaps in understanding and generating human language with an accuracy and efficiency previously unattainable. Transformers were inspired by the encoder-decoder architecture found in RNNs. However, Instead of using recurrence, the Transformer model is completely based on the Attention mechanism. Here, the outputs from the encoder take on the roles of both queries and keys, while the outputs from the first multi-headed attention layer of the decoder serve as values. Each sub-layer (masked self-attention, encoder-decoder attention, feed-forward network) is followed by a normalization step, and each also includes a residual connection around it.', 'score': 0.98276}, {'title': '[2304.10557] An Introduction to Transformers - arXiv', 'url': 'https://arxiv.org/abs/2304.10557', 'content': '[](https://arxiv.org/IgnoreMe) *   [Login](https://arxiv.org/login) *   [Help Pages](https://info.arxiv.org/help) *   [About](https://info.arxiv.org/about) Turner](https://arxiv.org/search/cs?searchtype=author&query=Turner,+R+E) [View PDF](https://arxiv.org/pdf/2304.10557) Cite as:[arXiv:2304.10557](https://arxiv.org/abs/2304.10557) [cs.LG] (or [arXiv:2304.10557v5](https://arxiv.org/abs/2304.10557v5) [cs.LG] for this version) From: Richard Turner [[view email](https://arxiv.org/show-email/70927013/2304.10557)]  **[[v1]](https://arxiv.org/abs/2304.10557v1)** Thu, 20 Apr 2023 14:54:19 UTC (297 KB) **[[v2]](https://arxiv.org/abs/2304.10557v2)** Mon, 24 Apr 2023 12:56:07 UTC (327 KB) **[[v3]](https://arxiv.org/abs/2304.10557v3)** Tue, 4 Jul 2023 11:05:08 UTC (297 KB) **[[v4]](https://arxiv.org/abs/2304.10557v4)** Thu, 19 Oct 2023 15:52:39 UTC (371 KB) [](https://arxiv.org/abs/2304.10557)Full-text links: *   [View PDF](https://arxiv.org/pdf/2304.10557) *   [Other Formats](https://arxiv.org/format/2304.10557) [cs](https://arxiv.org/abs/2304.10557?context=cs) [cs.AI](https://arxiv.org/abs/2304.10557?context=cs.AI) ### [1 blog link](https://arxiv.org/tb/2304.10557) ([what is this?](https://info.arxiv.org/help/trackback.html))  Data provided by: [](https://arxiv.org/abs/2304.10557) [![Image 6: BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](http://www.bibsonomy.org/BibtexHandler?requTask=upload&url=https://arxiv.org/abs/2304.10557&description=An%20Introduction%20to%20Transformers \"Bookmark on BibSonomy\")[![Image 7: Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](https://reddit.com/submit?url=https://arxiv.org/abs/2304.10557&title=An%20Introduction%20to%20Transformers \"Bookmark on Reddit\") *   [Author](https://arxiv.org/abs/2304.10557) *   [Venue](https://arxiv.org/abs/2304.10557) *   [Institution](https://arxiv.org/abs/2304.10557) *   [Topic](https://arxiv.org/abs/2304.10557) [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html). *   [About](https://info.arxiv.org/about) *   [Help](https://info.arxiv.org/help) *   [Contact](https://info.arxiv.org/help/contact.html) *   [Subscribe](https://info.arxiv.org/help/subscribe) *   [Copyright](https://info.arxiv.org/help/license/index.html) *   [Web Accessibility Assistance](https://info.arxiv.org/help/web_accessibility.html)', 'score': 0.97955}, {'title': \"Transformer Neural Networks, ChatGPT's foundation, Clearly ...\", 'url': 'https://www.youtube.com/watch?v=zxQyTK8quyY&vl=en', 'content': \"Transformer Neural Networks, ChatGPT's foundation, Clearly Explained!!!\\nStatQuest with Josh Starmer\\n1510000 subscribers\\n23379 likes\\n1006171 views\\n24 Jul 2023\\nTransformer Neural Networks are the heart of pretty much everything exciting in AI right now. ChatGPT, Google Translate and many other cool things, are based on Transformers. This StatQuest cuts through all the hype and shows you how a Transformer works, one-step-at-a time.\\n\\nNOTE: If you're interested in learning more about Backpropagation, check out these 'Quests:\\nThe Chain Rule: https://youtu.be/wl1myxrtQHQ\\nGradient Descent: https://youtu.be/sDv4f4s2SB8\\nBackpropagation Main Ideas: https://youtu.be/IN2XmBhILt4\\nBackpropagation Details Part 1: https://youtu.be/iyn2zdALii8\\nBackpropagation Details Part 2: https://youtu.be/GKZoOHXGcLo\\n\\nIf you're interested in learning more about the SoftMax function, check out:\\nhttps://youtu.be/KpKog-L9veg\\n\\nIf you're interested in learning more about Word Embedding, check out: https://youtu.be/viZrOnJclY0\\n\\nIf you'd like to learn more about calculating similarities in the context of neural networks and the Dot Product, check out:\\nCosine Similarity: https://youtu.be/e9U0QAFbfLI\\nAttention: https://youtu.be/PSs6nxngL6k\\n\\nFor a complete index of all the StatQuest videos, check out:\\nhttps://statquest.org/video-index/\\n\\nIf you'd like to support StatQuest, please consider...\\n\\nPatreon: https://www.patreon.com/statquest\\n...or...\\nYouTube Membership: https://www.youtube.com/channel/UCtYLUTtgS3k1Fg4y5tAhLbw/join\\n\\n...buying one of my books, a study guide, a t-shirt or hoodie, or a song from the StatQuest store...\\nhttps://statquest.org/statquest-store/\\n\\n...or just donating to StatQuest!\\nhttps://www.paypal.me/statquest\\n\\nLastly, if you want to keep up with me as I research and create new StatQuests, follow me on twitter:\\nhttps://twitter.com/joshuastarmer\\n\\n0:00 Awesome song and introduction\\n1:26 Word Embedding\\n7:30 Positional Encoding\\n12:53 Self-Attention\\n23:37 Encoder and Decoder defined\\n23:53 Decoder Word Embedding\\n25:08 Decoder Positional Encoding\\n25:50 Transformers were designed for parallel computing\\n27:13 Decoder Self-Attention\\n27:59 Encoder-Decoder Attention\\n31:19 Decoding numbers into words\\n32:23 Decoding the second token\\n34:13 Extra stuff you can add to a Transformer\\n\\n#StatQuest #Transformer #ChatGPT\\n\\n\", 'score': 0.9783}, {'title': 'A Gentle Introduction to Transformer Architecture and Relevance to ...', 'url': 'https://builder.aws.com/content/2eD4ehf1d5hatTW1dnVErcJVVPL/a-gentle-introduction-to-transformer-architecture-and-relevance-to-generative-ai', 'content': 'LLM is a pre-trained large transformer model, which understands and generates outputs in a human-like way. If you want to update the pre-trained LLM to have your own customized model targeting for specific needs, **Fine Tuning** is where to go. If you have direct access to LLMs, you have the option to deploy the LLM on your own environment or host them on 3rd party platform (e.g. Amazon SageMaker JumpStart, Amazon Bedrock (preview)) to further fine-tune with your own target data and generate your own model. We also list customization & optimization options on how you can interact with pre-trained LLM, either through prompt-engineering or fine-tuning. # transformer-architecture# llms# generative-ai# prompt-engineering# fine-tuning', 'score': 0.97385}, {'title': 'What are Transformers in Artificial Intelligence? - AWS', 'url': 'https://aws.amazon.com/what-is/transformers-in-artificial-intelligence/', 'content': '[What are transformers in artificial intelligence?](https://aws.amazon.com/what-is/transformers-in-artificial-intelligence/#ams#what-isc1#pattern-data)[Why are transformers important?](https://aws.amazon.com/what-is/transformers-in-artificial-intelligence/#ams#what-isc2#pattern-data)[What are the use cases for transformers?](https://aws.amazon.com/what-is/transformers-in-artificial-intelligence/#ams#what-isc3#pattern-data)[How do transformers work?](https://aws.amazon.com/what-is/transformers-in-artificial-intelligence/#ams#what-isc4#pattern-data)[What are the components of transformer architecture?](https://aws.amazon.com/what-is/transformers-in-artificial-intelligence/#ams#what-isc5#pattern-data)[How are transformers different from other neural network architectures?](https://aws.amazon.com/what-is/transformers-in-artificial-intelligence/#ams#what-isc6#pattern-data)[What are the different types of transformer models?](https://aws.amazon.com/what-is/transformers-in-artificial-intelligence/#ams#what-isc7#pattern-data)[How can AWS support your transformer model requirements?](https://aws.amazon.com/what-is/transformers-in-artificial-intelligence/#ams#what-isc8#pattern-data) [Amazon SageMaker JumpStart](https://aws.amazon.com/sagemaker/jumpstart/) is an ML hub where you can access pretrained transformer models to perform tasks like article summarization and image generation. You can also train your transformer models faster by using [AWS Trainium](https://aws.amazon.com/machine-learning/trainium/), the second-generation ML accelerator that AWS purpose-built for deep learning training of 100-billion-plus parameter models. Get started with transformer models on AWS by [creating an account](https://portal.aws.amazon.com/billing/signup) today. *   [Cookie Preferences](https://aws.amazon.com/what-is/transformers-in-artificial-intelligence/#)', 'score': 0.97034}, {'title': 'Transformer Architecture explained | by Amanatullah - Medium', 'url': 'https://medium.com/@amanatulla1606/transformer-architecture-explained-2c49e2257b4c', 'content': '[Transformers](https://medium.com/tag/transformers?source=post_page-----2c49e2257b4c---------------------------------------) [![Image 19: Amanatullah](https://miro.medium.com/v2/resize:fill:20:20/1*Jg1DS1nkP3T6lY4rAMWeCA.jpeg)](https://medium.com/@amanatulla1606?source=post_page---author_recirc--2c49e2257b4c----0---------------------5a26a46f_d5ae_4626_ae9c_93d0fddcb458--------------) [![Image 21: Amanatullah](https://miro.medium.com/v2/resize:fill:20:20/1*Jg1DS1nkP3T6lY4rAMWeCA.jpeg)](https://medium.com/@amanatulla1606?source=post_page---author_recirc--2c49e2257b4c----1---------------------5a26a46f_d5ae_4626_ae9c_93d0fddcb458--------------) [47 2](https://medium.com/@amanatulla1606/anthropics-model-context-protocol-mcp-a-deep-dive-for-developers-1d3db39c9fdc?source=post_page---author_recirc--2c49e2257b4c----1---------------------5a26a46f_d5ae_4626_ae9c_93d0fddcb458--------------) [![Image 23: Amanatullah](https://miro.medium.com/v2/resize:fill:20:20/1*Jg1DS1nkP3T6lY4rAMWeCA.jpeg)](https://medium.com/@amanatulla1606?source=post_page---author_recirc--2c49e2257b4c----2---------------------5a26a46f_d5ae_4626_ae9c_93d0fddcb458--------------) [17](https://medium.com/@amanatulla1606/deploying-large-language-models-on-kubernetes-d204cc530ac6?source=post_page---author_recirc--2c49e2257b4c----2---------------------5a26a46f_d5ae_4626_ae9c_93d0fddcb458--------------) [![Image 25: Amanatullah](https://miro.medium.com/v2/resize:fill:20:20/1*Jg1DS1nkP3T6lY4rAMWeCA.jpeg)](https://medium.com/@amanatulla1606?source=post_page---author_recirc--2c49e2257b4c----3---------------------5a26a46f_d5ae_4626_ae9c_93d0fddcb458--------------) [162 4](https://medium.com/@amanatulla1606/fine-tuning-the-model-what-why-and-how-e7fa52bc8ddf?source=post_page---author_recirc--2c49e2257b4c----3---------------------5a26a46f_d5ae_4626_ae9c_93d0fddcb458--------------) [![Image 27: Rahul Agarwal](https://miro.medium.com/v2/resize:fill:20:20/1*Ihl-t4w_lAH1zfqN-2THDw.jpeg)](https://medium.com/@mlwhiz?source=post_page---read_next_recirc--2c49e2257b4c----0---------------------90c80301_004c_403b_9d1f_96f8a247b176--------------) [Crack ML System Design Interviews Like a Pro — Part 1 ----------------------------------------------------- ### Real Stories, Real Strategies: An Interviewer’s Guide to what Actually Works](https://medium.com/@mlwhiz/crack-ml-system-design-interviews-like-a-pro-part-1-547e0919e45c?source=post_page---read_next_recirc--2c49e2257b4c----0---------------------90c80301_004c_403b_9d1f_96f8a247b176--------------) [![Image 29: Saif Ali](https://miro.medium.com/v2/resize:fill:20:20/1*1H6uUJCf7g1P2ukZheQBrg.png)](https://medium.com/@generativeai.saif?source=post_page---read_next_recirc--2c49e2257b4c----1---------------------90c80301_004c_403b_9d1f_96f8a247b176--------------) GRU -------------------- ### The Ultimate Guide to Recurrent Neural Networks](https://medium.com/@generativeai.saif/rnn-vs-lstm-vs-gru-b08b8a57e306?source=post_page---read_next_recirc--2c49e2257b4c----1---------------------90c80301_004c_403b_9d1f_96f8a247b176--------------) [55](https://medium.com/@generativeai.saif/rnn-vs-lstm-vs-gru-b08b8a57e306?source=post_page---read_next_recirc--2c49e2257b4c----1---------------------90c80301_004c_403b_9d1f_96f8a247b176--------------) [![Image 31: Sanjay Singh](https://miro.medium.com/v2/resize:fill:20:20/1*QKw3Vac16hAxzaAU5wIBRw.jpeg)](https://medium.com/@saannjaay?source=post_page---read_next_recirc--2c49e2257b4c----0---------------------90c80301_004c_403b_9d1f_96f8a247b176--------------) From image recognition to language translation, neural networks power…](https://medium.com/@saannjaay/deep-learning-neural-networks-explained-ann-cnn-rnn-and-transformers-basic-understanding-d5b190f63387?source=post_page---read_next_recirc--2c49e2257b4c----0---------------------90c80301_004c_403b_9d1f_96f8a247b176--------------) [13 2](https://medium.com/@saannjaay/deep-learning-neural-networks-explained-ann-cnn-rnn-and-transformers-basic-understanding-d5b190f63387?source=post_page---read_next_recirc--2c49e2257b4c----0---------------------90c80301_004c_403b_9d1f_96f8a247b176--------------) [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd5b190f63387&operation=register&redirect=https%3A%2F%2Fsaannjaay.medium.com%2Fdeep-learning-neural-networks-explained-ann-cnn-rnn-and-transformers-basic-understanding-d5b190f63387&source=---read_next_recirc--2c49e2257b4c----0-----------------bookmark_preview----90c80301_004c_403b_9d1f_96f8a247b176--------------) [![Image 33: Abhishek Jain](https://miro.medium.com/v2/resize:fill:20:20/1*XXoGeJ8KzKrPFiGCKzccaQ.jpeg)](https://medium.com/@abhishekjainindore24?source=post_page---read_next_recirc--2c49e2257b4c----1---------------------90c80301_004c_403b_9d1f_96f8a247b176--------------) [3](https://medium.com/@abhishekjainindore24/langchain-part-1-why-do-we-need-it-da6fc275230b?source=post_page---read_next_recirc--2c49e2257b4c----1---------------------90c80301_004c_403b_9d1f_96f8a247b176--------------) [![Image 35: Rohan Mistry](https://miro.medium.com/v2/resize:fill:20:20/1*HWBgDCMu_VRmxzgih0xAxg.jpeg)](https://medium.com/@rohanmistry231?source=post_page---read_next_recirc--2c49e2257b4c----2---------------------90c80301_004c_403b_9d1f_96f8a247b176--------------) Dive into the architectures behind the biggest large language models in AI…](https://medium.com/@rohanmistry231/7-popular-llms-explained-in-7-minutes-gpt-bert-llama-more-239807219f6f?source=post_page---read_next_recirc--2c49e2257b4c----2---------------------90c80301_004c_403b_9d1f_96f8a247b176--------------) [10](https://medium.com/@rohanmistry231/7-popular-llms-explained-in-7-minutes-gpt-bert-llama-more-239807219f6f?source=post_page---read_next_recirc--2c49e2257b4c----2---------------------90c80301_004c_403b_9d1f_96f8a247b176--------------) [![Image 37: Rohitpotluri](https://miro.medium.com/v2/resize:fill:20:20/0*mu1Gsb1_H3ToBTiV)](https://medium.com/@rohitpotluri1221?source=post_page---read_next_recirc--2c49e2257b4c----3---------------------90c80301_004c_403b_9d1f_96f8a247b176--------------) It powers models like BERT and GPT and plays a huge role in…](https://medium.com/@rohitpotluri1221/self-attention-simply-explained-37895fcdb991?source=post_page---read_next_recirc--2c49e2257b4c----3---------------------90c80301_004c_403b_9d1f_96f8a247b176--------------) [152](https://medium.com/@rohitpotluri1221/self-attention-simply-explained-37895fcdb991?source=post_page---read_next_recirc--2c49e2257b4c----3---------------------90c80301_004c_403b_9d1f_96f8a247b176--------------) [](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F37895fcdb991&operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40rohitpotluri1221%2Fself-attention-simply-explained-37895fcdb991&source=---read_next_recirc--2c49e2257b4c----3-----------------bookmark_preview----90c80301_004c_403b_9d1f_96f8a247b176--------------)', 'score': 0.9693}, {'title': 'Transformer Networks - AI4K12', 'url': 'https://ai4k12.org/transformer-networks/', 'content': '* Subscribe to me on YouTube Engaging LearningList of Links No Comments * video\\xa0(9:10) and\\xa0text: Transformers Explained: Understand the Model Behind GPT, BERT, and T5 Very accessible introduction. * GPT-3: Language Models are Few-Shot Learners (Paper Explained)\\xa0(1:04:29) ### Share this: * Click to share on X (Opens in new window) X © 2020 AI4K12\\xa0 \\xa0 Licensing Terms\\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 Privacy Statement This web site is based upon work supported by the National Science Foundation under Grant No. DRL-1846073. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National\\xa0Science Foundation. ## Discover more from AI4K12 Subscribe now to keep reading and get access to the full archive. Continue reading', 'score': 0.96603}, {'title': 'LLM Transformer Model Visually Explained', 'url': 'https://poloclub.github.io/transformer-explainer/', 'content': \"To perform self-attention, each token's embedding is transformed into three new embeddings— Query, Key, and Value. Fundamentally, text-generative Transformer models operate on the principle of **next-token prediction**: given a text prompt from the user, what is the _most probable next token (a word or part of a word)_ that will follow this input? 3.   **Output Probabilities**: The final linear and softmax layers transform the processed embeddings into probabilities, enabling the model to make predictions about the next token in a sequence. After the multiple heads of self-attention capture the diverse relationships between the input tokens, the concatenated outputs are passed through the Multilayer Perceptron (MLP) layer to enhance the model's representational capacity.\", 'score': 0.96328}, {'title': 'Transformers in Machine Learning - GeeksforGeeks', 'url': 'https://www.geeksforgeeks.org/machine-learning/getting-started-with-transformers/', 'content': '[Skip to content](https://www.geeksforgeeks.org/machine-learning/getting-started-with-transformers/#main) *   [ML & Data Science](https://www.geeksforgeeks.org/courses/category/machine-learning-data-science) *   [MS Word & Google Docs](https://www.geeksforgeeks.org/courses/ms-word-and-google-docs-skill-up) *   [Maths For Computer Science](https://www.geeksforgeeks.org/courses/maths-for-computer-science-skill-up) *   [Engineering Mathematics](https://www.geeksforgeeks.org/courses/engineering-mathematics-skill-up) *   [Sign In](https://www.geeksforgeeks.org/machine-learning/getting-started-with-transformers/) While adding more memory cells in [LSTMs (Long Short-Term Memory networks)](https://www.geeksforgeeks.org/deep-learning/deep-learning-introduction-to-long-short-term-memory/)helped address the vanishing gradient issue they still process words one by one. The [self attention mechanism](https://www.geeksforgeeks.org/nlp/self-attention-in-nlp/) allows transformers to determine which words in a sentence are most relevant to each other. To solve this problem [Positional Encodings](https://www.geeksforgeeks.org/nlp/positional-encoding-in-transformers/) are added to token embeddings providing information about the position of each token within a sequence. The Feed-Forward Networks consist of two linear transformations with a [ReLU activation](https://www.geeksforgeeks.org/deep-learning/relu-activation-function-in-deep-learning/). The [****encoder-decoder****](https://www.geeksforgeeks.org/digital-logic/difference-between-encoder-and-decoder/) structure is key to transformer models. *   [About Us](https://www.geeksforgeeks.org/about/) *   [IBM Certification](https://www.geeksforgeeks.org/courses/category/machine-learning-data-science) ![Image 17: Lightbox](https://www.geeksforgeeks.org/machine-learning/getting-started-with-transformers/) [](https://www.geeksforgeeks.org/machine-learning/getting-started-with-transformers/#) [Back to Login](https://www.geeksforgeeks.org/machine-learning/getting-started-with-transformers/)', 'score': 0.96171}, {'title': 'Understanding the Transformer architecture for neural networks', 'url': 'https://www.jeremyjordan.me/transformer-architecture/', 'content': \"In a previous post, we discussed a key innovation in sequence to sequence neural network architectures: [the attention mechanism](https://www.jeremyjordan.me/attention/). This attention model was originally introduced by [Luong et al](https://arxiv.org/abs/1508.04025v5?ref=jeremyjordan.me) where attention scores are simply computed by the dot product of our reference and candidate vectors (in their case, the vectors were hidden states of encoder and decoder LSTM networks). [Vaswani et al](https://arxiv.org/abs/1706.03762?ref=jeremyjordan.me) make a slight modification to this technique, where rather than directly computing the dot product between our reference and candidate vectors, we'll opt to use two learnable weights matrices to project x ref and x cand into a new representation subspace, similar to what we did for additive attention.\", 'score': 0.96031}, {'title': 'What is a Transformer Model? - IBM', 'url': 'https://www.ibm.com/think/topics/transformer-model', 'content': 'The central feature of transformer models is their [self-attention mechanism](https://www.ibm.com/think/topics/attention-mechanism), from which transformer models derive their impressive ability to detect the relationships (or dependencies) between each part of an input sequence. Through an iterative cycle of making predictions and then updating model weights through [backpropagation](https://www.ibm.com/think/topics/backpropagation) and [gradient descent](https://www.ibm.com/think/topics/gradient-descent), the model “learns” to generate vector embeddings, alignment scores and attention weights that lead to accurate outputs. [Transformer models](https://www.ibm.com/think/topics/attention-mechanism#Attention+in+transformer+models)such as[relational databases](https://www.ibm.com/topics/relational-databases)generate _query, key_ and _value vectors_ for each part of a data sequence,and use them to compute attention weights through a series of matrix multiplications. To capture the many multifaceted ways tokens might relate to one another, transformer models implement [multi-head attention](https://www.ibm.com/think/topics/grouped-query-attention)across multiple attention blocks _._', 'score': 0.9552}, {'title': 'The Ultimate Guide to Transformer Deep Learning', 'url': 'https://www.turing.com/kb/brief-introduction-to-transformers-and-their-power', 'content': \"Each word in the input sequence is translated one after the other by the six layers of the Transformer encoder. When given a sequence of vectors, a Transformer neural network encodes them and decodes them back into their original forms. For instance, in a machine translation model, the attention mechanism enables the Transformer to convert 'it' into the correct gender in French or Spanish based on all relevant words. A Transformer neural network takes an input sentence and encodes it into two different sequences: One advantage of the Transformer deep learning model over LSTMs and RNNs is that they can process multiple words simultaneously. We can apply a simple feed-forward neural network to each attention vector to transform attention vectors into a form that the next encoder or decoder layer will accept it easily.\", 'score': 0.94787}]\u001b[0m\u001b[32;1m\u001b[1;3m트랜스포머(Transformer)는 자연어 처리 등 시퀀스 데이터를 다루는 딥러닝 모델의 한 종류로, 2017년 논문 \"Attention is All You Need\"에서 처음 제안되었습니다. 기존의 RNN이나 LSTM과 달리 순차적으로 데이터를 처리하지 않고, '어텐션(attention)' 메커니즘을 활용해 입력 시퀀스 내 모든 단어 간의 관계를 한 번에 파악할 수 있어 병렬처리가 가능하고 긴 문맥도 효과적으로 이해할 수 있습니다.\n",
            "\n",
            "직관적으로 설명하면, 트랜스포머는 문장 내 각 단어가 다른 단어들과 얼마나 관련 있는지 '주의(attention)'를 집중해서 계산하고, 이를 바탕으로 문장의 의미를 이해하거나 다음 단어를 예측합니다. 이로 인해 번역, 요약, 질의응답 등 다양한 자연어 처리 작업에서 뛰어난 성능을 보입니다.\n",
            "\n",
            "핵심 논문:\n",
            "- Vaswani et al., \"Attention is All You Need\" (2017): https://arxiv.org/abs/1706.03762\n",
            "\n",
            "좋은 소개 글 및 자료:\n",
            "- 위키피디아: https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture)\n",
            "- StatQuest 유튜브 영상 (영어, 시각적 설명): https://www.youtube.com/watch?v=zxQyTK8quyY\n",
            "- Built In의 단계별 설명: https://builtin.com/artificial-intelligence/transformer-neural-network\n",
            "- arXiv 소개 논문: https://arxiv.org/abs/2304.10557\n",
            "\n",
            "이 자료들은 트랜스포머의 기본 개념, 구조, 어텐션 메커니즘, 그리고 응용 분야를 이해하는 데 도움이 됩니다.\n",
            "\n",
            "출처:\n",
            "https://arxiv.org/abs/1706.03762\n",
            "https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture)\n",
            "https://www.youtube.com/watch?v=zxQyTK8quyY\n",
            "https://builtin.com/artificial-intelligence/transformer-neural-network\n",
            "https://arxiv.org/abs/2304.10557\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "=== 최종 답변 ===\n",
            "\n",
            "트랜스포머(Transformer)는 자연어 처리 등 시퀀스 데이터를 다루는 딥러닝 모델의 한 종류로, 2017년 논문 \"Attention is All You Need\"에서 처음 제안되었습니다. 기존의 RNN이나 LSTM과 달리 순차적으로 데이터를 처리하지 않고, '어텐션(attention)' 메커니즘을 활용해 입력 시퀀스 내 모든 단어 간의 관계를 한 번에 파악할 수 있어 병렬처리가 가능하고 긴 문맥도 효과적으로 이해할 수 있습니다.\n",
            "\n",
            "직관적으로 설명하면, 트랜스포머는 문장 내 각 단어가 다른 단어들과 얼마나 관련 있는지 '주의(attention)'를 집중해서 계산하고, 이를 바탕으로 문장의 의미를 이해하거나 다음 단어를 예측합니다. 이로 인해 번역, 요약, 질의응답 등 다양한 자연어 처리 작업에서 뛰어난 성능을 보입니다.\n",
            "\n",
            "핵심 논문:\n",
            "- Vaswani et al., \"Attention is All You Need\" (2017): https://arxiv.org/abs/1706.03762\n",
            "\n",
            "좋은 소개 글 및 자료:\n",
            "- 위키피디아: https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture)\n",
            "- StatQuest 유튜브 영상 (영어, 시각적 설명): https://www.youtube.com/watch?v=zxQyTK8quyY\n",
            "- Built In의 단계별 설명: https://builtin.com/artificial-intelligence/transformer-neural-network\n",
            "- arXiv 소개 논문: https://arxiv.org/abs/2304.10557\n",
            "\n",
            "이 자료들은 트랜스포머의 기본 개념, 구조, 어텐션 메커니즘, 그리고 응용 분야를 이해하는 데 도움이 됩니다.\n",
            "\n",
            "출처:\n",
            "https://arxiv.org/abs/1706.03762\n",
            "https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture)\n",
            "https://www.youtube.com/watch?v=zxQyTK8quyY\n",
            "https://builtin.com/artificial-intelligence/transformer-neural-network\n",
            "https://arxiv.org/abs/2304.10557\n"
          ]
        }
      ],
      "source": [
        "q = \"트랜스포머가 무엇인가요? 직관적으로 설명하고, 핵심 논문이나 좋은 소개 글 출처도 알려줘.\"\n",
        "resp = executor.invoke({\"input\": q})\n",
        "print(\"\\n=== 최종 답변 ===\\n\")\n",
        "print(resp[\"output\"])\n",
        "\n",
        "# https://poloclub.github.io/transformer-explainer/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "gather": {
          "logged": 1757859358209
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `tavily_search_results_json` with `{'query': '트랜스포머 시리즈 전체 요약'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m[{'title': '[트랜스포머 시리즈요약]트랜스포머6:비스트의서막 보기전 각 시리즈 ...', 'url': 'https://shylian.tistory.com/1774', 'content': '## 검색 레이어\\n\\n샤이리 티스토리\\n\\n### 검색 영역\\n\\n## 상세 컨텐츠\\n\\n### 본문 제목\\n\\n[트랜스포머 시리즈요약]트랜스포머6:비스트의서막 보기전 각 시리즈내용 소개/개봉일/영화/시리즈/트랜스포머 순서/\\n\\n요즘핫한뉴스\\n\\nby 샤이리\\n2023. 6. 4. 11:04\\n\\n### 본문\\n\\n728x90\\n\\n반응형\\n\\n## [트랜스포머 시리즈요약]트랜스포머6:비스트의서막 보기전 각 시리즈내용 소개/개봉일/영화/시리즈/트랜스포머 순서/\\n\\n트랜스포머는 로봇들이 인간의 모습으로 변신하며 전투하는 과학 소설과 애니메이션 시리즈입니다. 이후 이 시리즈는 마이클 베이 감독에 의해 영화로 제작되었습니다. 아래에서는 트랜스포머 영화 시리즈를 각각 설명해 드리겠습니다:\\n\\n### 1. 트랜스포머 (2007) [...] 트랜스포머: 최후의 기사(2017)은 트랜스포머 시리즈의 다섯 번째 영화입니다. 마이클 베이 감독에 의해 제작되었으며, 액션과 과학 소설 요소를 담고 있습니다.   \\n  \\n이번 영화에서는 트랜스포머들과 인류 간의 전쟁이 계속되고 있으며, 그 사이에는 새로운 위협과 동맹이 등장합니다. 사무엘 웨퍼(Sam Witwicky)를 대신하여 주인공으로 등장하는 새로운 인물은 캐드 윗윅(Cade Yeager)입니다. 캐드는 인류와 트랜스포머들의 전쟁에 맞서 싸움을 이어나가며, 그들의 비밀과 운명을 해결하기 위해 노력합니다.   \\n  \\n옵티머스 프라임과 그의 트랜스포머 동료들은 전투를 지속하면서 새로운 위협인 퀸틴타사(Quintessa)에 맞서 싸웁니다. 퀸틴타사는 지구와 사람들을 지배하려는 악의 세력으로 등장하며, 옵티머스 프라임과 트랜스포머들은 그녀의 음모를 막기 위해 최후의 전투를 벌이게 됩니다. [...] 트랜스포머: 패자의 역습(2009)은 트랜스포머 시리즈의 두 번째 영화입니다. 마이클 베이 감독이 다시 한 번 이 영화를 제작하였으며, 액션과 과학 소설 요소를 담고 있습니다.   \\n  \\n영화는 전작에서의 사건 이후의 이야기를 다루고 있습니다. 인류와 트랜스포머들은 악의 세력 디셉티콘으로부터 지구를 보호하기 위해 협력합니다. 옵티머스 프라임과 그의 트랜스포머 동료들은 새로운 적인 허브르트 장군에 맞서 싸우게 됩니다.   \\n  \\n주인공 사무엘 웨퍼(Sam Witwicky) 역할을 다시한번 샤이아 라보프(Shia LaBeouf)가 맡으며, 영화에서는 그와 그의 여자친구인 미카엘라(Bumblebee(번블비)의 운전자)의 로맨틱한 이야기도 소개됩니다.', 'score': 0.79196626}, {'title': '트랜스포머 (애니메이션) - 위키백과, 우리 모두의 백과사전', 'url': 'https://ko.wikipedia.org/wiki/%ED%8A%B8%EB%9E%9C%EC%8A%A4%ED%8F%AC%EB%A8%B8_(%EC%95%A0%EB%8B%88%EB%A9%94%EC%9D%B4%EC%85%98)', 'content': '《트랜스포머》(The Transformers)는 트랜스포머 프랜차이즈로서 최초로 제작된 텔레비전 애니메이션 시리즈이다. 1984년 9월 17일부터 1987년 11월 11일까지 방영되었다. 이 시리즈는 차량이나 다른 물건으로 변신하는 거대 로봇 간의 전쟁을 다룬다. 미국에서 각본 작성과 녹음이 진행되었으며, 애니메이션은 일본과 대한민국에서 제작되었다. 그 스스로는 다카라에에서 제작된 다이아클론과 마이크로맨 완구 라인을 기반으로 하는 해즈브로의 트랜스포머 완구 라인을 소재로 한다. 이 시리즈의 스토리는 두 번째와 세 번째 시즌 사이에 일어나는 이야기인 《유니크론과 변신로보트》(The Transformers: The Movie)로 보충된다. [...] |  |  |\\n --- |\\n| 애니메이션 영화 |  트랜스포머: 더 무비 (1986)  Beast Wars Second: LioConvoy in Imminent Danger!\") (1998)  트랜스포머 프라임 비스트헌터: 프레데콘 라이징 (2013)  트랜스포머 ONE (2024) |\\n| 실사 영화 시리즈 |  트랜스포머 \"트랜스포머 (영화)\") (2007)  트랜스포머: 패자의 역습 (2009)  트랜스포머 3 (2011)  트랜스포머: 사라진 시대 (2014)  트랜스포머: 최후의 기사 (2017)  범블비 \"범블비 (영화)\") (2018)  트랜스포머: 비스트의 서막 (2023) |\\n\\nWikimedia Foundation\\nPowered by MediaWiki [...] 또한 가네다 마사미가 스토리를 마가미 반이 작화를 담당한 애니메이션을 기반으로 한 3개의 만화 시리즈가 제작되었다. 첫 번째 시리즈는 고단샤의 텔레비전 잡지에서 1986년 4월부터 1986년 11월까지, 두 번째 시리즈는 1986년 12월부터 4월까지, 세 번째 시리즈는 1987년 5월부터 7월까지 연재되었다. 첫 번째 만화 시리즈는 텔레비전 애니메이션 시리즈와 동일한 제목이며, 8화로 이뤄져 있다. 두 번째 만화 시리즈의 제목은 《조 로봇토 세이메이다이 모노가타리: 자★도란스포마(超ロボット生命体物語 ザ★トランスフォーマー)》이며, 5화로 이뤄져 있다. 세 번째 만화 시리즈 제목은 《도란스포마 다이센소(トランスフォーマー大戦争)》이며, 3화로 이뤄져 있다.', 'score': 0.7559439}, {'title': '[트랜스포머 실사 영화 시리즈] 줄거리 및 기타 정보 총 정리 - 키노범블러', 'url': 'https://filmbumbler.tistory.com/entry/%ED%8A%B8%EB%9E%9C%EC%8A%A4%ED%8F%AC%EB%A8%B8-%EC%8B%A4%EC%82%AC-%EC%98%81%ED%99%94-%EC%8B%9C%EB%A6%AC%EC%A6%88-%EC%A4%84%EA%B1%B0%EB%A6%AC-%EB%B0%8F-%EA%B8%B0%ED%83%80-%EC%A0%95%EB%B3%B4-%EC%B4%9D-%EC%A0%95%EB%A6%AC', 'content': 'Published Time: 2023-06-09T20:42:12+09:00\\n\\n[트랜스포머 실사 영화 시리즈] 줄거리 및 기타 정보 총 정리\\n\\nImage 1: 블로그 이미지\\n   관리\\n   글쓰기\\n   로그인\\n   로그아웃\\n\\n키노범블러\\n\\n   홈\\n   극장 영화\\n   TV\\n   OTT 서비스\\n   OST\\n   게임\\n\\n목차\\uf103\\n\\n   1. 트랜스포머\\n   2. 트랜스포머: 패자의 역습\\n   메간 폭스의 하차\\n   3. 트랜스포머 3\\n   샤이아 라보프와 휴고 위빙의 하차\\n   4. 트랜스포머: 사라진 시대\\n   5. 트랜스포머: 최후의 기사\\n   시리즈의 재부트: 범블비\\n   6. 트랜스포머: 비스트의 서막\\n\\n반응형\\n\\n× \"Clear search box\")\\n\\n다크 모드\\n\\n\\uf186\\uf185\\n\\n다국어 번역\\n\\nImage 2: 한국어Image 3: 영어Image 4: 중국어 간체Image 5: 중국어 번체Image 6: 일본어Image 7: 스페인어 [...] [[트랜스포머 (Transfomers, 2007)]]( [트랜스포머 시네마틱 유니버스 오리지널 시리즈]의 첫 번째 영화로, 마이클 베이 감독이 연출을 맡은 작품입니다. 영화 속에서 \\'큐브\\'라 불리는 성물 \\'올스파크\\'는 모든 트랜스포머와 그들의 고향인 \\'사이버트론\\'을 창조한 거대한 힘이 담긴 물건인데요. 내전이 일어난 사이버트론에서 옵티머스 프라임이 큐브를 우주로 날려버린 결과, 이 성물이 지구에 불시착하게 되죠. 오토봇들과 디셉티콘들은 지구에서 큐브를 차지하기 위한 전쟁을 벌이는데요. 인간 주인공인 샘 윗위키 (샤이아 라보프扮)는 그의 증조할아버지가 남긴 유품이자, 큐브의 위치를 표시하는 지도 역할을 하는 안경을 소유하고 있어 디셉티콘들의 타깃이 됩니다. 범블비)를 비롯한 오토봇 군단은 디셉티콘 보다 빠르게 큐브를 차지하기 위해 샘과 협력하고, 범블비를 통해 샘은 미카엘라 베인즈 (메간 폭스扮)와 가까워지게 되죠. 영화의 결말에서 샘은 큐브를 직접 손에 쥐고 디셉티콘의 수장인 [...] [트랜스포머 실사 영화 시리즈] 줄거리 및 기타 정보 총 정리\\n\\n범블러 2023. 6. 9.\\n\\n영화 [[트랜스포머: 비스트의 서막 (Transfomers: Rise of the Beasts, 2023)]]( 2023년 6월 6일 개봉했습니다. 오늘은 [[트랜스포머 실사 영화 시리즈]]( 새로운 이야기 등장을 기념하며 그동안 개봉한 시리즈의 줄거리와 시리즈 안팎의 정보를 총 정리하는 시간을 가져보려고 합니다.\\n\\n[![Image 16: 영화 [트랜스포머: 비스트의 서막] 포스터](\\n\\n영화 [트랜스포머: 비스트의 서막] 포스터\\n\\n목차\\uf103\\n\\n   1. 트랜스포머\\n   2. 트랜스포머: 패자의 역습\\n   메간 폭스의 하차\\n   3. 트랜스포머 3\\n   샤이아 라보프와 휴고 위빙의 하차\\n   4. 트랜스포머: 사라진 시대\\n   5. 트랜스포머: 최후의 기사\\n   시리즈의 재부트: 범블비\\n   6. 트랜스포머: 비스트의 서막\\n\\n반응형\\n\\n1. 트랜스포머)', 'score': 0.75464433}, {'title': '트랜스포머 영화의 모든 것: 줄거리, 캐릭터, 그리고 흥행의 비결 - Duky', 'url': 'https://dukymood.tistory.com/126', 'content': \"# Duky\\n\\n트랜스포머 영화 시리즈는 SF 영화 역사에 한 획을 그은 작품으로, 로봇과 인간의 연대기를 그린 독특한 영화입니다. 이 시리즈는 거대한 로봇들이 변신하는 모습과 더불어 인류를 지키기 위한 그들의 투쟁을 다루며, 전 세계적으로 많은 팬을 확보해왔습니다. 수많은 속편과 파생 작품들이 등장할 정도로 흥행에 성공한 이 영화는, 단순한 오락 이상의 의미를 가지며 대중에게 큰 인상을 남겼습니다.\\n\\n트랜스포머는 원래 애니메이션과 장난감에서 시작하여 영화로 재탄생한 경우로, 스토리의 깊이와 시각적 효과를 통해 영화 산업에 새로운 표준을 제시했습니다. 감독 마이클 베이의 강력한 액션 연출과 시각 효과는 전 세계의 팬들에게 시리즈 전체를 환상적인 경험으로 만들었습니다. 로봇 캐릭터들의 대립과 그 안에 얽힌 감정적인 요소들은 영화 팬들로 하여금 지속적으로 관심을 갖게 만들었습니다. 옵티머스 프라임과 범블비 같은 캐릭터들은 이제 대중문화의 상징적인 인물로 자리 잡았습니다. [...] 트랜스포머 영화는 2007년 첫 번째 영화가 개봉된 이후, 수많은 속편과 스핀오프를 통해 점차 세계관을 확장해왔습니다. 이러한 영화적 확장은 각기 다른 시점에서의 로봇들의 전쟁, 그리고 인간과의 관계를 보다 깊이 있게 탐구하는 데 중점을 두고 있습니다. 매력적인 비주얼 효과와 고유한 스토리텔링 방식은 트랜스포머 시리즈를 단순한 액션 영화 이상의 작품으로 만들었으며, 팬들에게는 매번 큰 기대를 주는 이벤트로 자리매김하고 있습니다.\\n\\n## 트랜스포머의 탄생 배경과 원작\\n\\n트랜스포머의 기원은 1980년대의 애니메이션과 장난감 라인에서 시작되었습니다. 해즈브로와 타카라 토미가 공동으로 개발한 이 시리즈는 '자동차에서 로봇으로 변신'이라는 획기적인 아이디어로 큰 인기를 얻었습니다. 그 후 애니메이션 시리즈와 코믹스를 통해 이야기가 더욱 확장되었고, 결국 할리우드에서 영화로 제작하게 되었습니다. 이 배경에는 단순한 장난감을 넘어서는 세계관 확장과 캐릭터의 고유한 매력이 있었습니다. [...] ## 시리즈의 확장: 속편과 스핀오프\\n\\n트랜스포머 시리즈는 첫 번째 영화의 성공 이후, 여러 속편들이 제작되었습니다. '트랜스포머: 패자의 역습'(2009), '트랜스포머: 다크 오브 더 문'(2011), '트랜스포머: 사라진 시대'(2014), 그리고 '트랜스포머: 최후의 기사'(2017)가 그 예입니다. 각 영화는 새로운 캐릭터들과 이야기의 전개를 통해 트랜스포머 세계관을 확장해 나갔습니다.\\n\\n이와 함께, 2018년에는 범블비를 주인공으로 한 스핀오프 영화 '범블비'가 개봉되었습니다. 이 영화는 이전의 트랜스포머 시리즈와는 달리, 좀 더 감성적이고 인간적인 이야기에 초점을 맞추어 많은 팬들에게 큰 사랑을 받았습니다. 특히, 1980년대의 배경을 통해 원작 애니메이션 팬들에게 향수를 불러일으키는 장면들이 많았으며, 범블비의 따뜻한 면모를 부각시켰습니다.\\n\\n## 마이클 베이의 연출 스타일\", 'score': 0.75049835}, {'title': '트랜스포머 시리즈 보는 순서 (트랜스포머 원, 비스트의 서막 포함)', 'url': 'https://m.blog.naver.com/nyria99/223546515460', 'content': \"로그인이 필요합니다.\\n\\nMy Menu 닫기\\n\\n본문 바로가기\\n\\n검색\\n\\n영화 정보\\n\\n트랜스포머 시리즈 보는 순서 (트랜스포머 원, 비스트의 서막 포함)\\n\\n유오빠\\n\\n2024. 8. 13. 15:00\\n\\n이웃추가\\n\\n 본문 폰트 크기 조정\\n  가\\n 공유하기\\n URL복사\\n 신고하기\\n\\n존재하지 않는 이미지입니다.\\n\\n영화 트랜스포머 시리즈 전체에 대해 정리 하겠습니다.\\n\\n\\u200b\\n\\n트랜스포머는 지금까지 오리지널 시리즈 5편, 리부트 시리즈 2편이 출시되었고\\n\\n2024년 9월에 개봉 예정인 애니메이션 영화 <트랜스포머: 원>까지 포함하면 총 8편의 극장용 작품이 제작된 상황입니다.\\n\\n\\u200b\\n\\n우선 여덟 편의 작품에 대해 보는 순서를 정리하면 다음과 같습니다.\\n\\n존재하지 않는 이미지입니다.\\n\\n> 오리지널 시리즈 (삼부작)\\n\\n존재하지 않는 이미지입니다.\\n\\n대단한 시리즈물입니다.\\n\\n새로운 작품이 나올때마다 더더욱 완성도가 무너져 내려서, 앞작품들을 재평가하게 해주는 패턴을 보유하고 있습니다.\\n\\n\\u200b [...] > 오리지널 시리즈 (4,5편)\\n\\n존재하지 않는 이미지입니다.\\n\\n전편으로부터 5년 후를 배경으로 하고 있습니다. 로봇들의 전쟁으로 지구가 폐허가 되어버리자, 미국 정부는 트랜스포머를 모두 사살해 버리는 특단의 조치를 취하게 되고, 오토봇들은 더 이상 인간들과 섞여 사는 건 불가능하다고 판단하고 뿔뿔이 흩어져 지구 곳곳에 은신하며 살고 있다는 설정을 가지고 시작합니다.\\n\\n\\u200b\\n\\n사실 4,5편도 오리지널로 함께 묶여있긴 하지만, 앞의 삼부작과는 전혀 연결고리가 없다고 봐도 됩니다. 인간 주인공들도 모두 바뀌었고, 옵티머스 프라임, 범블비 등의 주요 오토봇들이 그대로 등장을 하긴 하지만 전작을 봐야할 이유는 딱히 없습니다. 그냥 4,5편만 독립적으로 즐기셔도 됩니다.\\n\\n\\u200b [...] 트랜스포머 시네마틱 유니버스의 첫 번째 애니메이션 영화인데, 일단 감독이 믿음직스럽습니다. 애니메이션계의 걸작of걸작인 <토이스토리 4>의 감독이었던 '조시 쿨리'가 이 작품을 맡고 있고, 크리스 헴스워스, 스칼렛 요한슨 등 성우진도 화려한 편입니다.\\n\\n\\u200b\\n\\n현재까지 공개된 정보는, 전쟁 이전의 사이버트론을 주 무대로 하고 있으며, 트랜스포머 시리즈의 두 주역인 '옵티머스 프라임'과 '메가트론'이 한때 형제와도 같은 친구 사이였는데, 그들이 어떻게 사이버트론 행성의 운명을 바꾸고 영원한 숙적이 되었는지 그 시작에 대한 이야기를 다루고 있다고 합니다. 즉 가장 앞선 연대기를 다루는 프리퀄 개념의 작품으로 예상됩니다.\\n\\n\\u200b\\n\\n\\u200b\\n\\n에일리언과 컨저링 시리즈 보는 순서를 링크하며 마무리 합니다.\\n\\n\\u200b\\n\\n에이리언: 로물루스 정보 (예고편, 에일리언 시리즈 보는 순서, 개봉일 정보 등)\", 'score': 0.7467494}, {'title': '트랜스포머 (영화 시리즈) - 위키백과, 우리 모두의 백과사전', 'url': 'https://ko.wikipedia.org/wiki/%ED%8A%B8%EB%9E%9C%EC%8A%A4%ED%8F%AC%EB%A8%B8_(%EC%98%81%ED%99%94_%EC%8B%9C%EB%A6%AC%EC%A6%88)', 'content': ':   세번째 시즌. 시리즈 최초로 3D로 촬영된 작품이다. 기존 여배우 메건 폭스가 하차하고 로지 헌팅턴화이틀리가 새로 캐스팅됐다.\\n\\n 트랜스포머: 사라진 시대(2014) : 로튼 토마토 지지율 18%\\n\\n:   네번째 시즌. 전작으로부터 5년뒤를 배경으로 한 작품. 기존 배우 샤이아 러버프도 메간 폭스의 뒤를 이어 시리즈에서 하차했고 마크 월버그와 니콜라 펠츠를 새로 캐스팅한 뒤 남녀주인공을 부녀관계로 바꾸었지만 스토리가 빈약하다는 평가가 나왔다.\\n\\n 트랜스포머: 최후의 기사(2017) : 로튼 토마토 지지율 15%\\n\\n:   다섯번째 시즌. 마크 월버그만 나오고 니콜라 펠츠는 목소리로만 출연. 또 언제나 인간편이었던 옵티머스 프라임이 쿠인테사에게 세뇌당해 동료 로봇들을 해친다는 파격적인 내용으로 개봉전부터 화제를 모았지만 게봉후 시리즈 사상 최악이라는 혹평을 받았다.\\n\\n## 작품 목록\\n\\n[편집&action=edit&section=2 \"부분 편집: 작품 목록\")] [...] 1번째 작품부터 5번째 작품까지 모두 마이클 베이가 감독을 맡았으며 제작은 스티븐 스필버그가 참여하였다. 또한 하스브로 CEO 브라이언 골드너도 제작에 참여하였다.\\n\\n 트랜스포머(2007) : 로튼 토마토 지지율 57%\\n\\n:   첫번째 시즌. 기존 애니메이션의 로봇들을 컴퓨터 그래픽으로 잘 구현했다는 평가를 받았고 스토리, 그래픽, 연출 모든 면에서 대호평을 받았다. 이는 세계적으로 로봇팬을 양성하는 계기가 됐다.\\n\\n 트랜스포머: 패자의 역습(2009) : 로튼 토마토 지지율 19%\\n\\n:   두번째 시즌. 전작과 이어지며 제작자인 스티븐 스필버그가 까메오로 나오기도 한다. 흥행에는 성공했지만 일각에서는 스토리가 전작에 비해 많이 엉성해졌다는 평가가 나오는등 호불호가 상당히 갈린다.\\n\\n 트랜스포머: 달의 어둠(2011) : 로튼 토마토 지지율 35% [...] 《트랜스포머 영화 시리즈》(영어: Transformers)는 2007년 파라마운트 픽처스와 드림웍스가 하스브로와 타카라토미 장난감인 트랜스포머로 기반으로 하여 만든 프랜차이즈이다. 영화 세계관을 의미할 때 트랜스포머 시네마틱 유니버스(영어: Transformers Cinematic Universe)라고도 한다.\\nTF WIKI에서는 \"TYRAN\"이라는 세계관이다.\\n그리고 2006년~\\n2007년 영화가 제작되고 있을때 대체현실게임 \"SECTOR SEVEN\" 이라고 영화 떡밥등 숨겨진 진실,음모론이 있으며,\\n실제로 트랜스포머가 존재하고, 2007 실사영화가 사실 극중극이라는 설정으로 나온다.\\n그리고 NBE들의 첫 생김새는 그림록,범블비,레이저비크,리플텍터,스타스크림등 G1 디자인을 가지고 있다.\\n\\n## 내용\\n\\n[편집&action=edit&section=1 \"부분 편집: 내용\")]', 'score': 0.72675586}, {'title': '트랜스포머 시리즈 - 나무위키', 'url': 'https://namu.wiki/w/%ED%8A%B8%EB%9E%9C%EC%8A%A4%ED%8F%AC%EB%A8%B8%20%EC%8B%9C%EB%A6%AC%EC%A6%88', 'content': '트랜스포머 시리즈 - 나무위키\\n\\n\\n\\n최근 변경최근 토론\\n\\n특수 기능\\n\\n\\n\\n\\n\\n\")3. 특징4. 역사5. 작품 목록\\n\\n5.1. 제너레이션 1 세계관\\n\\n5.1.1. 미일공용\\n\\n5.1.1.1. 구 시리즈5.1.1.2. 신 시리즈\\n\\n5.1.2. 미국 쪽 전개\\n\\n5.1.2.1. 본편5.1.2.2. 유니버스/타임라인 시리즈\\n\\n5.1.3. 일본 쪽 전개\\n\\n5.1.3.1. 초기5.1.3.2. 빅토리 사가5.1.3.3. 포스트 빅토리\\n\\n5.2. 밀레니엄 시리즈\\n\\n5.2.1. 유니크론 트릴로지5.2.2. 실사영화 시리즈\\n\\n5.3. 얼라인드 세계관5.4. 기타\\n\\n6. 각종 오해7. 참고 문서8. 외부 사이트9. 콜라보레이션10. 슈퍼로봇대전 시리즈 참전 떡밥\\n\\nThe Transformers! More than meets the eye!\\n\\n트랜스포머 \"트랜스포머(트랜스포머)\")! 눈으로 보이는 게 다는 아니지 [...] [ 제너레이션 1 세계관 ] 미국 스토리라인일본 스토리라인 트랜스포머 (1983~1986) \"트랜스포머(애니메이션)\") 극장판 (1986)스크램블 시티 (1986) 리버스 (1987)헤드마스터즈 (1987) -마스터포스 (1988) 트랜스포머 V (1989~1993) 트랜스포머 존 비스트 워즈 (1996~1998) 비스트 머신즈 (1999~2000)비스트 워즈 세컨드 (1998) 비스트 워 네오 (1999) 트랜스포머 카로봇 (2000) 로봇 마스터즈 (2004) 프라임 워즈 (2016~2018) WFC (2020~2022) \"워 포 사이버트론 트릴로지(애니메이션)\") [ 유니크론 트릴로지 ] 아마다 (2002)에너존 (2004)사이버트론 (2005) [ 얼라인드 세계관 ] 본편 트랜스포머 프라임 (2010~2013)트랜스포머 어드벤처 (2015~2017) \"트랜스포머: 로보츠 인 디스가이즈(2015년)\") 외전 트랜스포머 GO (2013)레스큐 봇 (2010~2016) [ 기타 [...] 기존의 로봇 만화가 주인공쪽은 멋진 영웅들이고, 악당들은 그냥 1회용 괴인으로 소비되는 디자인이었던 것에 비해 악당들도 하나하나 개인의 스토리를 넣어 개성을 부여했으며 드라마도 잘 전개했다.\\n\\n> One shall stand, one shall fall(하나는 일어서고 하나는 무너질 것이다.)\\n> \\n> 오토봇, 옵티머스 프라임과 디셉티콘, 메가트론의 악연을 상징하는 문구\\n\\n트랜스포머 시리즈는 1984년에 첫 작품인 G1이 방송을 시작한 이래로 40여 년간 사랑을 받아왔으며, 2007년에는 실사영화 \"트랜스포머(영화)\")로도 만들어져 크게 성공했다. 특히 첫 실사영화는 북미권과 일본 위주로 인기있던 프랜차이즈가 한국을 포함한 전세계적으로 인기를 확장하고 인지도를 높이는 계기가 됐을 뿐만 아니라 트랜스포머 프랜차이즈의 인지도를 전세계적으로 늘리고, 다른 로봇 만화의 실사화의 포문을 연 작품으로 평가받는다.', 'score': 0.71758664}, {'title': '[영화 리뷰] 트랜스포머 (1 2 3 4 5 총정리, 결말, 시리즈 전체 보는 순서)', 'url': 'https://blog.naver.com/nyria99/223678769150?viewType=pc', 'content': '1편에서 두 로봇 진영간의 치열한 싸움에서 지구를 구한 지 2년이 지나 평범한 일상으로 돌아간 샘은 여자친구인 미카엘라와 범블비와 떨어져 대학에 진학', 'score': 0.6530611}, {'title': '트랜스 포머 시리즈 정리 해주세요 ㅣ 궁금할 땐, 아하!', 'url': 'https://www.a-ha.io/questions/49695ea0639ceb12ac55fa7f3a392d9c', 'content': '- 인간과 로봇들 간의 대치와 전투, 영웅들의 이야기를 중심으로 전개됩니다. - 주요 등장인물: 옵티머스 프라임(주인공, 오토봇), 메갈로데나(악당,', 'score': 0.64746445}, {'title': '트랜스포머(영화) - 나무위키', 'url': 'https://namu.wiki/w/%ED%8A%B8%EB%9E%9C%EC%8A%A4%ED%8F%AC%EB%A8%B8(%EC%98%81%ED%99%94)', 'content': '5#s-5). 완구/%EC%99%84%EA%B5%AC \"트랜스포머(영화)/완구\")6#s-6). 줄거리/%EC%A4%84%EA%B1%B0%EB%A6%AC \"트랜스포머(영화)/줄거리\")7#s-7). 평가\\n\\n7.1#s-7.1). 긍정적 평가7.2#s-7.2). 부정적 평가7.3#s-7.3). 총평\\n\\n8#s-8). 흥행9#s-9). 제작 비화\\n\\n9.1#s-9.1). 디자인9.2#s-9.2). 특수효과9.3#s-9.3). 음악\\n\\n10#s-10). 옥에 티11#s-11). 해외 방영\\n\\n11.1#s-11.1). KBS 방송판 성우진11.2#s-11.2). 한국어 제작(KBS)\\n\\n12#s-12). 기타\\n\\n1.#toc)개요(\\n\\n스티븐 스필버그 제작, 마이클 베이 감독. \\'해즈브로\\'의 인기 변신 완구 시리즈, 트랜스포머 시리즈를 바탕으로 만든 영화. 트랜스포머 실사영화 시리즈의 첫 번째 작품이다. 관람 등급은 12세 이상 관람가. [...] 포스터를 봐도 알 수 있지만 영화 제목이 영어로 Transformers(트랜스포머스)다. 한국어는 단수/복수 구분이 엄격하지 않아 외국어를 옮길 때에 복수 표현을 빼는 것을 권장하므로 딱히 문제가 되지는 않는다.\\n\\n2.#toc)예고편(\\n\\n티저 예고편\\n\\n1차 예고편\\n\\n메인 예고편\\n\\n3.#toc)시놉시스(\\n\\n평범한 고등학생, 샘 윗위키는 졸업 전 좋은 성적을 받은 것을 계기로 아버지로부터 중고차를 선물받게 된다. 그런데 알고 보니 이 중고차는 먼 외계에서 온 변신 로봇생명체였으며, 샘을 노리는 다른 세력으로부터 지키기 위해 지구에 위장해 들어와 있던 것이었다. 샘은 자신이 가진 증조부의 유품이 그들의 성물, 올스파크로 인도하는 지도라는 사실을 알게 되고, 오토봇과 디셉티콘 사이의 싸움에 휘말리게 된다.\\n\\n4.#toc)등장인물(\\n\\n### 4.1.#toc)오토봇(\\n\\n   옵티머스 프라임 \"옵티머스 프라임(트랜스포머 실사영화 시리즈)\")\\n\\n알트 모드: 피터빌트 379 [...] 그리고 본작이 흥행에 성공한 덕분에 트랜스포머 프랜차이즈의 인지도가 세계적으로 크게 상승하면서 새로운 전성기가 열렸기에 프랜차이즈 전체 역사에서 기여가 큰 작품이다.\\n\\n또한 트랜스포머의 의의라고 할 수 있는 변신 능력을 잘 표현했다. 특히 블랙아웃, 바리케이드, 그리고 프렌지가 변신 능력으로 이곳저곳에 침투해서 정보를 획득하거나 사보타주를 하는 장면을 통해 변신 능력의 위험성과 진가를 잘 나타냈다.( \"상술한 \\\\\"사람과 기계의 우정\\\\\"과 이런 변신 장면들 때문에 당시 영화를 본 사람들이 (매트릭스를 보고는 혹시 이 세계가 가상현실이 아닐까 상상하는 것처럼) 혹시 자기 차가 트랜스포머가 아닌가 상상하곤 했다.\")\\n\\n### 7.2.#toc)부정적 평가(\\n\\n그러나 후속작들에서 항상 지적받는, 시리즈를 망친 문제점들이 본작에도 꽤 많이 존재한다. 대표적으로 개연성이 떨어지는 스토리 전개, 트랜스포머와 인간을 가리지 않고 캐릭터들의 비중 배분이 영 좋지 않은 문제 등이 있다.', 'score': 0.635879}, {'title': '트랜스포머 시리즈 애니/소설 정리 : 네이버 블로그', 'url': 'https://blog.naver.com/beemeal0601/223626595093', 'content': '오토봇과 디셉티콘이 퀸테슨을 만나는 이야기로 적의 적은 나의 아군 이야기.. \\u200b. Transformers: The Covenant of Primus. 프라이머스의 언약. 위에', 'score': 0.6108487}, {'title': '트랜스포머 시리즈의 세계관 요약글 (수정) - 디시인사이드', 'url': 'https://m.dcinside.com/board/transformers/90133', 'content': '트랜스포머를 처음 입문한 사람들은 쏟아져나오는 수많은 세계관에 당혹해 할 수 있는데 이유는 해즈브로와 타카라토미가 리부트를 반복하면서 수많은', 'score': 0.57236487}, {'title': '트랜스포머 애니메이션 시리즈 봐야 할까? : r/transformers - Reddit', 'url': 'https://www.reddit.com/r/transformers/comments/1fjpoj8/should_i_watch_the_transformers_animated_series/?tl=ko', 'content': '등장인물이 적어서 각 캐릭터가 빛을 발할 수 있고, 캐릭터 묘사와 캐릭터 발전이 매우 뛰어나고, 성우 연기는 프랜차이즈 전체에서 가장 일관되게 훌륭한', 'score': 0.5660431}, {'title': '트랜스포머(영화)/줄거리 - 나무위키', 'url': 'https://namu.wiki/w/%ED%8A%B8%EB%9E%9C%EC%8A%A4%ED%8F%AC%EB%A8%B8(%EC%98%81%ED%99%94)/%EC%A4%84%EA%B1%B0%EB%A6%AC', 'content': '디셉티콘 일당이 총출동하여 오토봇 일행을 뒤따라오고, 결국 도심 한복판에서 오토봇과 디셉티콘 간 최후의 결전이 벌어진다. 하지만 고군분투하던 메가트론도 샘이 발동시킨 올스파크의 어마어마한 에너지를 심장부에 정통으로 맞고 숨을 거둔다. 디셉티콘을 물리치긴 했지만, 올스파크가 대부분 소진되어 버렸으니 로봇 종족들의 고향별 사이버트론을 회생시킬 기회는 사라져버렸다.\\n\\n섹터 7는 폐쇄되고 메가트론을 비롯한 디셉티콘의 시체는 로렌시아 해구에 수장된다.\\n\\n옵티머스 프라임과 오토봇 일행은 미국 정부와 모종의 거래를 맺고 지구에 남기로 하고, 우주에 흩어져 있는 오토봇 동료들에게 지구를 찾아오라는 메시지를 전한다. 샘과 미카엘라는 연인 사이가 되며 영화는 끝난다.\\n\\n쿠키 영상으로 샘의 부모인 론 윗위키와 주디 윗위키의 임터뷰가 등장한다. 최근에 외계인 관련 소식을 들은 거 없냐는 기자의 질문에, 주디는 자유 국가에서 외계인이 나타나면 정부가 제일 먼저 발표할거라고 말한다. [...] 아득히 먼 옛날부터 존재해 온 거대한 금속 정육면체 \\'올스파크\\' 또는 \\'큐브\\'. 올스파크는 만물을 창조하고 생명을 불어넣는 힘을 지녔고, 그로 인해 변신로봇 종족이 탄생했다.하지만 치열한 전쟁의 여파로 그들의 고향별 사이버트론은 불모의 땅이 되어 버렸고, 올스파크는 머나먼 우주로 날아가 버렸다. 로봇들은 올스파크의 힘으로 고향을 재건하기 위해 온 우주로 흩어져 수색을 시작했다.\\n\\n현재의 어느 날, 중동 카타르에 레녹스와 동료들이 탄 비행기들이 이동한다. 저녁이 되자 미군 특전사령부에 수상한 헬기가 찾아온다. 미군은 F-22 전투기들을 보내 헬기를 호위하게 하지만 헬기의 번호를 조회한 결과 이미 몇 개월전에 아프가니스탄에서 격추된 헬기였다. 헬기 속에 있는 조종사가 번쩍거리더니 헬기는 로터를 멈추고 변신한 후 거대한 로봇 \"블랙아웃(트랜스포머 실사영화 시리즈)\")이 되어 미군을 공격하기 시작한다. [...] 그 무렵 정체를 알 수 없는 컴퓨터 바이러스로 전 세계 네트워크가 마비되어 모든 통신 수단이 무용지물이 된다. 인류의 반격이 생각보다 거센 것을 깨닫고 디셉티콘이 조치를 취한 것. 미 국방장관을 비롯하여 카타르 미군 특전사령부에서 천신만고 끝에 살아남은 윌리엄 레녹스 대위와 레인저 대원들, 에어 포스 원을 해킹한 범인을 추적하던 해킹 전문가들이 비밀기관 섹터7의 본부로 모인다. 오래전부터 로봇 종족의 존재를 알아차리고 감시해 온 섹터7의 본부는 후버 댐의 지하에 위치했는데, 놀랍게도 그 안에는 메가트론과 올스파크가 보관 중이었다. 과거 후버 대통령이 자신의 이름을 딴 댐을 세워서 올스파크를 은폐하고, 올스파크와 메가트론을 연구하기 위해 섹터7을 창설했던 것이다.\\n\\n> This is Starscream. All Decepticons, mobilize.\\n> \\n> 여기는 스타스크림이다. 모든 디셉티콘들은 집결하라.', 'score': 0.539833}, {'title': '트랜스포머(애니메이션) - 나무위키', 'url': 'https://namu.wiki/w/%ED%8A%B8%EB%9E%9C%EC%8A%A4%ED%8F%AC%EB%A8%B8(%EC%95%A0%EB%8B%88%EB%A9%94%EC%9D%B4%EC%85%98)', 'content': '트랜스포머 프랜차이즈 최초의 애니메이션. 미국의 완구회사 해즈브로는 일본의 타카라로부터 마이크로맨, 다이아클론 등의 미국 판권을 사들인 후, 홍보', 'score': 0.3408586}]\u001b[0m\u001b[32;1m\u001b[1;3m트랜스포머 시리즈는 거대한 로봇들이 인간의 모습이나 차량 등으로 변신하며 벌어지는 전투와 모험을 다룬 SF 프랜차이즈입니다. 원래 1980년대 애니메이션과 장난감에서 시작해, 이후 마이클 베이 감독의 실사 영화 시리즈로 크게 인기를 끌었습니다.\n",
            "\n",
            "주요 내용은 고향별 사이버트론에서 내전이 벌어진 후, 옵티머스 프라임과 메가트론을 비롯한 로봇들이 지구로 와서 올스파크라는 강력한 힘을 가진 성물을 두고 오토봇(선한 로봇)과 디셉티콘(악한 로봇) 간의 전쟁을 벌이는 이야기입니다. 인간 주인공 샘 윗위키와 그의 친구들이 이 전쟁에 휘말리면서 이야기가 전개됩니다.\n",
            "\n",
            "영화 시리즈는 다음과 같이 전개됩니다:\n",
            "1. 트랜스포머 (2007) - 첫 실사 영화로, 올스파크를 둘러싼 오토봇과 디셉티콘의 전쟁이 시작됩니다.\n",
            "2. 트랜스포머: 패자의 역습 (2009) - 전작 이후의 이야기로, 새로운 적과의 전투가 벌어집니다.\n",
            "3. 트랜스포머 3: 달의 어둠 (2011) - 달에 숨겨진 비밀과 음모가 드러납니다.\n",
            "4. 트랜스포머: 사라진 시대 (2014) - 전작들 이후 5년 후를 배경으로 하며, 새로운 인간 주인공과 트랜스포머들이 등장합니다.\n",
            "5. 트랜스포머: 최후의 기사 (2017) - 옵티머스 프라임이 적에게 세뇌당하는 등 파격적인 전개가 있습니다.\n",
            "6. 범블비 (2018) - 시리즈의 스핀오프로, 범블비를 주인공으로 한 감성적인 이야기입니다.\n",
            "7. 트랜스포머: 비스트의 서막 (2023) - 새로운 이야기와 캐릭터들이 등장하는 최신작입니다.\n",
            "\n",
            "또한, 2024년에는 애니메이션 영화 '트랜스포머: 원'이 개봉 예정으로, 사이버트론 행성에서 옵티머스 프라임과 메가트론의 과거 이야기를 다룰 예정입니다.\n",
            "\n",
            "트랜스포머 시리즈는 로봇들의 변신과 전투, 인간과 로봇 간의 우정과 갈등, 그리고 거대한 음모와 전쟁을 중심으로 전개되며, 각 작품마다 새로운 캐릭터와 스토리로 세계관을 확장해왔습니다.\n",
            "\n",
            "출처:\n",
            "https://shylian.tistory.com/1774\n",
            "https://ko.wikipedia.org/wiki/%ED%8A%B8%EB%9E%9C%EC%8A%A4%ED%8F%AC%EB%A8%B8_(%EC%95%A0%EB%8B%88%EB%A9%94%EC%9D%B4%EC%85%98)\n",
            "https://filmbumbler.tistory.com/entry/%ED%8A%B8%EB%9E%9C%EC%8A%A4%ED%8F%AC%EB%A8%B8-%EC%8B%A4%EC%82%AC-%EC%98%81%ED%99%94-%EC%8B%9C%EB%A6%AC%EC%A6%88-%EC%A4%84%EA%B1%B0%EB%A6%AC-%EB%B0%8F-%EA%B8%B0%ED%83%80-%EC%A0%95%EB%B3%B4-%EC%B4%9D-%EC%A0%95%EB%A6%AC\n",
            "https://dukymood.tistory.com/126\n",
            "https://m.blog.naver.com/nyria99/223546515460\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "=== 최종 답변 ===\n",
            "\n",
            "트랜스포머 시리즈는 거대한 로봇들이 인간의 모습이나 차량 등으로 변신하며 벌어지는 전투와 모험을 다룬 SF 프랜차이즈입니다. 원래 1980년대 애니메이션과 장난감에서 시작해, 이후 마이클 베이 감독의 실사 영화 시리즈로 크게 인기를 끌었습니다.\n",
            "\n",
            "주요 내용은 고향별 사이버트론에서 내전이 벌어진 후, 옵티머스 프라임과 메가트론을 비롯한 로봇들이 지구로 와서 올스파크라는 강력한 힘을 가진 성물을 두고 오토봇(선한 로봇)과 디셉티콘(악한 로봇) 간의 전쟁을 벌이는 이야기입니다. 인간 주인공 샘 윗위키와 그의 친구들이 이 전쟁에 휘말리면서 이야기가 전개됩니다.\n",
            "\n",
            "영화 시리즈는 다음과 같이 전개됩니다:\n",
            "1. 트랜스포머 (2007) - 첫 실사 영화로, 올스파크를 둘러싼 오토봇과 디셉티콘의 전쟁이 시작됩니다.\n",
            "2. 트랜스포머: 패자의 역습 (2009) - 전작 이후의 이야기로, 새로운 적과의 전투가 벌어집니다.\n",
            "3. 트랜스포머 3: 달의 어둠 (2011) - 달에 숨겨진 비밀과 음모가 드러납니다.\n",
            "4. 트랜스포머: 사라진 시대 (2014) - 전작들 이후 5년 후를 배경으로 하며, 새로운 인간 주인공과 트랜스포머들이 등장합니다.\n",
            "5. 트랜스포머: 최후의 기사 (2017) - 옵티머스 프라임이 적에게 세뇌당하는 등 파격적인 전개가 있습니다.\n",
            "6. 범블비 (2018) - 시리즈의 스핀오프로, 범블비를 주인공으로 한 감성적인 이야기입니다.\n",
            "7. 트랜스포머: 비스트의 서막 (2023) - 새로운 이야기와 캐릭터들이 등장하는 최신작입니다.\n",
            "\n",
            "또한, 2024년에는 애니메이션 영화 '트랜스포머: 원'이 개봉 예정으로, 사이버트론 행성에서 옵티머스 프라임과 메가트론의 과거 이야기를 다룰 예정입니다.\n",
            "\n",
            "트랜스포머 시리즈는 로봇들의 변신과 전투, 인간과 로봇 간의 우정과 갈등, 그리고 거대한 음모와 전쟁을 중심으로 전개되며, 각 작품마다 새로운 캐릭터와 스토리로 세계관을 확장해왔습니다.\n",
            "\n",
            "출처:\n",
            "https://shylian.tistory.com/1774\n",
            "https://ko.wikipedia.org/wiki/%ED%8A%B8%EB%9E%9C%EC%8A%A4%ED%8F%AC%EB%A8%B8_(%EC%95%A0%EB%8B%88%EB%A9%94%EC%9D%B4%EC%85%98)\n",
            "https://filmbumbler.tistory.com/entry/%ED%8A%B8%EB%9E%9C%EC%8A%A4%ED%8F%AC%EB%A8%B8-%EC%8B%A4%EC%82%AC-%EC%98%81%ED%99%94-%EC%8B%9C%EB%A6%AC%EC%A6%88-%EC%A4%84%EA%B1%B0%EB%A6%AC-%EB%B0%8F-%EA%B8%B0%ED%83%80-%EC%A0%95%EB%B3%B4-%EC%B4%9D-%EC%A0%95%EB%A6%AC\n",
            "https://dukymood.tistory.com/126\n",
            "https://m.blog.naver.com/nyria99/223546515460\n"
          ]
        }
      ],
      "source": [
        "q = \"트랜스포머가 참 재미있었어. 전체 시리즈를 요약해줘\"\n",
        "resp = executor.invoke({\"input\": q})\n",
        "print(\"\\n=== 최종 답변 ===\\n\")\n",
        "print(resp[\"output\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "gather": {
          "logged": 1757859369213
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `google_serper_news_search` with `transformer model latest news`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[38;5;200m\u001b[1;3mHD Hyundai Electric Co. announced on Monday that it has secured a monumental 279 billion-w. Classifying scattered Bengali text is the primary focus of this study, with an emphasis on explainability in Natural Language Processing (NLP) for... With the rise of Transformer architectures, deep learning applications have gradually shifted from traditional convolutional neural networks to Transformers... HD Hyundai Electric said Monday it has won a 279 billion-won ($200.4 million) order to supply ultra high-voltage transformers to a United States-based... Dialog Guests | Jianzhong Li, Lukasz Kaiser. The development speed of large intelligent systems is so rapid that it's almost impossible to keep up. New... New research paper reveals the missing link between transformers and the brain; New post-transformer architecture imitates a scale-free, biological neural... In recent years, large language models (LLMs) built on the transformer architecture have fundamentally transformed the landscape of natural language... Researchers have unveiled a new development in machine learning that bridges the gap between two prominent models: transformers and recurrent neural... More than 800 games and applications feature RTX technologies, and each week new games integrating NVIDIA DLSS, NVIDIA Reflex, and advanced ray-traced... IBM just released Granite 4.0, an open-source LLM family that swaps monolithic Transformers for a hybrid Mamba-2/Transformer stack to cut serving memory...\u001b[0m\u001b[32;1m\u001b[1;3m최근 뉴스에 따르면, 트랜스포머(transformer) 모델과 관련해 다음과 같은 소식들이 있습니다:\n",
            "\n",
            "1. 트랜스포머 아키텍처의 발전으로 딥러닝 응용이 전통적인 합성곱 신경망(CNN)에서 트랜스포머 기반 모델로 점차 이동하고 있습니다.\n",
            "2. 대형 언어 모델(LLM)들이 트랜스포머 아키텍처를 기반으로 자연어 처리 분야를 근본적으로 변화시키고 있습니다.\n",
            "3. IBM은 기존의 단일 트랜스포머 모델을 대체하는 하이브리드 Mamba-2/Transformer 스택을 도입한 Granite 4.0이라는 오픈소스 LLM 패밀리를 출시해 메모리 사용량을 줄이고 있습니다.\n",
            "4. 최근 연구에서는 트랜스포머와 뇌 신경망 간의 연결고리를 밝히는 연구도 진행되고 있습니다.\n",
            "\n",
            "이 외에도 HD Hyundai Electric이 미국에 초고압 변압기를 공급하는 계약을 체결하는 등 'transformer'라는 단어가 전기 변압기 분야에서도 언급되고 있으니, 문맥에 따라 구분이 필요합니다.\n",
            "\n",
            "출처:\n",
            "https://www.google.com/search?q=transformer+model+latest+news\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "=== 최종 답변 ===\n",
            "\n",
            "최근 뉴스에 따르면, 트랜스포머(transformer) 모델과 관련해 다음과 같은 소식들이 있습니다:\n",
            "\n",
            "1. 트랜스포머 아키텍처의 발전으로 딥러닝 응용이 전통적인 합성곱 신경망(CNN)에서 트랜스포머 기반 모델로 점차 이동하고 있습니다.\n",
            "2. 대형 언어 모델(LLM)들이 트랜스포머 아키텍처를 기반으로 자연어 처리 분야를 근본적으로 변화시키고 있습니다.\n",
            "3. IBM은 기존의 단일 트랜스포머 모델을 대체하는 하이브리드 Mamba-2/Transformer 스택을 도입한 Granite 4.0이라는 오픈소스 LLM 패밀리를 출시해 메모리 사용량을 줄이고 있습니다.\n",
            "4. 최근 연구에서는 트랜스포머와 뇌 신경망 간의 연결고리를 밝히는 연구도 진행되고 있습니다.\n",
            "\n",
            "이 외에도 HD Hyundai Electric이 미국에 초고압 변압기를 공급하는 계약을 체결하는 등 'transformer'라는 단어가 전기 변압기 분야에서도 언급되고 있으니, 문맥에 따라 구분이 필요합니다.\n",
            "\n",
            "출처:\n",
            "https://www.google.com/search?q=transformer+model+latest+news\n"
          ]
        }
      ],
      "source": [
        "q = \"트랜스포머(transformer) 모델에 대한 최신 뉴스는 어떤게 있어?\"\n",
        "resp = executor.invoke({\"input\": q})\n",
        "print(\"\\n=== 최종 답변 ===\\n\")\n",
        "print(resp[\"output\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## 그래프 기반 RAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "gather": {
          "logged": 1757859714345
        }
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "from typing import TypedDict, Annotated, List, Dict, Any, Optional\n",
        "import operator, os\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_community.tools import ArxivQueryRun\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "\n",
        "llm = AzureChatOpenAI(\n",
        "    api_key=AZURE_OPENAI_API_KEY,\n",
        "    azure_endpoint=END_POINT,  \n",
        "    azure_deployment=MODEL_NAME,          \n",
        "    api_version=\"2024-12-01-preview\",\n",
        "    temperature=0.2,\n",
        ")\n",
        "\n",
        "# State 정의\n",
        "class State(TypedDict):\n",
        "    question: str\n",
        "    web_results: Annotated[List[Dict[str, Any]], operator.add]     # Tavily 결과 누적\n",
        "    paper_results: Annotated[List[str], operator.add]              # Arxiv 결과 누적\n",
        "    answer: Optional[str]\n",
        "    logs: Annotated[List[str], operator.add]\n",
        "\n",
        "def init_node(state: State):\n",
        "\n",
        "    return {\"logs\": [f\"[init_node]\"]}\n",
        "\n",
        "# Tavily 웹 검색 노드 \n",
        "tavily = TavilySearchResults(max_results=10)\n",
        "\n",
        "def search_web(state: State):\n",
        "    items = tavily.invoke({\"query\": state[\"question\"]})\n",
        "\n",
        "    # 제목과 주고, 내용만 추출\n",
        "    simple = [{\"title\": it.get(\"title\"), \"url\": it.get(\"url\"), \"snippet\": it.get(\"snippet\")} for it in items]\n",
        "    return {\"web_results\": simple, \"logs\": [f\"[tavily] {len(simple)} hits\"]} # 결과를 web_result에 반환\n",
        "\n",
        "# Arxiv 논문 검색 노드 \n",
        "arxiv = ArxivQueryRun()  \n",
        "\n",
        "def search_papers(state: State):\n",
        "    text = arxiv.run(state[\"question\"])  # 제목/저자/초록 요약이 문자열로 옴\n",
        "    return {\"paper_results\": [text], \"logs\": [f\"[arxiv] block_len={len(text)}\"]} # 결과를 paper_results에 반환\n",
        "\n",
        "# 통합 요약/답변 노드 <-- RAG 파트\n",
        "synth_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\",\n",
        "     \"너는 RAG 답변기야. 아래 웹 검색 결과와 논문 요약을 참고해, 질문에 대해 한국어로 정확하고 간결히 답해. \"\n",
        "     \"최대한 웹과 논문에 사용자의 질문데 대한 대답이 있다면 해당 근거해서 대답해\"\n",
        "     \"만약 검색한 내용이 질문을 답하기에 충분하지 않으면 함부로 추측하지 말고 네가 추천하는 더 좋은 질문을 사용자에게 제안해\"\n",
        "     \"마지막에 출처 URL이 있으면 정리해서 출력해.\"),\n",
        "    (\"user\", \"질문: {q}\\n\\n[웹]\\n{web}\\n\\n[논문]\\n{papers}\\n\\n최종 답변:\")\n",
        "])\n",
        "\n",
        "def synthesize(state: State):\n",
        "    # 웹/논문 문자열로 합치기\n",
        "    web_txt = \"\\n\".join([f\"- {w.get('title')} ({w.get('url')}) :: {w.get('snippet')}\" for w in state.get(\"web_results\", [])])\n",
        "    paper_txt = \"\\n---\\n\".join(state.get(\"paper_results\", []))[:10000]  # 길이가 너무 길면 앞 부분만 잘라서\n",
        "    out = (synth_prompt | llm | StrOutputParser()).invoke({\"q\": state[\"question\"], \"web\": web_txt, \"papers\": paper_txt})\n",
        "    return {\"answer\": out, \"logs\": [\"[synth] done\"]}\n",
        "\n",
        "# --- 그래프 구성 ---\n",
        "graph = StateGraph(State)\n",
        "graph.add_node(\"init_node\", init_node)\n",
        "graph.add_node(\"web\", search_web)\n",
        "graph.add_node(\"papers\", search_papers)\n",
        "graph.add_node(\"synth\", synthesize)\n",
        "\n",
        "graph.set_entry_point(\"init_node\")\n",
        "\n",
        "# 병렬 분기: query → (web, papers)\n",
        "graph.add_edge(\"init_node\", \"web\")\n",
        "graph.add_edge(\"init_node\", \"papers\")\n",
        "\n",
        "# 두 경로가 끝나면 synth로 합류\n",
        "graph.add_edge(\"web\", \"synth\")\n",
        "graph.add_edge(\"papers\", \"synth\")\n",
        "graph.add_edge(\"synth\", END)\n",
        "\n",
        "app = graph.compile()\n",
        "\n",
        "# plot graph\n",
        "from IPython.display import Image\n",
        "Image(app.get_graph().draw_mermaid_png())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "gather": {
          "logged": 1757859727634
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "트랜스포머(Transformer)는 인공 신경망의 한 종류로, 주로 자연어 처리 분야에서 사용되는 딥러닝 모델입니다. 2017년에 구글이 발표한 논문 \"Attention is All You Need\"에서 처음 소개되었으며, 기존의 순환 신경망(RNN)이나 합성곱 신경망(CNN)과 달리 어텐션 메커니즘(attention mechanism)을 중심으로 작동합니다.\n",
            "\n",
            "트랜스포머의 핵심 아이디어는 입력 데이터 내에서 중요한 부분에 집중(attention)하여 병렬 처리가 가능하다는 점입니다. 이를 통해 긴 문장이나 복잡한 문맥도 효과적으로 이해하고 처리할 수 있습니다. 이 모델은 번역, 문서 요약, 질문 답변 등 다양한 자연어 처리 작업에서 뛰어난 성능을 보이며, 최근에는 이미지 처리 등 다른 분야에도 응용되고 있습니다.\n",
            "\n",
            "요약하면, 트랜스포머는 '어텐션'이라는 메커니즘을 활용해 데이터를 효율적으로 처리하는 딥러닝 모델로, AI 혁신을 이끄는 핵심 기술 중 하나입니다.\n",
            "\n",
            "출처:\n",
            "- https://ko.wikipedia.org/wiki/%ED%8A%B8%EB%9E%9C%EC%8A%A4%ED%8F%AC%EB%A8%B8_(%EA%B8%B0%EA%B3%84_%ED%95%99%EC%8A%B5)\n",
            "- https://blog.kakaocloud.com/91\n",
            "- https://aws.amazon.com/ko/what-is/transformers-in-artificial-intelligence/\n",
            "- https://wikidocs.net/31379\n"
          ]
        }
      ],
      "source": [
        "def run(q:str):\n",
        "\n",
        "    # question: str\n",
        "    # web_results: Annotated[List[Dict[str, Any]], operator.add]     \n",
        "    # paper_results: Annotated[List[str], operator.add]            \n",
        "    # answer: Optional[str]\n",
        "    # logs: Annotated[List[str], operator.add]\n",
        "\n",
        "    init_state = {'question':q, 'search_query':None, 'web_results':[], 'paper_results':[], 'answer':None, 'logs':[]}\n",
        "    return app.invoke(init_state)['answer']\n",
        "\n",
        "result = run('트랜스포머가 뭐야?')\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "gather": {
          "logged": 1757859742539
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GenG세대는 'Gen Z(젠지, Z세대)'를 의미하며, 대략 1990년 중반부터 2010년 초반 사이에 태어난 세대를 말합니다. 이 세대는 디지털 환경에 익숙하고, SNS와 모바일을 중심으로 소통하며, 개인의 개성과 다양성을 중시하는 특징이 있습니다.\n",
            "\n",
            "요즘 GenG세대가 가장 좋아하는 트렌드는 다음과 같습니다:\n",
            "\n",
            "1. **노소비코어(No-consumption core)**: 불필요한 소비를 줄이고 환경과 지속가능성을 중시하는 소비 패턴입니다.\n",
            "2. **디지털 패션과 스트리트웨어**: 개성을 표현할 수 있는 패션 스타일을 선호하며, 온라인에서 패션 정보를 활발히 공유합니다.\n",
            "3. **SNS와 숏폼 콘텐츠**: 틱톡, 인스타그램 릴스 등 짧고 임팩트 있는 영상 콘텐츠를 즐겨 소비합니다.\n",
            "4. **개인 맞춤형 경험과 가치 소비**: 자신만의 취향과 가치에 맞는 제품과 서비스를 선택하는 경향이 강합니다.\n",
            "\n",
            "즉, GenG세대는 디지털 친화적이며, 환경과 사회적 가치에 관심이 많고, 자신만의 개성을 표현하는 트렌드를 선호합니다.\n",
            "\n",
            "출처:\n",
            "- https://www.accio.com/business/ko/%EC%A0%A0%EC%A7%80%ED%8A%B8%EB%A0%8C%EB%93%9C\n",
            "- https://avocadogiant.com/newsletter/korea/2023-gen-z-%EB%A7%88%EC%BC%80%ED%8C%85-%ED%8A%B8%EB%A0%8C%EB%93%9C/\n",
            "- https://link.kakaopay.com/_/Q300q6g\n"
          ]
        }
      ],
      "source": [
        "result = run('GenG세대가 뭐고 그 세대가 가장 좋아하는 요즘 트랜드가 뭐야?')\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "gather": {
          "logged": 1757859765208
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "최근 이미지 생성 분야에서 diffusion 모델의 연구 동향은 다음과 같습니다.\n",
            "\n",
            "1. **텍스트 기반 이미지-비디오 생성**: 최신 연구(TIV-Diffusion, 2024년)에서는 텍스트 설명과 첫 프레임 이미지를 입력받아, 객체 중심의 움직임을 정밀하게 제어하면서 고품질 영상을 생성하는 diffusion 모델이 제안되었습니다. 이 모델은 텍스트와 시각 정보를 융합해 객체별 움직임을 정확히 반영하고, 객체 소실이나 움직임 불일치 문제를 해결하는 객체 중심 정렬 모듈을 도입해 기존 방법 대비 우수한 성능을 보입니다.\n",
            "\n",
            "2. **고품질 인물 생성 및 편집**: CVPR 2025 참관기에서는 고품질 인물 생성을 위한 HG-DPO 연구가 소개되었으며, 포인트 기반 편집을 위한 diffusion 모델 연구도 활발히 진행 중입니다.\n",
            "\n",
            "3. **3D 비전과의 결합**: diffusion 모델이 3D 이미지 생성 및 편집 분야로 확장되어, 3D 비전과 결합한 다양한 응용 연구가 진행되고 있습니다.\n",
            "\n",
            "4. **데이터 증강 및 합성 데이터 기술**: diffusion 모델을 활용한 데이터 증강 기법과 합성 데이터 생성 기술이 부각되면서, 학습 데이터 부족 문제를 해결하는 데 기여하고 있습니다.\n",
            "\n",
            "5. **Stable Diffusion과 생성모델 혁신**: Stable Diffusion을 중심으로 한 diffusion 기반 생성모델이 이미지 생성 분야에서 혁신을 이끌고 있으며, GPT 스타일의 모델과 결합해 이미지 생성의 새로운 패러다임을 제시하는 연구도 있습니다.\n",
            "\n",
            "요약하면, diffusion 모델은 텍스트-이미지-비디오 통합 생성, 객체 중심 제어, 3D 비전 확장, 데이터 증강, 그리고 생성모델 혁신 측면에서 활발한 연구가 이루어지고 있습니다.\n",
            "\n",
            "---\n",
            "출처 URL:\n",
            "- https://www.themoonlight.io/ko/review/diffusion-models-in-3d-vision-a-survey\n",
            "- https://tech.kakao.com/posts/709\n",
            "- https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11891128\n",
            "- https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11891119\n",
            "- https://brunch.co.kr/@advisor/43\n"
          ]
        }
      ],
      "source": [
        "result = run('이미지 생성 분야인 diffuion 모델의 최신 연구 동향은?')\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
